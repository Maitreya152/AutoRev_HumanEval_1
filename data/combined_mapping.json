{
    "0jsfesDZDq": {
        "gold": "**Summary**\nThis paper introduces a novel task-agnostic method called Lyapunov Noise Pruning (LNP) for designing sparse Recurrent Spiking Neural Networks (RSNNs) from an untrained and arbitrarily initialized dense network. The method utilizes the Lyapunov spectrum and spectral graph sparsification algorithms to prune synapses and neurons while retaining network stability, enabling the sparse network to be later trained for various tasks. The methodology has been shown to outperform alternative pruning approaches in terms of network efficiency, while maintaining similar performance levels on diverse down-streaming tasks and datasets. The paper\u2019s novelty lies in its approach to pruning prior to training, which is not commonly addressed in typical models that prune post-training.\n\n**Strengths**\n- The paper is well-written, providing clear illustrations of the methods and implementations, making it approachable for readers.\n- Introduces a novel, task-agnostic method for designing sparse RSNN (Recurrent Spiking Neural Networks), which significantly contrasts with conventional task-dependent pruning approaches.\n- Demonstrates that Lyapunov Noise Pruning (LNP) can enhance network efficiency over alternative methods like AP (Activity Pruning), which supports its potential utility in network pruning.\n- The proposed method utilizes the heterogeneous timescales of RSNNs, offering biological plausibility and further aiding the pruning process, proving to be not only task-agnostic but also learning-rule-agnostic.\n- Despite its novelty, the technique considers the equivalence between dense and sparse networks, which increases its suitability for models like HRSNN.\n\n**Weaknesses**\n- The paper does not fully explain the motivation behind focusing specifically on RSNNs or the significance of LNP within the broader field of SNNs.\n- Lack of clarity in differentiating between the dynamics of recurrent network structures and the intrinsic recurrency of spiking neurons.\n- The experimental design and the chosen network models might be too simplistic and might not reflect the prunability needed in more complex or real-world scenarios.\n- Inconsistencies and lack of clarity in the references and citations, suggesting a need for better organization of literature and referencing.\n- The results section lacks error bars for CIFAR-10, omitting necessary details about accuracy variance that could indicate performance reliability.\n- The contribution of each component of LNP is not clearly delineated through an ablation study, weakening the argument for the necessity of each in the overall performance of the method.\n\n**Questions**\n- 1. Could you clarify why RSNNs were chosen for applying LNP, particularly when considering the unique challenges posed by the dual dynamics inherent in these networks?\n- 2. How does LNP address the discontinuity characteristically associated with spikes in RSNNs, especially when analyzing the Lyapunov spectrum?\n- 3. What does \"heterogeneous\" signify in the context of timescales in RSNN? Is it merely referring to variable time constants, or is there a broader interpretation?\n- 4. Can the authors explain the impact of random initialization versus LNP initialization on the network dynamics during training?\n- 5. Given that some studies like that by Panda et al., have shown different results, what are the specific advantages or shortcomings of the LNP method in comparison?\n- 6. There is mention of using Lorenz and Rossler datasets which are not typical in SNN research. Could you provide justifications or citations for their use?\n- 7. Is it possible to apply the principles and methods of LNP to non-recurrent, purely feed-forward SNNs to test its generalizability across different network architectures?",
        "5_5": "**Summary**\nThis paper introduces the Lyapunov Noise Pruning (LNP) method, a novel approach for pruning Recurrent Spiking Neural Networks (RSNNs) to enhance computational efficiency and accuracy. LNP employs spectral graph sparsification and the Lyapunov spectrum to identify and eliminate redundant neurons and synapses, ensuring network stability. The paper demonstrates the efficacy of LNP through experiments on both synthetic and real-world datasets, showcasing improved performance metrics over traditional methods. Furthermore, the paper explores the application of LNP to heterogeneous RSNNs (HRSNNs), which exhibit diverse neuronal timescales, thereby improving network performance.\n\n**Strengths**\n- The paper addresses a novel and significant problem of pruning spiking neural networks, which is a critical issue given the high computational costs of these networks.\n- The introduction of a Lyapunov-based pruning method is both innovative and timely, with a clear and well-presented algorithm.\n- The paper provides a thorough explanation and analysis of the proposed method, including its application to HRSNN, which demonstrates a better performance compared to other methods.\n- The results of the experiments are compelling, indicating that the proposed method outperforms existing techniques in terms of accuracy and computational efficiency.\n- The paper is well-written, providing a clear exposition of the research problem, methodology, and results, making it accessible and understandable.\n\n**Weaknesses**\n- The novelty of the approach is questionable as it primarily combines existing techniques (spectral graph sparsification and Lyapunov spectrum analysis) with no substantial theoretical contribution.\n- The paper lacks a detailed description of the datasets used in the experiments and does not provide sufficient details about the training process, such as the architecture of the models used.\n- There is a significant lack of experimental validation on real-world datasets, which is crucial for assessing the practical applicability of the proposed method.\n- The paper does not sufficiently explore the potential impact of the proposed method on model interpretability and does not address the computational cost associated with the pruning and training process.\n- The method's claim of being task-agnostic is not convincingly supported, as the pruning results are not consistently better across all tasks.\n- The paper does not discuss the impact of the pruning method on the training of spiking neural networks, particularly in scenarios where spiking networks are more suitable than non-spiking networks.\n\n**Questions**\n- Could the authors clarify the novelty of their approach and provide a detailed comparison with other existing methods?\n- How do the authors address the challenge of applying the proposed method to real-world datasets, and what are the specific advantages of using spectral graph sparsification in this context?\n- In the context of computational cost, how does the pruning and training process impact the overall efficiency of the model, and what are the implications for real-world applications?\n- How does the proposed method perform on other types of spiking neural networks, such as those with different types of neurons or network structures?\n- Can the authors provide additional experimental results, particularly on real-world datasets, to further validate the effectiveness and applicability of the proposed method?\n- How does the method address the issue of interpretability in spiking neural networks, and what are the potential implications for model understanding and trustworthiness?",
        "5_3": "**Summary**\nThe paper explores a novel method, Lyapunov Noise Pruning (LNP), aimed at optimizing the performance of Recurrent Spiking Neural Networks (RSNNs) by reducing complexity through pruning. LNP is positioned as a task-agnostic approach that leverages Lyapunov exponents and spectral graph sparsification to prune neurons and synapses, enhancing the computational efficiency and prediction accuracy of RSNNs. The method is tested across various datasets, demonstrating its effectiveness in reducing computational overhead while maintaining performance. Despite its innovative approach and experimental validation, the paper suffers from unclear explanations and a lack of rigorous theoretical backing for the proposed method. There is also a significant absence of comparison with other state-of-the-art pruning methods and a lack of discussion on related works, which are crucial for establishing the novelty and contribution of the research.\n\n**Strengths**\n- The paper proposes a novel method, Lyapunov Noise Pruning (LNP), which is task-agnostic, aiming to reduce computational overhead in Recurrent Spiking Neural Networks (RSNNs) while maintaining performance.\n- Extensive experimental results demonstrate the effectiveness of the LNP method across different datasets, including image classification and time-series prediction tasks.\n- The paper is clearly written, providing a good overview of the LNP method and its implementation, which makes the content accessible and understandable.\n- The proposed method uses a principled approach based on the Lyapunov spectrum, which could potentially offer insights into the dynamics of RSNNs.\n\n**Weaknesses**\n- The paper lacks a clear explanation of the method's underlying principles and the rationale behind its design, particularly concerning the integration of Lyapunov exponents and spectral graph sparsification.\n- The related work section is insufficient, omitting crucial discussions of other pruning methods in the literature, which undermines the paper's ability to position itself within the current research landscape.\n- There is a lack of comparison with other state-of-the-art pruning methods, which is necessary to substantiate the claimed improvements over existing techniques.\n- The paper does not provide a detailed analysis of the time complexity involved in the proposed method, which is critical for understanding its feasibility in practical scenarios.\n- The presentation of the paper contains several typographical errors and lacks clarity in some figures and algorithm descriptions, which could confuse the reader.\n- The paper does not discuss the potential limitations of the LNP method, such as the impact of noise on model performance or the robustness of the method to variations in hyperparameters.\n\n**Questions**\n- Can the authors provide a more detailed explanation of the method's underlying principles and the specific role of Lyapunov exponents and spectral graph sparsification in this context?\n- How does the proposed LNP method compare with other state-of-the-art pruning methods in terms of computational overhead and performance?\n- Could the authors discuss the time complexity of the proposed method and its implications for practical applications?\n- What are the potential limitations of the LNP method, and how could they be addressed to improve the method's robustness and reliability?\n- Could the authors clarify the notation and descriptions used in the paper, particularly in relation to the algorithms and figures, to enhance the clarity of the content?"
    },
    "30L0rr9W8A": {
        "gold": "**Summary**\nThe paper explores safe data-driven control with neural networks where true state access is unavailable. It innovatively embeds observations in a latent space using a Lipschitz autoencoder, on which a safe controller and dynamics are learned without explicit safe or unsafe set definitions. The approach involves learning the dynamics and control barrier function (CBF) in this latent space, using a QP-CLF based approach or directly regressing over gradients. These components are learned end-to-end, and experimental validations on common CBF benchmarks and the CARLA simulator are provided. There seems to be a significant focus on theoretical aspects, particularly around embedding dynamics and safe control optimization in a latent space, postulating an interesting mechanism to handle partial observability.\n\n**Strengths**\n- The idea of embedding the dynamics in a latent space and performing safe control optimization therein is innovative, allowing for the learning of both the dynamics and the safe controller without pre-specifying safe sets or dynamics.\n- The novelty of learning a Control Barrier Function (CBF) in the latent space shows significant potential, and the use of Lipschitz neural networks and Bjorck layers provides a robust framework for this purpose.\n- The presentation and the figures in the paper are of high quality, clearly demonstrating the results and adding credibility to the experimental outcomes, which are convincingly good, particularly highlighted by the results from the CARLA simulation.\n- The paper is generally well-written, making it accessible and easy to follow.\n\n**Weaknesses**\n- The discussion on safety, specifically regarding barrier certificates, is too brief and lacks clarity. The conditions for barrier certificates should explicitly pertain to the interior of the safe set, and this delineation is not adequately drawn out.\n- The manuscript fails to provide discussions or guarantees that the safety constraints in the latent space will map appropriately onto the actual physical space, raising concerns about real-world applicability and the robustness of safety claims.\n- There is a notable absence of a detailed explanation on the need for and advantage of using Lipschitz autoencoders over other potential data-driven control methods like reinforcement learning or Gaussian processes.\n- The practical benefits of this approach remain under-discussed, particularly in comparison to other existing methods, where some level of prior knowledge about dynamics can significantly enhance training realism and stability.\n- The paper lacks sufficient theoretical detail to ensure that the notions of traditional CBFs carry over effectively into the latent space, such as the ensuring of the injectiveness of the encoder or concerns regarding the dimensionality and topology of the latent space compared to the original state space.\n- Certain technical descriptions and mathematical expressions require refinement for better clarity and precision.\n- There is a lack of discussion about the training stability and details, including whether training was end-to-end, the robustness of the learning across various trials, and the specifics of the encoder training process.\n\n**Questions**\n- How does this work relate to traditional methods of data-driven output feedback control in terms of approach and effectiveness?\n- Can the latent-space embedding be considered a form of neural observer? If not, why does this distinction exist?\n- Is there a rigorous way to analyze the performance and safety of the decoded trajectories in real scenarios? What are the metrics for judging the reliability of safety in practical applications?\n- Considering that the true state might often be inaccessible, how does this model compete with systems where partial state information is utilized to enhance learning accuracy and efficiency?\n- Given the compromise on theoretical strictness (using a soft loss function for CBF), is there a methodology planned for reinforcing these approximate models via verification mechanisms?\n- Can details be provided about the epsilon-deviation behavior from safety boundaries during empirical evaluations and the implications for persistent safety?\n- Lastly, how do the authors address potential disconnects or topological disparities when mapping from the latent space configurations to the original state space structure, particularly in terms of safety set connectivity?",
        "5_5": "**Summary**\nThe paper introduces the LatentCBF framework, which employs a data-driven control barrier function (CBF) to enhance safety in autonomous systems like cars and drones. The novel approach defines the CBF in the latent space, which is derived from observations through an autoencoder, and learns the system dynamics and control barrier functions simultaneously. The framework is tested in simulated environments, showcasing its ability to maintain safety without requiring full state information. The paper also proposes using a Lipschitz network-based AutoEncoder to ensure the Lipschitz continuity of the CBF, which is crucial for the theoretical safety guarantees of the framework. Despite its innovative approach, the paper has been critiqued for its lack of empirical validation in real-world scenarios, unclear theoretical contributions, and poor presentation that makes it difficult to follow.\n\n**Strengths**\n- The paper introduces a novel framework for safe control in autonomous systems, particularly focusing on using a data-driven control barrier function (CBF) that operates in the latent space, which is derived from observations through an autoencoder.\n- The use of a Lipschitz network-based autoencoder is highlighted as a significant contribution, ensuring the Lipschitz continuity of the CBF, which is crucial for theoretical safety guarantees.\n- The framework has been tested in simulated environments, demonstrating its ability to maintain safety without requiring full state information, which is a notable advancement over traditional methods that rely on full state knowledge.\n- The paper explores the use of a data-driven approach to learn the CBF, which could potentially lead to more practical and adaptable safety protocols in autonomous systems.\n\n**Weaknesses**\n- The paper lacks empirical validation in real-world scenarios, which is crucial to establish the effectiveness and robustness of the proposed framework in practical applications.\n- The theoretical contributions of the paper are not clearly outlined, making it difficult to discern the specific novel contributions of the framework.\n- The presentation of the paper is problematic, with a significant amount of content relegated to the appendix, making it difficult for readers to grasp the main ideas and contributions of the research.\n- The paper does not sufficiently justify the choice of using a Lipschitz network-based autoencoder, and the empirical performance of the proposed framework compared to other methods (like rCBLF-QP and BarrierNet) is not convincingly demonstrated.\n- There is a lack of detailed comparison with existing methods, particularly in terms of computational efficiency, which is a critical aspect for real-time applications.\n\n**Questions**\n- Could the authors provide empirical evidence of the framework's performance in real-world scenarios to validate its effectiveness and robustness?\n- How does the proposed framework compare in terms of computational efficiency with other methods like rCBLF-QP and BarrierNet?\n- What specific theoretical contributions does the paper offer, and how do these contribute to the field of safe control in autonomous systems?\n- Can the authors clarify the choice and necessity of using a Lipschitz network-based autoencoder in their framework?\n- Is there a detailed explanation or empirical evidence that supports the claim that the proposed framework is more suitable for defining a neural barrier function compared to traditional networks?",
        "5_3": "**Summary**\nThis paper introduces LatentCBF, a novel method that leverages latent space representations to define control barrier functions (CBFs) for safe control of robotic systems, particularly in environments where full state information is inaccessible. The approach employs a Lipschitz network-based autoencoder and a barrier network to map observations into latent space, where a CBF is defined. The paper presents several experiments across different robotic systems, showcasing the potential of LatentCBF in improving safety and robustness in control tasks. However, the novelty and theoretical grounding of the method are questioned, as the core idea of using latent space for CBF definition appears to be a straightforward extension of existing methods. The paper also suffers from unclear explanations, limited theoretical justification, and inadequate comparison with existing methods.\n\n**Strengths**\n- The paper is well-structured, clearly written, and easy to follow.\n- The proposed method effectively learns control barrier functions (CBFs) from observations without requiring full state information, which is a significant advancement in the field.\n- The paper demonstrates that using Lipschitz networks in the latent space can improve the performance of CBFs by reducing the risk of singularities, which is a critical aspect for safe control.\n- The application of the method to various robotic systems, including quadrotors and cars, is broad and shows versatility in its application.\n- The paper is well-motivated and clearly presents the rationale behind using latent space representations for CBF definition, which appears to be a novel approach.\n\n**Weaknesses**\n- The novelty of the proposed method is questionable as the core idea of using latent space for CBF definition seems to be a straightforward extension of existing methods.\n- The paper lacks a detailed theoretical analysis on how the CBF is learned in the latent space, which is crucial for understanding the theoretical guarantees of the proposed method.\n- There is insufficient comparison with existing methods, particularly those that also use neural networks to learn barrier functions. This omission weakens the paper's claim of superiority over existing approaches.\n- The paper's experimental setup and results are not convincing enough to support the claims of the method's effectiveness. Specifically, the use of an oracle-based baseline and the lack of statistical analysis in the results undermine the robustness of the findings.\n- The method's applicability is limited to specific robotic systems, which restricts its generalizability.\n- The paper has multiple typographical errors and unclear statements, which could potentially confuse the reader.\n\n**Questions**\n- Can the authors clarify the novelty of the proposed method and how it significantly differs from existing methods?\n- How does the CBF in latent space ensure safety and control, and what are the theoretical guarantees of this approach?\n- What is the specific contribution of the Lipschitz network in this context, and how does it enhance the performance of the barrier function?\n- Can the authors provide a more detailed comparison with existing methods that also use neural networks to learn barrier functions?\n- Why was an oracle-based baseline used in the experiments, and can the authors provide statistical analysis of the results to support their claims?\n- How does the proposed method perform in scenarios where the observations are noisy or incomplete, and what measures are taken to ensure the robustness of the CBF in such cases?"
    },
    "4y3GDTFv70": {
        "gold": "**Summary**\nThe paper provides a theoretical explanation for emergent abilities in large language models (LLMs), such as in-context learning, chain-of-thought prompting, and instruction fine-tuning, by linking these to Bayesian inference on latent intentions underlying the language. The authors argue that emergent capabilities arise from the compositional structures in language encoded within the distribution of LLMs, describing the relationship through a mixture model. They present some formal results and use synthetic data for experimental validation. However, the paper seems to make minor adjustments to existing frameworks (e.g., Xie, 2022) without adding substantial novelty. Reviewers critiqued the formalization of concepts and argued that certain sections lack specificity or formal arguments.\n\n**Strengths**\n- The paper tackles crucial concepts such as in-context learning, Chain of Thought (CoT), and instruction fine-tuning, which are significant in the study of large language models (LLMs).\n- The manuscript is well-written, clear, and follows a logical structure, making it easy for readers to follow the argumentation and analyses presented.\n- The study introduces a novel perspective on the role of language and underlying intentions in enabling emergent properties of LLMs.\n- The formal results and theoretical discussions, particularly the soundness of the theoretical results, are compelling and substantiate the arguments made.\n- The paper includes comparisons of the proposed model with different applications and capabilities of LLMs, enhancing the reader's understanding of the practical implications of the theory.\n\n**Weaknesses**\n- The paper struggles with novelty in theoretical results, as some of the concepts, including in-context learning as state or intention estimation, have been previously defined by Xie, 2022.\n- The characterization and definition of the CoT prompts and instruction fine-tuning sections are not rigorous, causing difficulties in understanding how they build on the foundational concepts of LLMs, particularly in-context learning.\n- Sections on Chain-of-Thought prompting and instruction fine-tuning are vague and lack formal specificity, particularly in how these sections tie back to the foundational model of generative cognition in LLMs.\n- The paper does not adequately address the implications of using different types of tokenizers (like character-based versus BPE tokenizers) in experimentation on the findings and their generalizability to standard LLM behaviors.\n- There is insufficient discussion on how the use of synthetic data impacts findings, and there\u2019s a lack of statistical significance tests or uncertainty estimates to substantiate the results.\n\n**Questions**\n- Can you clarify the definitions provided in Section 2 regarding the concept of \\(\\epsilon\\)-ambiguity and the terms and conditions used in characterization?\n- The proof of Theorem 1 references neural networks and SGD\u2014how do these fit into the discussion since the theorem itself does not specify architecture or training procedures?\n- How does the paper\u2019s approach to identifying and defining emergent behaviors compare to other contemporary theories, such as those proposed by Arora et al. (2023)?\n- Please elaborate on the hyperparameter selection for the LMs and the impact these parameters have on the findings presented in the paper.\n- Is there a noticeable difference between the outcomes when using character-based models versus BPE tokenizers in your experiments?\n- Could you discuss how well the model's findings might adapt or apply to natural language, outside the confines of structured experimental setups?",
        "5_5": "**Summary**\nThe paper explores the capabilities of large language models (LLMs) through a novel lens, focusing on their ability to perform well on unseen tasks by leveraging their training on extensive datasets. It proposes a latent space theory to explain these emergent capabilities, specifically attributing them to Bayesian inference on the sparse joint distribution of languages. The authors argue that LLMs can perform effectively due to their ability to approximate the marginal distribution of languages, which is claimed to be sparse, thereby allowing for efficient inference. The paper is supported by both theoretical and simulated results, which are aimed at substantiating the claims made by the authors.\n\n**Strengths**\n- The paper is well-written and provides a clear explanation of the concepts involved, making it accessible to readers.\n- It proposes a novel latent space theory to explain the emergent capabilities of large language models (LLMs), which is an interesting and potentially impactful contribution to the field.\n- The authors provide a solid theoretical foundation for their claims, which is complemented by simulated results that help to substantiate their arguments.\n- The paper explores the properties of language generation through a latent space model, which is both an intuitive and effective way to study the problem.\n- The paper is well-motivated, providing a logical progression from the problem statement to the proposed solution, which makes it easy to follow and understand.\n\n**Weaknesses**\n- The paper does not clearly define what is meant by the \"emergent capabilities\" of LLMs, which could lead to confusion about the specific abilities being discussed.\n- The authors claim that the marginal distribution of languages is sparse, which is not supported by empirical evidence or existing literature. This claim is crucial to the validity of the paper's main argument.\n- The paper lacks a detailed discussion on the practical implications of the proposed latent space theory, which could limit its applicability in real-world scenarios.\n- There is a lack of clarity regarding how the theory relates to other existing works, such as the theory of in-context learning as Bayesian inference proposed by Xie et al. (2022). A more thorough discussion on the differences and similarities could enhance the paper's contribution.\n- The paper does not provide sufficient empirical evidence to support its claims, particularly regarding the sparsity of the marginal distribution and the effectiveness of the proposed approach.\n- The presentation of the paper could be improved, particularly in the organization and clarity of the theoretical sections.\n\n**Questions**\n- Could the authors clarify what is meant by \"emergent capabilities\" in the context of this paper?\n- How do the authors justify the claim that the marginal distribution of languages is sparse, and what empirical evidence supports this claim?\n- Can the authors provide more details on how the proposed latent space theory can be applied in practical scenarios, and what are the benefits of this approach compared to existing methods?\n- How does the proposed theory relate to the work by Xie et al. (2022) on in-context learning as Bayesian inference, and what are the key differences between the two approaches?\n- Could the authors provide more empirical evidence to support their claims, particularly regarding the sparsity of the marginal distribution and the effectiveness of the proposed approach?\n- How does the paper address the practical challenges of estimating the marginal distribution of languages, and what are the implications for the proposed latent space theory?",
        "5_3": "**Summary**\nThe paper explores the performance of Large Language Models (LLMs) under the assumption that text is generated from a latent intention space. It argues that the model's ability to produce coherent and contextually relevant text is due to its implicit knowledge of the underlying distribution of these intentions. The authors introduce a measure of language ambiguity and claim that LLMs are effective in modeling the marginal distribution, which in turn influences their performance on various tasks. The paper is structured to present theoretical results, supported by synthetic experiments, aiming to demonstrate how the model's ability to approximate the marginal distribution is linked to its performance across different scenarios. However, the paper faces criticism for its unclear presentation, lack of real-world examples, and insufficient empirical validation.\n\n**Strengths**\n- The paper introduces a novel latent space theory to explain the emergent abilities of Large Language Models (LLMs), providing a fresh perspective on the capabilities of these models.\n- The theoretical approach and formalization of the problem are rigorous and sound, making the paper's arguments and conclusions well-supported and logically coherent.\n- The concept of language ambiguity and its relationship to LLM performance is an interesting and original angle that could benefit further research and discussion in the field.\n- The paper is well-structured and written, with clear presentation of ideas, making it accessible and easy to follow for readers.\n\n**Weaknesses**\n- The paper lacks real-world examples and empirical evidence to support its claims about LLMs' ability to implicitly model the distribution of intentions, which is crucial for validating the theoretical assertions.\n- The connection between the theoretical model and real-world applications is not clearly established, leaving some skepticism about the practical implications of the proposed theory.\n- The paper does not provide sufficient comparative analysis with other existing models or methods, which could have strengthened the argument by showing the superiority or novelty of the proposed approach.\n- Some sections of the paper are described as difficult to follow, with potentially confusing or unclear explanations of key concepts such as the relationship between language ambiguity and model performance.\n- The experimental design is limited to synthetic data, which does not convincingly demonstrate the practical effectiveness of the proposed theory in real-world scenarios.\n\n**Questions**\n- Could the authors provide real-world examples or case studies to demonstrate how the proposed theory applies in practical scenarios?\n- How do the authors define and differentiate \"unambiguous\" and \"\\(\\epsilon\\)-ambiguous\" languages within the context of their theory?\n- Can the authors clarify the specific relationship between language ambiguity and the model's performance as discussed in the paper?\n- What are the potential implications of the proposed theory for the development of more advanced or specialized LLMs, and how might it guide future research in this area?\n- How does the proposed theory align with or differ from existing models or approaches in the field, and what are the potential advantages or limitations of the proposed method compared to these alternatives?"
    },
    "73dhbcXxtV": {
        "gold": "**Summary**\nThe paper introduces a novel framework, LOLAMEME, which aims to expand mechanistic understanding by integrating logic, memory, and nuanced language aspects through two manifestations: LoLa and MeMe languages. It presents a hybrid architecture named T HEX, which modifies the Hyena model by incorporating GPT-2 layers. Various experiments are conducted to benchmark T HEX against traditional GPT-2 and Hyena models, showing improvements in specific tasks and on targeted datasets. Despite these advancements, the paper lacks clarity in the motivation behind model design and requires substantial improvements in presentation, including addressing grammatical errors and inconsistencies in data description.\n\n**Strengths**\n- The research proposes an innovative hybrid architecture combining transformer-based GPT-2 and convolution-based Hyena, demonstrating improved performance on selected test datasets.\n- The creation of the LOLAMEME framework and its implementation in constructing multiple datasets with several billion tokens adds significant value and potential for future research in the field.\n- Comprehensive experiments have been conducted across these datasets and a related benchmark to evaluate the effectiveness of the new framework, showing promising results.\n\n**Weaknesses**\n- The motivation behind the model design and problem formulation is unclear, with insufficient explanation of the differences and relative strengths between T HEX, GPT-2, and Hyena architectures.\n- The novelty seems limited as the primary architectural changes involve straightforward layer replacements between the Hyena model and GPT-2.\n- The paper suffers from structural inconsistencies, unclear dataset construction details, and several typographical and grammatical errors in key sections, including the abstract and tables.\n- The related work section lacks a comprehensive review of existing literature, particularly in areas of mechanistic interpretability of large language models (LLMs).\n- Experiments lack depth in analysis, providing limited insight into why certain architectural changes lead to observed performance differences, and do not explore a broader range of existing datasets to validate findings.\n- Inconsistencies in experimental results and reporting, such as the unexplained loss metrics in section 6.5, need addressing to bolster the credibility of the results.\n\n**Questions**\n- Could you clarify the specific motivations and problem formulations that led to the development of the hybrid T HEX model?\n- What distinguishes the T HEX model from its components, GPT-2 and Hyena, and what are the advantages of this hybrid approach?\n- Why is there a lack of in-depth analysis or interpretation of the experimental results regarding the specific effects of architecture modifications?\n- Could an illustration of the LOLAMEME framework be provided to aid in understanding its structure and role within the research?\n- How can the experimental settings be improved to more reliably reflect model behaviors such as memorization and in-context learning, and why were these settings chosen?",
        "5_5": "**Summary**\nThe paper introduces LoLaMeMe, a framework aimed at mechanistic evaluation of language models, particularly focusing on logical reasoning and memory. LoLaMeMe is designed to generate synthetic datasets with varying complexities to evaluate the models' performance. The framework includes a hybrid architecture, T Hex, which is shown to outperform GPT-2 and Hyena on the proposed tasks. However, the paper lacks a comprehensive evaluation across different datasets and architectures, which raises questions about its generalizability and scalability. Additionally, concerns are raised regarding the novelty of the proposed framework and the lack of thorough comparisons with existing benchmarks.\n\n**Strengths**\n- The paper addresses an important and timely topic in the evaluation of language models, focusing on mechanistic interpretability and the creation of a new framework.\n- It introduces a novel dataset and task design, which is crucial for benchmarking and advancing research in this field.\n- The inclusion of a new model architecture, T Hex, is a significant contribution, and its performance evaluation across different tasks is thorough and insightful.\n- The paper is well-structured and easy to follow, with clear explanations and a logical flow of ideas.\n- The proposed framework effectively incorporates logical reasoning and memory challenges, enhancing the depth and variety of the evaluations conducted.\n\n**Weaknesses**\n- The paper lacks a thorough evaluation of the proposed framework across a broader range of tasks and architectures, which limits the understanding of its generalizability and applicability.\n- The creation of synthetic datasets raises concerns about their realism and relevance to practical scenarios, which may affect the validity of the results obtained.\n- There is a lack of detailed analysis on the impact of different hyperparameters and architectural choices, such as the number of global variables, which could influence the performance and scalability of the models.\n- The paper does not adequately discuss the limitations of the proposed framework, nor does it provide a comparative analysis with existing benchmarks or frameworks, which is essential for establishing its effectiveness.\n- The novelty of the proposed framework is questioned, with some reviewers suggesting that it builds heavily on existing frameworks without sufficient differentiation or innovation.\n- The paper contains some inaccuracies and potential oversights in its literature review and experimental design, which could undermine the credibility and reliability of the findings.\n\n**Questions**\n- Can the authors clarify the choice of using synthetic datasets and discuss the potential limitations and biases this may introduce in the evaluation results?\n- How does the proposed framework compare with existing benchmarks and frameworks in terms of task coverage and evaluation metrics?\n- What are the specific challenges and considerations when scaling up the proposed framework to larger, more complex datasets or different types of language models?\n- Could the authors provide a more detailed analysis of the impact of different hyperparameters and architectural choices on the performance of the models?\n- How does the proposed framework address the issue of generalizability, and can it be applied to real-world datasets or scenarios?\n- In light of the concerns about the novelty of the proposed framework, can the authors elaborate on the unique contributions of their work and how it advances the state-of-the-art in mechanistic interpretability research?",
        "5_3": "**Summary**\nThe paper introduces LoLaMeMe, a dataset designed to evaluate mechanistic interpretability in language models by incorporating logical reasoning and variable memorization tasks. The dataset is divided into two main tasks: logical reasoning over memorized facts (LoLa) and memorization of facts (MeMe). The authors test various models including GPT-2, GPT-3.5, and a Transformer Hex architecture, comparing their performance on this new dataset. The study also includes a new model called T Hex, which shows promising results, particularly in logical reasoning tasks. The paper also explores the influence of pretraining on model performance and introduces a new benchmark, LoLaMeMe, to assess models' ability to perform complex logical operations and variable handling.\n\n**Strengths**\n- The paper is well-written, clear, and easy to follow, making it accessible to a broad audience.\n- The introduction of the LoLaMeMe benchmark is significant, providing a new dataset to assess the performance of various models in mechanistic interpretability.\n- The authors present a comprehensive analysis of the dataset, including detailed task descriptions and a thorough evaluation of model performance across different tasks.\n- The experiments are well-designed, and the paper includes a variety of baselines to ensure a robust evaluation of the proposed methods.\n- The inclusion of a Transformer Hex model that outperforms other models on certain tasks adds value to the research.\n- The paper effectively compares the performance of different models on the LoLaMeMe benchmark, providing insights into the strengths and limitations of various architectures.\n\n**Weaknesses**\n- The paper lacks a clear and focused problem statement, making it difficult to understand the main objective and contributions of the research.\n- There is an inconsistency in the use of terms such as \"mechanistic interpretability,\" which could be clarified to avoid confusion.\n- The paper does not include a detailed description of the Transformer Hex model, specifically the architecture and training process used.\n- There is a lack of clarity in the experimental setup, including the selection of baseline models and the specific tasks used in the experiments.\n- The evaluation metrics used are not well-defined, and the paper does not provide a comprehensive analysis of the results.\n- The paper contains minor errors and typos, which could be corrected to improve the overall quality of the manuscript.\n- The novelty of the LoLaMeMe benchmark is questioned, as similar datasets have been proposed in prior works.\n- The paper does not address the scalability of the LoLaMeMe dataset to larger models and does not include results on larger models such as LLaMA and Vicuna.\n\n**Questions**\n- Could you clarify the main objective and contributions of the paper to ensure a clear understanding of the research?\n- What is the definition of \"mechanistic interpretability\" as used in the paper?\n- Can you provide a detailed description of the Transformer Hex model, including its architecture and training process?\n- Could you clarify the selection of baseline models and the specific tasks used in the experiments?\n- How are the evaluation metrics defined, and can you provide a more comprehensive analysis of the results?\n- What is the novelty of the LoLaMeMe benchmark compared to other similar datasets?\n- Can you provide results on larger models such as LLaMA and Vicuna to evaluate the scalability of the LoLaMeMe dataset?\n- How does the LoLaMeMe benchmark compare to other datasets in terms of difficulty and complexity?\n- Can you provide a more detailed explanation of the experimental setup, including the training and testing procedures for the models?"
    },
    "BoLqnXEdSE": {
        "gold": "**Summary**\nThis paper introduces a novel fairness measure named probable demographic parity, aimed at handling continuous sensitive attributes like weight or age. This measure fundamentally critiques and seeks to improve upon the deficiencies of the Generalized Demographic Parity (GDP) measure by Jiang et al., which fails to account adequately for small population segments. Unlike GDP, the proposed method employs a sampling strategy ensuring each segment has a substantial measure, controlled by the hyperparameter alpha, enhancing the fairness measurement's sensitivity to smaller groups. The approach's theoretical basis is discussed, emphasizing its ability to provide a more accurate approximation of demographic parity than existing measures. However, the paper also faces criticism for lacking in thorough experimental validation against various baselines, and gaps in theoretical coverage that could potentially limit the reader\u2019s grasp of the proposed method's reliability and scope.\n\n**Strengths**\n- The paper tackles the underexplored area of fairness considering continuous sensitive attributes, presenting an interesting extension of demographic parity (DP).\n- The authors introduce a new measure that extends DP to address both mean prediction disparity and maximum prediction disparity, offering a potential balance between these two metrics.\n- Mathematically, the concept and the formulation are robust and clearly articulated, with Theorem 1 showing that for discrete attributes, the new definition aligns with traditional DP.\n- Empirical techniques for measuring the proposed metric are employed, highlighting benefits in computational complexity.\n- The paper involves a good discussion on feasible solutions and the modifications needed for quantized sensitive attributes under specific conditions.\n\n**Weaknesses**\n- The paper fails to adequately explain or justify the choice of alpha, a parameter crucial to their proposed measure.\n- There is a significant lack of experiments demonstrating the superiority of the proposed metric over existing methods like mean prediction disparity and maximum prediction disparity.\n- Insufficient related work discussion, particularly omitting existing literature that studies metrics like equalized odds for continuous sensitive attributes, which could enhance the paper's depth.\n- The claimed advantages of the proposed metric are not empirically validated against any established baselines.\n- Presentation of the theory, particularly around the assessment of underestimation and overestimation issues (as seen in Figure 1), could be better structured for clarity.\n- Theoretical aspects such as the conditions for convergence and the validation procedure for selecting alpha remain incomplete or unclear.\n\n**Questions**\n- How do you choose the appropriate alpha for the proposed metric, and what impact does it have?\n- Can you enhance the experimental section to demonstrate that your proposed metric indeed performs better than both mean prediction disparity and maximum prediction disparity?\n- Could you discuss and compare your metric against other contemporary approaches, such as distance covariance-based metrics cited from the literature (e.g., references [1], [2])?\n- How can this metric be effectively scaled or adapted to scenarios involving multiple continuous sensitive attributes?\n- Could you explain the practical implications and limitations of your method, particularly in real-world applications where sensitive attributes vary widely?",
        "5_5": "**Summary**\nThe paper introduces \"Probable Demographic Parity,\" a novel metric for assessing fairness in machine learning models with continuous sensitive attributes. This metric measures the maximum disparity of predictions within probable segments of the sensitive attribute, rather than using mean or maximum disparities. The approach aims to balance the strengths of existing metrics like maximum and mean disparities by considering only probable segments with a minimum probability threshold. The paper also claims to improve upon previous metrics by reducing the effect of outliers and providing a more consistent estimation error. However, the paper suffers from issues such as unclear definitions, lack of detailed theoretical backing, and inadequate experimental results, making it difficult to assess the validity and effectiveness of the proposed metric.\n\n**Strengths**\n- The proposed metric is straightforward and intuitive, aiming to reduce the effect of outliers and providing a more consistent estimation error compared to previous methods.\n- The paper is well-structured and easy to follow, providing a clear and logical flow that enhances understanding.\n- The authors have provided a good motivation for the need for a new metric and have addressed the issue of continuous sensitive attributes in machine learning.\n\n**Weaknesses**\n- The definition of probable demographic parity and the concept of probable segments are unclear and not well-defined, leading to potential confusion and misinterpretation.\n- The theoretical analysis provided is insufficient, lacking detailed proofs and clear explanations that could substantiate the claims made about the metric's properties and advantages.\n- Experimental results are limited and lack sufficient statistical significance to convincingly support the proposed metric. The results also do not convincingly show that the proposed metric outperforms existing metrics.\n- The paper could benefit from a more detailed discussion on the selection and tuning of parameters like alpha, which is critical for the application of the proposed metric.\n- The connection between probable demographic parity and traditional demographic parity is not convincingly established, which raises questions about the metric's validity and relevance in practical scenarios.\n- The paper does not sufficiently discuss related work or provide a comprehensive comparison with existing fairness metrics, which could have strengthened the context and motivation for the proposed metric.\n\n**Questions**\n- Could you clarify the definition of probable demographic parity and provide a detailed explanation of the concept of probable segments?\n- What are the specific theoretical properties that the proposed metric aims to achieve, and how are these properties supported by the provided analysis?\n- Can you provide more detailed experimental results, including statistical significance and a comparison with existing fairness metrics?\n- How is the parameter alpha selected and tuned in practical applications of the proposed metric?\n- Could you discuss the practical relevance and applicability of the proposed metric in real-world scenarios, particularly in comparison to existing metrics?\n- What are the limitations of the proposed metric, and how does it compare to other fairness metrics in terms of computational complexity and effectiveness?",
        "5_3": "**Summary**\nThe paper introduces a new metric, \"probable demographic parity,\" aimed at enhancing fairness assessment in machine learning models by considering probable segments of a continuous sensitive attribute. This approach claims to mitigate issues associated with traditional fairness metrics by focusing on segments with higher probability thresholds, thus avoiding underestimation or overestimation problems. The authors propose a method to estimate probable demographic parity and argue for its connection with demographic parity, although this relationship appears more like a heuristic than a rigorous theoretical backing. The metric has been evaluated against existing fairness metrics, showing some improvements in fairness and accuracy, though its novelty and theoretical grounding are questioned.\n\n**Strengths**\n- The paper addresses a relevant and challenging problem in the field of fairness in machine learning, specifically focusing on continuous sensitive attributes.\n- The proposed metric, probable demographic parity, is innovative as it considers segments of continuous sensitive attributes with higher probability thresholds, which may help in avoiding underestimation or overestimation problems associated with traditional fairness metrics.\n- The manuscript is well-structured, with clear definitions and explanations of the proposed method, making it accessible and easy to follow.\n- The paper includes a thorough theoretical analysis of the proposed metric, exploring its properties and relationship to demographic parity.\n- Experimental results are provided, showing that the new metric can perform better than traditional metrics in terms of fairness and accuracy.\n\n**Weaknesses**\n- The paper lacks a rigorous theoretical foundation for the proposed metric, particularly in defining and explaining the connection between probable demographic parity and demographic parity.\n- The relationship between probable demographic parity and demographic parity is not convincingly established, and it seems more like a heuristic than a theoretically grounded connection.\n- The experimental setup is limited, with only two datasets used, which may not sufficiently demonstrate the generalizability of the proposed metric.\n- There is a lack of clarity on how the proposed metric improves upon existing fairness metrics, particularly in terms of its practical implementation and real-world applicability.\n- The paper does not sufficiently discuss related work, particularly other recent developments in fairness metrics for continuous sensitive attributes.\n- The manuscript has several presentation and grammar issues that need to be addressed for better clarity and professional quality.\n\n**Questions**\n- Can the authors clarify the connection between probable demographic parity and demographic parity, especially in terms of theoretical backing?\n- How does the proposed metric improve upon existing fairness metrics in practical scenarios, and can more detailed examples or case studies be provided?\n- Could the authors discuss how the metric is calculated and implemented in real-world applications, particularly in terms of computational efficiency and scalability?\n- Are there any plans to include more datasets in the experimental evaluation to better demonstrate the generalizability of the proposed metric?\n- How does the proposed metric address potential issues of bias in the estimation of segments with higher probability thresholds, and how does it ensure fairness in the presence of such biases?"
    },
    "c1QBcYLd7f": {
        "gold": "**Summary**\nThis paper introduces a novel model called GraDK, which leverages graph neural networks (GNN) to enhance the modeling of influence kernels in marked point processes. Using GNN, the proposed model effectively captures various interactions between marks treated as nodes within a graph. This is achieved through a convolution of kernels over the time domain and graph structure, permitting flexible modeling of inter-event-category dependence. The paper highlights the superiority of its method through extensive simulations and empirical data, indicating enhanced predictive performance over existing methods. The method's ability to model non-stationary and multi-hop interactions is validated through real-world datasets and synthetic data analyses.\n\n**Strengths**\n- The paper introduces an innovative approach integrating graph neural networks (GNNs) with kernel-based influence models, offering potentially transformative insights into point process modeling over graphs.\n- The numerical experiments presented are well-executed, demonstrating the model\u2019s effective predictive performance across both synthetic and actual datasets.\n- The paper is very well-written, facilitating clarity in the presentation of concepts and ease of comprehension for the reader.\n- The scalability of the training algorithm, which linearly scales with data size, enhances the practical applicability of the proposed model.\n- The use of localized graph filters improves the scalability and practical implementation of the model when applied to large graph structures.\n\n**Weaknesses**\n- The paper would benefit from a deeper engagement with the foundational literature, particularly concerning existing GNN and kernel-based methods. Specifically, discussions on how this approach uniquely advances over methodologies documented in references like Learning neural point processes with latent graphs, Graph neural point process for temporal interaction prediction, etc., are needed.\n- The novelty of the proposal is questionable, given the existing body of work on GNNs and point processes. The incremental nature of the technical contribution needs a clearer articulation.\n- Explanations on graph construction and the criteria for node and edge definitions are lacking detailed clarity, particularly concerning their applicability across various real-world datasets.\n- The logic behind the observed minimal improvement in likelihood when compared to powerful baselines like transformers and graph attention mechanisms is not convincingly addressed, casting doubt on the statistical significance of the results reported.\n- The evaluation framework is incomplete without robust baseline comparisons. Significant existing models and methods seem omitted from comparative analysis, which could potentially skew the perceived effectiveness of the proposed model.\n- The intensity function's potential negativity, even with the use of log-barrier methods, raises concerns about the theoretical soundness and practical safety of the model.\n\n**Questions**\n- 1. Could you elaborate on the use of the FullyNN model in your experiments as a marked point process model, specifically in relation to handling marks of each event as outlined by Omi et al., 2019?\n- 2. On page 4, concerning the orthogonality of basis functions and their decomposition using a fully-connected neural network, how is uniqueness ensured without imposing orthogonality?\n- 3. What specific types of network interactions are best modeled by this approach, and what are the inherent limitations in complex graph structures, particularly as indicated by performance anomalies observed with the increase in the number of nodes?\n- 4. In light of existing works cited (such as Fang et al., 2023; Dong et al., 2022), how does your model distinctively incorporate or advance over the concepts of adjacency matrices and heterogeneity in nodes?\n- 5. Given that your model uses a combination of conventional methods noted, could you further discuss the independent contributions and theoretical advancements your approach offers to justify its novelty and effectiveness?",
        "5_5": "**Summary**\nThe paper introduces a novel method for modeling point processes over graphs, utilizing a graph-based influence kernel to capture the dynamics of event interactions. This kernel is constructed using graph neural networks (GNNs), which allows for capturing the influence between different types of events. The authors provide a detailed analysis of the model's performance across synthetic and real-world datasets, showing competitive results against existing baselines. However, the paper suffers from several shortcomings, including unclear notations, poor writing quality, and an incomplete exploration of related works. The method's complexity and the justification for the choice of loss function and GNN architectures remain unclear, contributing to a lack of transparency and comparability with other models.\n\n**Strengths**\n- The paper introduces a novel method for modeling point processes over graphs using graph neural networks, which allows for capturing event interactions and influences between different types of events.\n- The paper demonstrates the effectiveness of the proposed model through extensive experiments on synthetic and real-world datasets, comparing it favorably against existing baselines.\n- The method incorporates a graph-based influence kernel to capture the dynamics of event interactions, which is a significant advancement in the field of point process modeling.\n\n**Weaknesses**\n- The paper suffers from poor writing quality, with many unclear notations and complex expressions that hinder the understanding of the method.\n- The complexity of the model is not adequately justified, particularly the choice of loss function and the selection of GNN architectures, which are crucial for the model's performance.\n- There is a lack of comprehensive related work discussion, particularly concerning graph-based point process models, which could provide a clearer context for the proposed method.\n- The paper does not provide a clear explanation of the choice of graph neural networks (GNNs) over other types of neural networks and fails to discuss the scalability of the proposed method.\n- There is an absence of detailed analysis of the computational complexity and time complexity of the proposed method, which is essential for practical applications.\n- The experimental evaluation is limited in scope and does not sufficiently demonstrate the robustness and generalization capabilities of the proposed method.\n- The paper contains several typographical errors and inconsistencies that need to be addressed to improve clarity and professionalism.\n\n**Questions**\n- Could the authors clarify the choice of the loss function and the selection of GNN architectures, providing a detailed justification for these decisions?\n- Why was the GNN architecture chosen over other types of neural networks, and how does it affect the performance of the model?\n- Can the authors provide a detailed analysis of the computational complexity and time complexity of the proposed method?\n- How does the proposed method compare with other graph-based point process models in terms of scalability and performance?\n- Could the authors discuss the limitations of the current method and provide insights into potential future research directions?\n- What are the practical applications of the proposed method, and how can it be effectively used in real-world scenarios?",
        "5_3": "**Summary**\nThe paper explores a novel integration of Graph Neural Networks (GNNs) with point processes to model temporal events over graphs. The authors propose a new kernel function that combines a GNN with a localized graph filter basis, aiming to capture the intricate relationships between events within a graph structure. This model is supported by a theoretical analysis and experimental validations across various datasets, showing the potential of this approach in enhancing the predictive capabilities of point process models. Despite the contributions, concerns are raised regarding the novelty of the approach, the choice of evaluation metrics, and the clarity of some theoretical formulations. The paper attempts to bridge the gap between point processes and graph neural networks, but it faces challenges in demonstrating the significant advantages of the proposed method over existing models.\n\n**Strengths**\n- The paper introduces an innovative approach by integrating Graph Neural Networks (GNNs) with point processes, which is a novel application of GNNs.\n- The methodology presented is theoretically sound, with a clear and comprehensive theoretical analysis provided.\n- The paper is well-written, with a logical flow that enhances readability and understanding.\n- The use of GNNs to model the influence kernel is both practical and theoretically interesting, potentially opening up new avenues for research in this area.\n- The experiments conducted are extensive, covering both synthetic and real-world data, and demonstrate the method's effectiveness.\n\n**Weaknesses**\n- The paper lacks a detailed description of the GNN architecture used, which is crucial for understanding the implementation details and the model's behavior.\n- The novelty of the approach is questionable as it closely resembles previous works, with the main difference being the use of a localized graph filter basis.\n- There are concerns regarding the choice of evaluation metrics and the results presented, which may not convincingly support the claims made in the paper.\n- The paper does not adequately address the computational complexity of the proposed method, which is a significant drawback given the resource-intensive nature of GNNs.\n- Some theoretical assumptions and notations are unclear or inadequately explained, which could lead to confusion about the model's implementation and results.\n- The paper does not provide a clear comparison with existing methods, particularly those that also utilize GNNs for modeling point processes.\n\n**Questions**\n- Can the authors provide a detailed description of the GNN architecture used in the experiments?\n- How does the proposed method handle the computational complexity introduced by the use of GNNs?\n- What is the specific rationale behind the choice of evaluation metrics, and can the authors clarify the results presented in the tables?\n- Could the authors explain the unclear assumptions and notations mentioned in the paper, such as the use of \"d\" and the assumptions related to the model's parameters?\n- How does the proposed method compare with existing point process models that use GNNs, and what are the advantages of this new approach?\n- In the context of the experiments, how do the authors ensure that the learned graph kernel accurately represents the underlying dependencies in the data?"
    },
    "Dw6y6bEtXm": {
        "gold": "**Summary**\nThe paper presents a novel framework designed to generate high-resolution data from coarse-grained measurements using surrogate models that integrate physical priors. The models leverage an encode-process-decode approach, supported by a training routine that includes physics-informed losses, to ensure fidelity to underlying physical laws governing the dynamics of the system. Employing U-Net and Fourier neural network models, the proposal aims to apply super-resolution techniques to dynamically model systems described by partial differential equations (PDEs). Despite efforts towards clarity and experimental validation across various PDE contexts, the paper struggles with clear articulation of objectives, comparison with non-Fourier based methods, and the overall organization.\n\n**Strengths**\n- The paper is innovative in addressing real-world applications with relatively under-applied surrogate physics models and proposes a novel training framework that is structured in two phases for improved predictive performance.\n- The methods introduced in this work are justified through experiments over multiple PDE-governed systems, indicating the method's effectiveness in various contexts.\n- The authors have documented their training routine thoroughly, enhancing the reproducibility, and made the source code available, adding to the academic transparency.\n- The creativity in employing coarse-grained data alongside physics to achieve super-resolution, making the study relevant in fields where high-resolution data might not be readily available.\n\n**Weaknesses**\n- The paper suffers from organizational and clarity issues, making it difficult to understand the proposed methodology, particularly the definitions, the role and implementation of the transition module, and the down-sampling operator. Additionally, the paper omits explanations for choices like the use of U-Net architecture and lacks clear formulae for loss terms and metrics.\n- It seems that the relevance of predicting coarse-grained observations lacks justification since simulations in practical scenarios often involve high-resolution data.\n- Comparisons with other state-of-the-art methods are not sufficiently broad, focusing primarily on FNO-based methods without considering other contemporary neural operator methods. Also, performance in zero-shot super-resolution cases is unaddressed.\n- The results presented show inconsistencies, for instance, where baselines like PINO* achieve lower reconstruction errors, questioning the superiority of the proposed method. Practical usability and the accuracy level necessary for scientific applications also remain unexplored.\n\n**Questions**\n- Could the authors clarify what specific problems the proposed method aims to address, particularly regarding the practical necessity for coarse-grained prediction models?\n- What is the rationale behind employing the U-Net architecture for the encoder, given the availability of more recent and potentially more effective architectures like UNet++ or Transformer?\n- How does the \"hard encoding\" of \\( \\tilde{o} \\) into \\( \\hat{u}_t \\) function precisely? If it involves dense coupling between high-res and low-res solutions, how does this design decision impact the efficacy of improving high-resolution predictions from low-resolution observations?\n- Could the authors delve deeper into the impact of each term in their proposed loss function and elucidate how changes in the output resolution of \\( f_{\\theta} \\) influence computational costs and prediction accuracy in comparison to baseline methods?\n- There is a reliance on physics loss defined by a fourth-order central difference scheme and Runge-Kutta time discretization, but the paper does not discuss the range of problems where this approach is applicable. Could the authors provide insights on this aspect?\n- The function of \\( f_{\\theta} \\) and its specific role in employing higher-order finite difference techniques require further elucidation. Is there a finite difference operator embedded, or is there a special transformation applied that imitates such an operator?",
        "5_5": "**Summary**\nThe paper introduces the Physics-Informed Coarse-grained data Learning (PICL) framework, designed to address the challenges of modeling physical systems with coarse-grained data. PICL integrates physics information through a learnable fine-grained state representation and employs a two-stage fine-tuning period to enhance model performance. The framework comprises an encoding module for generating the fine-grained state and a transition module for predicting subsequent states. The proposed method is evaluated across several PDE-governed physical systems, demonstrating improvements in predictive accuracy. However, the paper faces criticism for its lack of clarity in methodological descriptions, insufficient experimental details, and limited novelty in comparison to existing approaches.\n\n**Strengths**\n- The paper is clearly written, with well-defined problems and goals, making it easy to understand and follow.\n- The use of physics-informed learning is innovative and effectively utilizes physics loss to enhance the reconstruction ability of the encoding module and the generalization ability of the transition module.\n- The framework is well-structured, with a clear description of the physics-informed loss function, which is beneficial for understanding and replicating the methodology.\n- The authors have provided a thorough evaluation of the framework using various datasets, demonstrating its effectiveness in predicting future coarse-grained observations.\n- The approach is supported by well-conducted experiments, showing superior performance compared to other baseline models.\n\n**Weaknesses**\n- The paper lacks a detailed description of the methodology, particularly the encoding module and the transition module, which are crucial for understanding the framework's operation.\n- The experimental setup and results presentation are unclear and inadequately detailed, making it difficult for readers to assess the validity and significance of the results.\n- There is insufficient comparison with state-of-the-art methods, and the related work section is not comprehensive, lacking important references and discussions.\n- The novelty of the approach is limited as the proposed framework closely resembles existing methods, such as PINNs, and lacks sufficient differentiation or justification for its unique contributions.\n- The paper contains typographical errors and unclear notation, which can hinder comprehension and detract from the overall quality of the manuscript.\n- The computational cost associated with the proposed method is not discussed, which is an essential consideration for practical applications.\n\n**Questions**\n- Could you elaborate on how the encoding module is specifically designed to handle coarse-grained data and generate a fine-grained state representation?\n- What are the specific advantages of using physics-informed loss in the encoding module, and how does it contribute to the overall performance of the framework?\n- How does the proposed framework compare to other physics-informed learning methods in terms of performance and computational efficiency?\n- Can you provide more details about the experimental setup, including the datasets used, the evaluation metrics, and the specific comparisons made with other methods?\n- How do the authors justify the use of a physics-informed loss function in the transition module, and what are the theoretical or empirical underpinnings of this approach?\n- Could the authors discuss the computational cost associated with the proposed method and compare it to other methods to provide a clearer picture of its practical applicability?",
        "5_3": "**Summary**\nThis paper introduces a novel framework named Physics-Informed Coarse-grained data Learning (PICL) aimed at improving the prediction of physical systems under coarse-grained data conditions. The framework employs a two-stage training process where initially, both the encoder and transition modules are trained together with a focus on data loss, followed by a second stage where the transition module is fine-tuned using physics loss, and the encoder is fine-tuned using data loss. This approach is designed to enhance predictive capabilities in scenarios where only coarse-grained data is available. The framework has been tested across several physical systems, showing improvements over traditional data-driven methods. However, the paper is criticized for its lack of novelty, as similar methodologies have been previously explored. Additionally, there are concerns regarding the clarity of the writing, the selection of datasets, and the overall impact of the framework on the scientific community.\n\n**Strengths**\n- The paper is well-structured, making it easy to follow and understand the methodology and results.\n- The proposed framework is evaluated on a variety of physical systems, demonstrating its versatility and broad applicability.\n- The paper is well-written, with clear explanations and a straightforward presentation of results.\n- The framework introduces a novel approach to model physical systems, particularly in scenarios with coarse-grained data.\n- The experimental results presented are encouraging, showing potential for the framework in various physical systems.\n- The concept of using physics loss for model training is innovative and has not been thoroughly explored in previous literature.\n\n**Weaknesses**\n- The paper lacks a clear explanation of the physical significance and the necessity of using coarse-grained data, which is crucial for understanding the problem and the proposed solution.\n- The related work section is insufficiently detailed, making it difficult to understand the novelty and contributions of the proposed framework.\n- The framework's design and training process are not fully justified, particularly the use of two-stage training and the rationale behind the specific loss functions used.\n- There is a lack of novelty as similar frameworks have been previously proposed in literature, and the paper does not adequately differentiate its approach from existing methods.\n- The paper does not provide sufficient experimental results or comparisons with baseline models, making it difficult to evaluate the effectiveness of the proposed framework.\n- The writing style is inconsistent and could be improved for better clarity and readability.\n- The selection of datasets is questionable, particularly the use of datasets like the Shallow Water dataset, which may not adequately represent the conditions under which the framework is intended to perform.\n\n**Questions**\n- 1. Can the authors provide more details on the physical significance and necessity of using coarse-grained data in their framework?\n- 2. How does the proposed framework compare with existing physics-informed frameworks, and what are the main advantages of this approach?\n- 3. Could the authors explain the rationale behind the two-stage training process and the specific loss functions used in the framework?\n- 4. What are the specific contributions of the framework, and how does it differ from existing methodologies?\n- 5. Can the authors provide more experimental results and comparisons with baseline models to better demonstrate the effectiveness of the proposed framework?\n- 6. How does the framework handle different types of physical systems, such as nonlinear systems, and what are the limitations of the proposed method?\n- 7. The paper mentions the use of coarse-grained data; could the authors clarify what this term means in the context of their framework and provide more details on how it is used in the experiments?"
    },
    "f7PmO5boQ9": {
        "gold": "**Summary**\nThis paper introduces DynaEval, a dynamic interaction-based evaluation framework tailored for large language models (LLMs) within game-theoretical contexts. Inspired by extensive games with perfect information (EGPI), DynaEval incorporates an interaction process structured through selection, interaction, recording, and circulation. The framework is characterized by introducing fairness through anonymity and synchronous communication, and stability via independent multiple interactions. Central to its implementation are a referee and a message pool ensuring fair and stable assessments. The authors also make use of four specific game scenarios to test and compare various LLMs. While the application of game theory to LLM evaluation poses an intriguing approach, concerns are raised about the novelty and clarity of the proposed conditions and their practical contribution to the field.\n\n**Strengths**\n- The paper addresses the significant and less-explored problem of evaluating LLMs with fairness and stability guarantees, making it highly relevant to the ICLR conference.\n- The paper is well-written and easy to read, providing clear and theoretically grounded approaches.\n- Novelty is introduced by linking the interaction process of LLMs to extensive games with perfect information (EGPI), and attempting to move beyond static evaluation frameworks by emphasizing dynamic interaction scenarios.\n- The authors provide straightforward, well-executed experiments that demonstrate a gap between static and dynamic uses of LLMs, highlighting practical implications for real-world applications.\n\n**Weaknesses**\n- The technical contribution appears limited as the methods for ensuring fairness and stability are perceived as standard, with no substantial novel insights or practical implementation specifics tailored to dynamic interactions.\n- There is a lack of clarity and sufficient details on key concepts such as the referee, message pool, and task rules, which play critical roles in the evaluation framework.\n- The connection made between DynaEval and EGPI is underdeveloped and not convincingly justified. It\u2019s unclear how this theoretical framework concretely benefits the proposed evaluation methodology.\n- The paper seems to lack a strong comparative discussion of the proposed methods against existing evaluation techniques, particularly in demonstrating the superiority of dynamic over static evaluations.\n- Statistical significance issues arise, with the results presented (e.g., overlapping distributions, negligible performance differences) not convincingly supporting the claims made.\n- Elements of the paper, including crucial definitions and equations, are not explained well enough, potentially confusing readers about their purpose or relevance.\n\n**Questions**\n- How does DynaEval specifically evaluate the 'ability of interaction' beyond the interaction between LLMs, especially in terms of engaging with human users?\n- Can you provide more details or a clearer explanation of the task rules, and how they influence the fairness and stability of LLM evaluations?\n- In what ways does DynaEval manage to address the dynamic nature of LLM interactions better than static evaluation methods?\n- Could you clarify the role and operational framework of the referee in ensuring unbiased performance evaluation?\n- In the context of IDIOMS SOLITAIRE, which specific abilities are being tested? Is the capability related truly to interaction, or merely to the breadth of data exposure?\n- The source code link provided does not work. Could this be updated to allow for replication and further study of your findings?\n- Is the stability condition introduced appropriate and reliable for evaluating convergence among differing LLMs?",
        "5_5": "**Summary**\nThe paper introduces DynaEval, a novel dynamic interaction-based LLM evaluation framework, which utilizes a message pool and an LLM-based referee to ensure fairness and stability in evaluating LLMs' performance across various tasks like Code Generation and Review, Machine Translation, and Idiom Solitaire. The framework operates by breaking down interactions into rounds, allowing for a structured evaluation process that maintains fairness and stability. Despite its innovative approach, the paper has been criticized for its lack of clarity, specifically in the definitions and methodologies used. The experimental results, while indicating the potential of DynaEval, are limited in scope and depth, lacking a comprehensive comparison with existing methods. The paper also does not sufficiently address the potential biases in the evaluation process and does not provide clear guidelines for task designers or users of the framework.\n\n**Strengths**\n- The paper introduces a novel dynamic interaction-based LLM evaluation framework, which provides a new perspective on LLM evaluation and offers an innovative approach to assess the capabilities of LLMs in dynamic real-world scenarios.\n- The framework's design is intuitive and effectively integrates the message pool and the LLM-based referee, ensuring fairness and stability in the evaluation process.\n- The experiments conducted demonstrate the potential of DynaEval in effectively evaluating the abilities of LLMs in dynamic interaction-based evaluation tasks.\n- The paper is well-written, making it accessible and easy to follow, which facilitates understanding of the complex concepts involved.\n\n**Weaknesses**\n- The paper lacks clarity in several sections, particularly in the definitions and methodologies used. For instance, the definition of the interaction process in Section 3.1 is unclear and needs further explanation.\n- The experimental results are limited in scope and depth, and the paper fails to provide a comprehensive comparison with existing methods, which undermines the robustness of the findings.\n- The paper does not adequately address potential biases in the evaluation process, which is crucial for ensuring the reliability and validity of the results.\n- There is a lack of clear guidelines for task designers or users of the framework, which could lead to confusion or misuse of the framework.\n- The paper's theoretical contributions, while innovative, are not sufficiently justified or explained, making it difficult to fully grasp the significance and implications of the research.\n\n**Questions**\n- Can you provide more detailed explanations for the definitions and methodologies used in the paper, particularly in Section 3.1?\n- How do you address potential biases in the evaluation process, and what measures are in place to ensure the reliability and validity of the results?\n- Could you provide a more comprehensive comparison with existing methods to better establish the effectiveness and novelty of DynaEval?\n- What are the specific guidelines for task designers or users of the framework, and how can they ensure proper implementation and utilization of the framework?\n- In terms of theoretical contributions, could you clarify the significance and implications of these contributions in the context of LLM evaluation?",
        "5_3": "**Summary**\nThe paper introduces DynaEval, a novel framework for evaluating Large Language Models (LLMs) in dynamic real-world scenarios using a dynamic game theory approach. DynaEval incorporates a message pool and a referee component to ensure fairness and stability in LLM evaluations. The framework is designed to handle various types of dynamic interactions between LLMs and external agents, assessing their performance across multiple tasks including idiom solitaire, public goods game, code generation, and machine translation. The authors claim that DynaEval offers a more comprehensive and adaptive evaluation method compared to traditional supervised signal-based approaches, enhancing the understanding of LLM capabilities in diverse and dynamic environments.\n\n**Strengths**\n- The paper introduces a novel evaluation framework, DynaEval, designed for dynamic interactions between LLMs and external agents, providing a more comprehensive approach to LLM assessment compared to traditional methods.\n- The use of a referee and a message pool to ensure fairness and stability in the evaluation process is a well-considered and logical design choice.\n- The paper is well-structured and clearly written, making it accessible and easy to follow, which is further supported by the inclusion of a detailed appendix for additional information.\n- DynaEval's flexibility in handling various tasks and its ability to support different interaction scenarios, such as symmetric and asymmetric games, are highlighted as significant strengths.\n- The paper presents a series of experimental results across multiple tasks, demonstrating the effectiveness of the proposed framework.\n\n**Weaknesses**\n- The paper lacks a thorough comparison with other dynamic evaluation frameworks, such as DICE and LLM-Eval, which could provide a clearer context and positioning of DynaEval within the existing landscape.\n- The experimental design is limited in scope, primarily focusing on a small set of LLMs and tasks, which may not adequately demonstrate the framework's generalizability across diverse real-world scenarios.\n- The motivation and necessity for a new framework are not convincingly argued, particularly in relation to the existing capabilities of traditional LLM evaluation frameworks.\n- The use of the term \"dynamic\" is somewhat misleading as the evaluation tasks described do not inherently involve dynamic interactions among LLMs.\n- The paper does not provide sufficient details on the specific implementation of the referee and the message pool, which are crucial components of the DynaEval framework.\n- There is a lack of detailed discussion on the potential biases and fairness issues that may arise in the evaluation process, particularly in the context of asymmetric interactions.\n\n**Questions**\n- Could you clarify the choice of tasks used in the experiments and the rationale behind selecting specific LLMs for these tasks?\n- How does DynaEval ensure fairness in scenarios where LLMs are interacting with external agents or other LLMs, and what measures are in place to mitigate potential biases?\n- In terms of the experimental design, could you provide more details on the specific settings used for each task and the number of interactions involved?\n- How does the framework handle asymmetric interactions, and what measures are taken to ensure that the evaluation is fair and unbiased?\n- What are the main differences between DynaEval and other existing evaluation frameworks such as DICE and LLM-Eval?"
    },
    "GAXedKmbFZ": {
        "gold": "**Summary**\nThe paper introduces Disco-Bench, a new benchmark dataset focused on discourse phenomena, accommodating nine tasks. These tasks span language understanding, translation, and generation, with an offering of multiple datasets, including a diagnostic set and a large unlabeled dataset for language model pretraining. Primarily featuring Chinese (both modern and classical) and English data, the benchmark evaluates several existing models like BERT, RoBERTa, GPT-3.5, and GPT-4, showing specifics of their performance across different tasks. Although the benchmark\u2019s design and intended contributions are noteworthy, the paper faces criticism regarding the vague presentation of data, unclear copyright and ethical considerations, and insufficient methodological details which raises concerns on the experimental approaches and claims.\n\n**Strengths**\n- The paper highlights an underexplored area by focusing on benchmark datasets that cover multi-sentence and document-level phenomena, alongside traditional single sentences or pairs.\n- It introduces a large, diverse benchmark comprising various discourse-related tasks and presents results showing the limitations of both large and smaller pre-trained models.\n- The creation of a large corpus of Chinese+English text in the literary domain and the demonstration that continued pre-training on this corpus can mitigate some limitations is noteworthy.\n- It is commendable that the paper does not only integrate existing datasets but provides new datasets, specifically focusing on the literary domain, and also introduces a diagnostic test suite for assessing model performance on discourse phenomena.\n\n**Weaknesses**\n- The paper suffers from vague descriptions and lacks clarity in multiple sections including the annotation and alignment processes, how datasets were constructed, and the treatment of copyright and ethical concerns.\n- There is no clear rationale provided for the methodological choices, such as why certain datasets were chosen or created, and how they compare with existing datasets.\n- Quality assurance steps are mentioned, but the specifics such as the double annotation confirmation and the profiles of annotators are unclear.\n- The paper fails to provide a qualitative analysis to support its conclusions, particularly the effects observed in Table 5 where specific pretraining seems to impact model performance on certain tasks.\n- Some existing benchmarks like Super GLUE or LOT already cover similar tasks, and the paper does not sufficiently differentiate its benchmarks from these in terms of novelty or utility.\n\n**Questions**\n- Could the authors clarify whether smaller models encounter issues due to text length and if strategies like truncation or other mechanisms for handling long inputs were employed?\n- Why were the specific six cohesion properties chosen for the diagnostic test suite, and why are these properties important?\n- In the discussion of inter-annotator agreement scores and model performance differences, is there an explanation for the dramatic differences in performance on similar tasks noted by other studies, such as those referenced by Song et al. (2020)?\n- How was the manual alignment of chapters in the Novel Translation task performed, and does \"manually aligned\" imply that millions of alignment annotations were actually completed by the authors?\n- What portion of the performance difference noted in Table 5 between vanilla models and Disco-Bench pretrained models is attributable solely to domain or language mismatches?",
        "5_5": "**Summary**\nThe paper introduces Disco-Bench, a benchmark designed to assess the contextual modeling abilities of language models, focusing on discourse phenomena such as cohesion and coherence. The benchmark comprises nine document-level datasets in Chinese and English, supplemented by a diagnostic test suite to gauge the extent of discourse information internalized by models. The benchmark covers a range of tasks including understanding, translation, and generation, with the datasets being constructed from literature domains. The paper further explores the impact of fine-grained pretraining on these models, indicating improvements in discourse modeling. However, concerns are raised about the novelty of the benchmark, the diversity of the datasets, and the clarity of its evaluation metrics.\n\n**Strengths**\n- The paper is well-written, making it easy to follow and understand.\n- The proposed benchmark covers a variety of tasks, including understanding, translation, and generation, which helps to evaluate models' contextual understanding.\n- The benchmark is designed to assess intra-sentence contextual properties, which is a crucial aspect in natural language processing (NLP).\n- The paper provides a comprehensive analysis of different models, including standard Transformer, pretrained models, and large language models (LLMs), which gives a good overview of model performance across various tasks.\n- The inclusion of a diagnostic test suite allows for a deeper understanding of the models' ability to internalize discourse information.\n\n**Weaknesses**\n- The novelty of the benchmark is questioned as it appears to be a collection of existing datasets with some modifications.\n- The diversity of the datasets is limited, primarily focusing on Chinese and English, which may not adequately represent the linguistic diversity of other languages.\n- The evaluation metrics used in the benchmark may not be adequate or robust enough to accurately measure the models' performance, particularly in tasks involving generation and translation.\n- There is a lack of detailed analysis on the construction of the datasets, particularly the criteria for selecting and processing the data.\n- The paper does not provide a comprehensive discussion on the limitations and potential biases of the benchmark.\n- The evaluation results are not thoroughly explained, making it difficult to interpret the significance of the findings.\n\n**Questions**\n- How was the benchmark dataset constructed, and what specific criteria were used for selecting and processing the data?\n- Can the authors provide more details on the evaluation metrics used in the benchmark and explain why these metrics were chosen?\n- What are the specific limitations and potential biases of the benchmark, and how do these affect the validity of the results?\n- Can the authors clarify the relationship between the benchmark and the Disco-Bench training dataset, and explain how the benchmark is designed to be challenging for models?\n- What are the reasons for the use of different metrics for evaluating the models, and can the authors provide a more detailed comparison of the metrics used?\n- How does the benchmark account for the diversity of linguistic structures and phenomena across different languages?",
        "5_3": "**Summary**\nThe paper introduces Disco-Bench, a benchmark designed to evaluate the contextual understanding of large language models (LLMs) by assessing their discourse modeling capabilities. The benchmark includes a set of tasks such as discourse detection, reasoning, and translation, covering both Chinese and English languages. It features a diagnostic dataset that tests model's ability to discern cohesive and coherent discourse in text. Despite the novelty of this benchmark, several issues were raised concerning its clarity, methodological rigor, and the novelty of its contributions. There are concerns about the benchmark's generalizability across different languages, the lack of comprehensive baseline comparisons, and the potential overfitting of models to the training data used for the benchmark.\n\n**Strengths**\n- The proposed Disco-Bench benchmark is well-designed to evaluate the ability of LLMs to understand discourse, which is crucial for their practical applications.\n- The benchmark covers both Chinese and English languages, ensuring a broader evaluation scope.\n- The benchmark introduces a novel diagnostic dataset for probing models' discourse knowledge, providing a new tool for evaluating discourse modeling capabilities.\n- The paper is clearly written and easy to follow, making it accessible to a wide range of readers.\n- The benchmark is diverse in its tasks and covers a range of discourse phenomena, which could facilitate further research in discourse modeling.\n\n**Weaknesses**\n- The novelty of the benchmark is questionable as similar benchmarks have been proposed in recent years, such as the discourse benchmark from the ACL 2022 conference.\n- The paper lacks comprehensive baseline comparisons, particularly with other discourse modeling benchmarks like the one from ACL 2022.\n- The benchmark's generalizability across different languages and languages with complex grammar and syntax is not clearly demonstrated.\n- The evaluation metrics used are not sufficiently robust, particularly in the context of language understanding tasks.\n- The methodology for constructing the Disco-Bench training and diagnostic datasets is not sufficiently explained, raising concerns about data quality and potential overfitting.\n- The benchmark's scope is limited to Chinese and English, which may not reflect the performance of models on other languages.\n- The paper does not provide sufficient evidence that the models are not overfitting to the training data used for the benchmark.\n- There is a lack of comparison with other pre-trained models that might have been trained on similar data, which could affect the validity of the findings.\n\n**Questions**\n- Can the authors clarify the method used to construct the Disco-Bench training and diagnostic datasets?\n- How do the authors ensure that the models are not overfitting to the training data used for the benchmark?\n- Why were certain evaluation metrics, such as GPT-3.5 and GPT-4, not included in the baseline comparisons?\n- How does the benchmark ensure its generalizability across different languages, particularly those with complex grammar and syntax?\n- Can the authors provide more detailed information on the performance of Disco-Bench pretrained models compared to other models trained on similar data?\n- What specific discourse phenomena are tested in the benchmark, and how are these phenomena defined and measured?"
    },
    "Gq1Zjhovjr": {
        "gold": "**Summary**\nThis paper introduces a novel consistency regularization method called Logit Attribution Matching (LAM) aimed at improving domain generalization. The authors reinterpret domain generalization through a causal latent decomposition model, stressing the importance of causal-invariant prediction, where predictions remain consistent despite variations in non-core factors. The paper suggests that consistency regularization may be an optimal solution for domain generalization under certain conditions, with traditional methods like probability matching, logit matching, and feature matching being special cases of this broader framework. Extensive experiments demonstrate the effectiveness of LAM, comparing its performance against existing domain generalization and data augmentation strategies. Despite these contributions, concerns were raised about the theoretical underpinnings not being sufficiently connected to the proposed method, and the novelty and practical value of the solutions were questioned by some reviewers.\n\n**Strengths**\n- The paper presents a clear writing style and the idea flow is easy to follow, making the concept of domain generalization from a causal latent decomposition perspective both interesting and novel.\n- Utilizing the Optimal DG theorem enhances understanding by summarizing existing consistency regularization methods into a general framework.\n- A thorough set of experiments conducted over multiple image datasets demonstrates the superiority of the proposed methods, especially the label-aware matching (LAM) approach, in outperforming both domain generalization and consistency regularization methods in out-of-distribution settings.\n- The theoretical backing, although in question regarding its application, highlights the significance of the causal invariant property for domain generalization.\n- A simple yet effective additional weight term over each feature unit and class label introduced shows significant improvements in handling out-of-distribution (OOD) scenarios.\n\n**Weaknesses**\n- There appears to be a lack of novel contributions, as the paper builds on extensively studied areas like consistency regularization and targeted augmentation, and fails to sufficiently differentiate or extend these concepts in a significant new direction.\n- The link between the theoretical foundations such as the Optimal DG theorem and the applied techniques like LAM is weak and not well-motivated, which could confuse the contribution significance.\n- Several assumptions, for example, those used in Theorem 1, are overly strong and not likely to hold in practical scenarios, limiting the applicability and robustness of the proposed methods.\n- The dependence on targeted augmentation (TA) is criticized for lack of algorithmic novelty and general applicability, as it might not be effective or feasible across various datasets and new domains.\n- The paper suffers from certain clarity issues due to extensive use of abbreviations and a sporadic connection of contributions in the introductory section, making it difficult to grasp the integration of ideas at first.\n\n**Questions**\n- Can the authors clarify how the Optimal DG theorem directly supports the implementation of LAM? How do these theoretical insights translate into the practical effectiveness of LAM?\n- Why was the feature matching model chosen as the base for logit attribution matching? Could probability matching or logit matching models provide better or worse outcomes?\n- Is it possible to see further clarifications on how label-aware matching (LAM) performs when faced with dataset-agnostic augmentation methods like RandAugment, CutMix, or AugMix?\n- Given the significant reliance on targeted augmentation, how can LAM be effectively applied to new domains where such specific data augmentations may not be viable?\n- How do the weights introduced in LAM (e.g., \\(w_{uy_k}\\)) determine or influence model performance and what guides their configuration during training or setup?",
        "5_5": "**Summary**\nThe paper explores the synergy between data augmentation (DA) and consistency regularization (CR) in domain generalization, proposing a novel method called Logit Attribution Matching (LAM). This method leverages class labels to enhance the performance of DA by matching logit vectors, particularly in a causal framework where domain shifts are addressed through DA. The experiments conducted across various datasets, including ImageNet, iWildCam, and Camelyon, demonstrate the effectiveness of LAM in improving out-of-distribution (OOD) performance. The paper also includes a theoretical analysis to justify the CR-based approach to domain generalization, although some reviewers noted that the theoretical contributions could be better explained and integrated with the empirical findings.\n\n**Strengths**\n- The paper provides a thorough analysis of the combination of data augmentation and consistency regularization in the context of domain generalization, showing how these elements can improve out-of-distribution (OOD) performance.\n- It offers a novel method, Logit Attribution Matching (LAM), which is designed to leverage class labels to enhance data augmentation by matching logit vectors, showing significant improvements over baseline methods.\n- The paper is well-written and organized, making it easy to follow, and includes a detailed explanation of the methods used and the experimental setup.\n- It provides a clear and structured presentation of the problem, along with theoretical and empirical justifications for the proposed approach.\n\n**Weaknesses**\n- The paper lacks a comprehensive comparison with existing methods, particularly those that have demonstrated superior performance in previous works. This omission raises concerns about the novelty and effectiveness of the proposed method.\n- There is a noticeable lack of clarity in the presentation of theoretical contributions, particularly the causal framework and its application to the domain generalization problem. This section is also criticized for being overly technical and not well integrated with the empirical results.\n- The paper's theoretical discussion does not sufficiently address the assumptions and limitations of the causal framework, which may not be realistic or applicable in practical scenarios.\n- The experiments are limited in scope, focusing primarily on a few datasets, and do not explore a broader range of domain generalization tasks, which might have strengthened the validity of the findings.\n- There is a lack of detailed discussion on the choice of data augmentation techniques and the potential impact of different augmentation strategies on the results.\n\n**Questions**\n- Could the authors elaborate on the specific choice of data augmentation techniques used and their rationale, as well as the impact of different augmentation strategies on the results?\n- How does the proposed method compare with existing methods, especially those that have shown superior performance in previous works? What are the advantages of the proposed method over these existing methods?\n- Can the authors clarify the role and justification of the causal framework in the context of domain generalization, particularly its assumptions and limitations?\n- Why were certain datasets selected for the experiments, and how do these choices affect the generalizability of the findings?\n- Could the authors discuss the potential scalability of the proposed method to more complex and diverse domain generalization tasks, such as those involving multiple sources of domain shifts?",
        "5_3": "**Summary**\nThe paper examines the potential synergy between domain generalization (DG) and consistency regularization (CR) by proposing a novel method called Logit Attribution Matching (LAM). It aims to improve domain generalization by enhancing the model's ability to make predictions based on core factors, rather than relying on spurious correlations. The proposed method involves creating pairs of training examples with the same semantic content and applying a consistency regularization loss that focuses on the target class. Theoretical analysis and empirical evidence are provided to demonstrate the effectiveness of LAM. Despite the promising results, the paper faces criticism regarding its novelty, as similar approaches have been explored in previous works, and the theoretical contributions are seen as incremental. Additionally, there is a noted lack of discussion on the broader implications of the method and its potential application to different types of domain shifts.\n\n**Strengths**\n- The paper is well-organized, clearly written, and easy to follow, making it accessible to a broad audience.\n- The experimental results are comprehensive, demonstrating that the proposed method improves domain generalization performance compared to existing methods.\n- The idea of enhancing domain generalization through consistency regularization is innovative and well-supported by theoretical analysis, which highlights the importance of core factors in model predictions.\n- The proposed method, Logit Attribution Matching (LAM), is shown to be effective in improving domain generalization and has a clear theoretical justification.\n- The paper provides a thorough empirical evaluation of the proposed method, including ablation studies and comparisons with other DG methods.\n\n**Weaknesses**\n- The novelty of the paper is limited, as similar approaches using consistency regularization to enhance domain generalization have been explored in previous works.\n- The theoretical contributions of the paper are considered incremental, primarily extending previous results by the same authors.\n- The paper lacks a discussion on the broader implications of the proposed method and its potential application to different types of domain shifts, such as distributional shifts.\n- The proposed method's effectiveness is limited to specific datasets, and there is a lack of generalizability tests across diverse datasets.\n- The paper has several formatting issues, including incorrect citation formats and inconsistent notation, which may affect the paper's professionalism.\n- The method's reliance on domain-specific data augmentation may not be practical for all applications, and the method's scalability in larger datasets or more complex settings is not explored.\n- The paper does not fully address how the proposed method compares with other methods that do not use consistency regularization.\n\n**Questions**\n- Can the authors clarify the novelty of their approach compared to existing works that also use consistency regularization for domain generalization?\n- What are the broader implications of the proposed method beyond the specific datasets tested?\n- How does the proposed method perform on different types of domain shifts, and what are its limitations in this regard?\n- Can the authors provide more details on how the proposed method can be adapted to different datasets and more complex settings, such as larger datasets?\n- How does the proposed method compare with other methods that do not use consistency regularization, and can the authors provide a detailed analysis of these comparisons?\n- Could the authors discuss how the proposed method can be integrated with other domain generalization techniques, such as those mentioned in the references provided, to enhance its effectiveness?"
    },
    "i7oU4nfKEA": {
        "gold": "**Summary**\nThis paper investigates the effects of multilingual pretraining on language model performance across a huge dataset covering 250 languages. The authors conducted controlled experiments using GPT2-style models, training over 10,000 models in varying settings, where they adjusted factors such as monolingual and multilingual data sizes, linguistical similarities, and model sizes. Key findings suggest that while low-resource languages benefit from the addition of multilingual data, this often negatively affects high-resource language modeling. The extent of these effects is influenced by the syntactic and, to a lesser extent, lexical similarities of the languages used. Results suggest that for certain languages and configurations, targeted monolingual models may be more effective than massively multilingual approaches. The impact of multilingual pretraining varies with model size, and the small sizes of models used (up to 45M parameters) bring into question the scalability and applicability of the findings to larger, state-of-the-art language models.\n\n**Strengths**\n- The paper provides an in-depth study of the effects of multilingual pretraining for small-ish language models, assessing a variety of factors including resource levels, syntactic/lexical/geographic similarities, and model size. This holistic approach enhances understanding of how cross-lingual transfer can benefit language models.\n- Researchers conducted extensive and controlled experiments, pre-training a massive number (over 10000) of monolingual and multilingual language models across more than 250 languages. This effort substantiates the paper\u2019s claims with concrete experimental evidence.\n- The methodology adopted, particularly the choice of tokenization approach and the metric for evaluating model performance, enables an intuitive comparison between monolingual and multilingual models. The paper clearly outlines these methods, contributing positively to its reproducibility and clarity.\n\n**Weaknesses**\n- All models studied are relatively small, capped at up to 45M parameters. This limitation is notable as larger models (in the scale of billions of parameters) are common in current research and applications, and results from small models may not generalize well to larger scales.\n- There is a contradiction or lack of support regarding the claim that \u201cmultilingual pre-training may not be beneficial to any languages involved.\u201d This is particularly perplexing given the evidence suggesting clear benefits for low-resource languages.\n- The paper's evaluation heavily relies on pretraining loss metrics, whereas inclusion of downstream task performance could provide a fuller picture of the practical effectiveness of the multilingual models.\n- Repetitiveness and possible inconsistencies in the manuscript, such as different numbers cited for the total models trained and formatting issues, suggest the need for better proofreading and editing for clarity and accuracy.\n\n**Questions**\n- Do the authors expect these results to translate to related larger-scale tasks such as machine translation, speech recognition, etc.? How might the findings align with or diverge from the current state-of-the-art models for these tasks?\n- Why was there relatively minor impact observed when selecting the most vs. the least related languages for inclusion in the multilingual training sets?\n- Could the authors clarify the apparent contradiction regarding the benefits of multilingual pre-training, especially given the positive results shown for low-resource languages?\n- There is mention of both the syntactic similarity of added languages driving results and the surprising finding that adding \"similar\" languages sometimes resulted in larger performance degradation. Could the authors discuss potential reasons for these findings and the implications for multilingual model training strategies?\n- Regarding multilingual tokenizers, is there a limitation with using a uniform vocabulary size (e.g., 32K tokens) for scenarios involving many languages with varying scripts? How might this affect model performance and fairness across languages?",
        "5_5": "**Summary**\nThe paper examines the impact of multilingual pretraining on language models' performance across 252 languages. It introduces a novel approach by pretraining models from scratch, varying factors such as monolingual and multilingual dataset sizes, model size, and linguistic similarity of the pre-training languages. The study reveals that adding multilingual data generally benefits low-resource languages and harms high-resource ones. This effect is attributed to the limited model capacity, suggesting that multilingual data can act as a regularization mechanism for low-resource languages. The paper also discusses how linguistic similarity affects performance improvements, showing that syntactic similarity is a more significant factor than lexical similarity.\n\n**Strengths**\n- The paper is well-written, easy to follow, and effectively presents the research question and the proposed methodology.\n- The research is highly relevant to the field of multilingual language modeling, providing valuable insights into the impact of multilingual pretraining on model performance across different language resources.\n- The paper is thorough and well-documented, providing a comprehensive overview of related work and a clear description of the experimental setup, data collection, and results.\n- The findings are significant, highlighting how multilingual data can affect the performance of language models in different resource scenarios and how linguistic similarity influences these effects.\n- The paper successfully addresses the question of how different multilingual pre-training language distributions affect multilingual language model performance.\n\n**Weaknesses**\n- The paper's experimental setup is not thoroughly justified, particularly the selection of languages and the choice of dataset sizes, which could limit the generalizability of the findings.\n- There is a lack of exploration into the potential benefits of adding multilingual data to high-resource languages, despite the observation that it generally harms their performance.\n- The paper lacks a discussion on the implications of its findings for practical applications, such as text generation or translation tasks, and does not adequately explore the limitations of the study.\n- The novelty of the work is limited, as it primarily builds on existing research and does not introduce new methodologies or significantly extend the state-of-the-art.\n- The paper does not discuss the potential risks associated with the proposed approach, such as the impact on model performance in high-resource languages or the long-term effects of multilingual pretraining on model capabilities.\n\n**Questions**\n- How were the 252 languages chosen for the study, and what are the criteria for selecting languages?\n- Why were the dataset sizes selected as 1M, 10M, 100M, and 1B tokens, and how do these choices impact the results?\n- Can the authors elaborate on the benefits of adding multilingual data to high-resource languages, as suggested by the paper's findings?\n- What are the limitations of the study, and how do they affect the generalizability of the results?\n- How do the authors plan to address the potential risks associated with the proposed approach, such as the impact on model performance in high-resource languages?\n- Could the authors provide more details on the potential applications and implications of the findings for practical scenarios, such as text generation or translation tasks?",
        "5_3": "**Summary**\nThe paper presents a comprehensive study on the impact of multilingual data on low-resource languages during the pre-training of large language models. It investigates the effects of adding monolingual and multilingual data, varying in size and linguistic similarity, on model performance. The study is notable for its extensive empirical analysis across 252 languages, pre-training over 1900 monolingual and 8400 multilingual models. The findings suggest that moderate amounts of multilingual data, particularly when linguistically similar, can enhance model performance in low-resource settings. The study also examines the effects of model size, finding that larger models generally perform better across languages. While the paper is praised for its thorough methodology and insightful results, it is criticized for lack of clarity in presentation, particularly in terms of data handling and model specifics.\n\n**Strengths**\n- The paper is well-structured and clearly written, making it accessible and easy to follow, which is beneficial for a broad audience.\n- The study is comprehensive, covering a large number of languages (252) and a wide range of monolingual and multilingual models, enhancing the generalizability of the results.\n- It offers a thorough empirical analysis of the impact of multilingual data on low-resource languages, providing insights into how model performance changes with varying amounts of multilingual data.\n- The paper is well-motivated and addresses a significant and relevant topic in the field of natural language processing, particularly in the context of low-resource languages.\n- The study's findings are generally consistent with previous research, adding credibility to the results and reinforcing the paper's contributions to the field.\n\n**Weaknesses**\n- The paper lacks clarity in some areas, particularly concerning the experimental setup and data handling, which could hinder understanding and replication of the results.\n- There is insufficient discussion on the methodological choices, such as the decision to use perplexity as a performance metric and the rationale behind certain experimental design decisions like the handling of validation sets and model training.\n- The writing could be improved for better readability and professional presentation; several sentences are overly complex and contain grammatical errors.\n- The paper does not adequately compare with related works, which is a significant oversight given the relevance of these studies to the paper's topic.\n- The paper does not explore other important aspects such as the impact of different pre-training data sources, the influence of linguistic similarity beyond multilingual data, and the effects of varying model sizes, which are crucial for a more comprehensive understanding.\n\n**Questions**\n- Could the authors clarify the criteria used for selecting the languages included in the study and the rationale behind the decision to exclude certain languages?\n- How were the perplexity scores calculated for the validation sets, and what specific validation sets were used?\n- What is the role of the monolingual data in the study, and how does it affect the performance of the models? Are there specific results or insights related to monolingual data that the authors could highlight?\n- How does the study account for the potential biases introduced by the choice of perplexity as a performance metric, particularly in languages with different character sets?\n- Can the authors elaborate on the methodology used to determine the linguistic similarity of languages, and how this similarity affects the model performance?\n- What are the implications of the findings for future research in multilingual language model training, particularly in low-resource settings?"
    },
    "iGHPVbttMs": {
        "gold": "**Summary**\nThe paper explores the relationship between cyclical behavior in game-theoretic learning algorithms and the support of mixed-strategy Nash equilibria (MSNE). It introduces a novel graph search learning method called GraphNES aimed at identifying Nash equilibria through self-play in non-cooperative games. This method either concludes at a pure Nash equilibrium or identifies cycles indicative of the support of a MSNE. The paper's empirical studies in games like Connect4 and Naruto Mobile demonstrate that GraphNES can outperform conventional methods requiring larger strategic datasets. However, reviewers have critiqued the clarity and accessibility of the paper, indicating that its theoretical contributions and the novelty of the results might be overshadowed by presentation issues and lack of a thorough literature review.\n\n**Strengths**\n- The paper provides valuable insights into the behavior of empirical game theoretic algorithms and uses these insights to advance the state of the art.\n- The authors present a historical context to strategically analyze phenomena observed in game theory, successfully tying earlier observations of cyclic patterns to formal predictions like the Poincar\u00e9 recurrence theorem.\n- The detection of cycling within Path-Response Strategy Oscillations (PRSO) dynamics is presented as a significant method for uncovering the support strategies of a Mixed Nash Equilibrium (MSNE), suggesting its utility not just as a diagnostic tool but also for understanding foundational game structures.\n- The manuscript addresses an important problem with self-play in gaming frameworks that are not strictly transitive, offering solutions to reduce the number of necessary strategies in training through minimized opponent population, as observed in the GraphNES which outperforms traditional methods like NeuPL.\n- The paper contains rigorous results and interesting experiments that showcase its practical applications in specific games, enhancing understanding of their theoretical implications.\n- Some sections of the paper, such as the introduction, are clearly written, providing a solid grasp of the context and the contributions claimed.\n\n**Weaknesses**\n- The paper is generally difficult to read due to either formatting issues or poor clarity in the writing; specific examples include multiple proofs under a single theorem without clear delineation and frequent typographical errors.\n- The novelty of the research findings is questionable as similar themes have been extensively discussed in prior works, necessitating a more thorough investigation and citation of related literature to solidify the paper's contribution.\n- Computational complexity concerns raised by the claims of feasible cycle detection within PRSO dynamics are not sufficiently addressed, leaving questions about alignment with conventional complexity issues surrounding Nash Equilibria.\n- The scope of the experiments and environmental choices for testing the algorithms are limited or inappropriately selected, which could affect the generalizability and applicability of the results.\n- Visual aids such as algorithmic flowcharts are missing, which could help clarify complex processes discussed in the text.\n- Some sections lack rigorous definitions and thorough explanations (e.g., cyclical strategies, the class of games applicable to the main theorem), which are critical for the understanding and validation of the claimed results.\n\n**Questions**\n- Can the authors clarify the intended purpose of the experiments and the concrete takeaways, especially in relation to the practical applications of the findings?\n- What specific definitions and formal parameters can be provided for key concepts such as cyclical strategies, complete cyclical strategies, and the class of games the main theorem applies to?\n- How does the paper align its claims of computational feasibility with the known PPAD-hardness of finding Nash Equilibria through conventional methods?\n- In light of the criticisms regarding the novelty of the results, can the authors clarify the distinctions and contributions of their findings compared to existing literature, particularly through an expanded related work section?\n- Could the authors provide additional visual representations of the algorithms to aid in understanding, as well as a discussion on the rationale behind the selection of specific environments for the experimental validations?",
        "5_5": "**Summary**\nThe paper explores the notion of cyclical strategies in non-cooperative games and their equivalence to the support set of a mixed-strategy Nash Equilibrium (MSNE). It introduces a novel approach utilizing a directed graph search to identify these cyclical strategies, which are seen as integral to finding MSNE. The method is supported by a theoretical analysis that links cyclical strategies to MSNE, although empirical validations are limited to simple games like Connect4 and Naruto Mobile. The study suggests that this graph-based search could potentially be more efficient than traditional methods like Policy Space Response Oracles (PSRO) in finding MSNE, but the experimental results are not convincing, and the paper lacks a broader evaluation across diverse games.\n\n**Strengths**\n- The paper introduces a novel perspective on finding Nash Equilibria by considering cyclical strategies as orderly sequences rather than chaotic anomalies.\n- It establishes a theoretical equivalency between a complete set of cyclical strategies and the support set of a Mixed Strategy Nash Equilibrium (MSNE).\n- The paper presents a new graph-based learning representation for self-play, which is theoretically grounded and could potentially be more efficient than existing methods like Policy Space Response Oracles (PSRO).\n- The study demonstrates improved self-play efficiency in discovering both Pure Strategy Nash Equilibrium (PSNE) and MSNE in noncooperative games such as Connect4 and Naruto Mobile.\n\n**Weaknesses**\n- The empirical validation of the proposed method is limited to very simple games, which does not convincingly demonstrate the method's effectiveness across more complex or realistic game scenarios.\n- The paper lacks a comprehensive comparative analysis with other existing methods, particularly PSRO, to adequately demonstrate the superiority or effectiveness of the new method.\n- The theoretical claims made about the equivalency of cyclical strategies and the support set of MSNE are not universally convincing, especially in the context of games with multiple Nash Equilibria.\n- There is a significant lack of detailed experimental results and a thorough evaluation of the proposed method, including a lack of discussion on the computational efficiency and practical implementation aspects.\n- The paper does not address potential issues like the computational cost associated with maintaining and querying the vector database of all strategies, which could be a significant limitation in practical applications.\n\n**Questions**\n- Could you elaborate on how the proposed method compares in terms of computational efficiency to existing methods like PSRO, particularly in more complex games?\n- How does the proposed method handle games with multiple Nash Equilibria, and what are the implications for the theoretical claims made in the paper?\n- In practical terms, how does the vector database of all strategies impact the computational resources and query efficiency of the proposed method?\n- Given the limited empirical validation, how do you plan to expand the experimental scope to include more complex or realistic game scenarios?\n- Could you provide more details on the implementation of the proposed method, including the computational cost and scalability issues associated with the vector database storage and query?",
        "5_3": "**Summary**\nThe paper discusses a novel approach to finding Nash Equilibria (NE) in non-cooperative games, focusing on the role of cyclical strategies in equilibrium states. It introduces a graph-based method to identify cycles in strategy interactions, which is claimed to enhance computational efficiency over traditional methods like PSRO. The paper posits that cyclical strategies, when present, can represent a Nash Equilibrium, challenging the conventional notion that equilibria must be deterministic. However, the paper's core theoretical claims and their practical implications are questioned by reviewers, with some highlighting the absence of rigorous theoretical proofs and others expressing concerns about the empirical methodology used.\n\n**Strengths**\n- The paper is well-written, easy to read, and provides clear motivations and results, making it accessible to a broad audience.\n- The proposed method is simple, effective, and innovative, using a graph-based approach to find Nash Equilibria (NE) in games, which is a novel and interesting approach.\n- The paper is clearly motivated and the problem tackled is relevant and significant, providing an alternative to traditional methods in game theory.\n- The theoretical claim about cyclical strategies being equivalent to the support set of a Mixed Strategy Nash Equilibrium (MSNE) is intriguing and contributes to the existing literature on game theory.\n\n**Weaknesses**\n- The paper lacks rigorous mathematical proof for its central claims, specifically regarding the equivalence of cyclical strategies to the support set of a Mixed Strategy Nash Equilibrium (MSNE), which raises concerns about the theoretical foundation of the results.\n- The method proposed has significant empirical flaws; it does not outperform existing methods like PSRO and Simplex-NeuPL, and lacks a thorough discussion of why this is the case.\n- The empirical results are presented as only a few graphs, which do not convincingly demonstrate the efficacy of the proposed method.\n- The paper does not adequately discuss or compare the computational efficiency of the proposed method against existing approaches, which is crucial for its practical applicability.\n- The paper contains some misleading statements and lacks a clear distinction between the proposed method and existing approaches like PSRO, which could lead to confusion about the originality and impact of the research.\n\n**Questions**\n- Could the authors provide a rigorous mathematical proof to support the claim that cyclical strategies are equivalent to the support set of a MSNE?\n- What is the specific motivation behind using the proposed method instead of existing methods like PSRO or Simplex-NeuPL? How does the proposed method improve upon these approaches?\n- Why does the proposed method not outperform existing methods in the empirical results presented? What are the reasons for this lack of performance improvement?\n- How does the proposed method compare in terms of computational efficiency to existing methods? Can the authors provide a detailed comparison or analysis of the computational resources required?\n- Can the authors clarify the statement that \"Myopic BR is more efficient and effective in finding improved counter policies\"? What specific improvements or advantages does this method provide over other approaches?"
    },
    "ipWSxcmgsx": {
        "gold": "**Summary**\nThe paper introduces NormIntSleep, a two-stage framework for interpretable sleep-stage classification using deep neural networks (DNNs) and linear models. The first stage involves training a DNN to classify sleep stages, followed by a linear model mapping the DNN's latent representations to a clinically interpretable feature space. These features are then input into a glass-box model for final sleep stage prediction. The proposed framework not only matches the performance of non-interpretable models but is also grounded in clinically established knowledge, making it attractive for medical applications. The paper also introduces a new metric, AlignmentDT, to measure the consistency of the glass-box model's decisions with domain knowledge. However, the paper faces criticism regarding the clarity of model comparisons, experiment descriptions, and the generalizability of its methods to other domains.\n\n**Strengths**\n- The paper addresses a critical area in machine learning for healthcare, focusing on interpretability in sleep staging algorithms, which is essential for clinical applications and healthcare.\n- It is well-written and structured for ease of understanding, highlighting significant efforts in explaining the implementation and motivation behind the study.\n- Extensive experiments were conducted on two different datasets, showcasing a variety of baselines which enriches the empirical evaluation and supports robust comparative analysis.\n- The introduction of the Interpretable Decision Tree and decision-making process explained through practical examples (e.g., Figure 2 in section 5.1) effectively bridge the gap between methodological advances and practical, clinical needs.\n- The relevance and potential impact of the work are clear, given the emphasis on explainability and the healthcare context, which could aid in broader acceptance and trust of machine learning models in medical settings.\n\n**Weaknesses**\n- The paper struggles with clarity in several sections; the explanations of methods and results are sometimes confusing, and important details are either missing or not sufficiently explained (e.g., lack of detail on hypermetric tuning, definitions of key terms and metrics).\n- Concerns about the interpretability of the proposed models, particularly when projections diverge from actual features, which could mislead the interpretability of the model\u2019s output.\n- The reproducibility of results is questionable as the code for the experiments is not provided, and there seems to be a lack of standard error reporting in the results, which diminishes the scientific rigor.\n- The paper's technical contributions appear limited, with some methodologies and metrics poorly generalized beyond specific setups (e.g., alignment metrics tailored only for decision trees).\n- The generalizability of the approach to other domains is questionable, and comparisons to other state-of-the-art methods in interpretability are insufficiently explored or justified.\n\n**Questions**\n- Can you clarify the process and criteria used for the optimization of model hyperparameters? Were techniques like cross-validation employed?\n- For the alignment metric, please provide a detailed explanation of its calculation. Was there any manual verification by clinicians, and was there a consensus among multiple clinicians?\n- Could you discuss how the cross-entropy loss for the DNN is combined with the regression loss during the pre-training stage? Is it a simple average, or is there another method used?\n- In regards to the experiments and interpretations from NormIntSleep, can you provide further justification or evidence that supports the meaningfulness of the interpretations generated?\n- Given the concerns about model interpretability when projections diverge from actual features, can you provide further clarifications or modifications to the methodology that might address these concerns?\n- Please consider adding more details about the hypnogram used in the study and discuss the utility limitations of the proposed metrics which seem tailored mainly for decision trees.",
        "5_5": "**Summary**\nThe paper presents a novel approach called NormIntSleep that integrates interpretable features with neural network embeddings for sleep stage classification, aiming to enhance the interpretability of deep learning models in clinical applications. It introduces a new metric, \\(Alignment_{DT}\\), to evaluate the alignment between the decision tree and clinical domain knowledge. The proposed method combines features like kurtosis, skewness, variance, and mean with deep neural network embeddings, demonstrating a performance comparable to state-of-the-art methods while offering more interpretable results. The approach is validated using two public datasets, and the paper includes ablation studies and a detailed explanation of the methodological choices.\n\n**Strengths**\n- The paper introduces a novel approach that integrates interpretable features with neural network embeddings to enhance the interpretability of deep learning models in clinical applications, specifically in sleep stage classification.\n- The proposed method demonstrates performance comparable to state-of-the-art methods, highlighting its effectiveness.\n- The use of a new metric, \\(Alignment_{DT}\\), for quantifying the alignment between the decision tree and clinical domain knowledge is a significant contribution to the field.\n- The paper includes ablation studies and detailed explanations of methodological choices, which aids in understanding the rationale and impact of different design decisions.\n- The authors provide a comprehensive evaluation of the proposed method using two public sleep classification datasets, benchmarking against state-of-the-art interpretable and deep learning methods.\n- The manuscript is well-structured, making it easy to follow, and the code is available, allowing for reproducibility and further research by the community.\n\n**Weaknesses**\n- The paper does not adequately discuss how the proposed method can be generalized beyond the specific task of sleep stage classification, which limits its applicability to other domains.\n- There is a lack of clear and detailed explanation of the feature engineering process, including the rationale behind the selection and combination of features.\n- The paper does not provide sufficient evidence to support the claim that the proposed method is more interpretable than existing approaches, as the interpretability evaluation is not robustly justified.\n- The decision to use a linear projection layer as the core of the method is not convincingly motivated, and the paper lacks a comparative analysis of different projection layers (e.g., linear vs. non-linear).\n- The paper has several typographical errors and inconsistencies in notation, which can confuse readers and detract from the overall quality of the presentation.\n\n**Questions**\n- Can the authors provide more details on how the proposed method can be generalized to other domains beyond sleep stage classification?\n- How was the feature engineering process determined, and what were the specific considerations for selecting and combining features?\n- What is the rationale behind the use of a linear projection layer as the core of the method, and how does this choice impact the interpretability and performance of the proposed method?\n- Could the authors elaborate on the interpretability evaluation and provide more robust justification for the claim that the proposed method is more interpretable than existing approaches?\n- What are the specific steps involved in using the proposed method for clinical decision support systems, and how does the method ensure compliance with clinical guidelines and domain expertise?\n- How do the authors address the potential biases and errors introduced by the use of decision trees in the proposed method, particularly in the context of clinical applications where precision is critical?",
        "5_3": "**Summary**\nThe paper introduces NormIntSleep, a novel approach aimed at enhancing the interpretability of sleep stage classification by combining neural network embeddings with a linear projection and decision tree classifiers. The approach aims to provide domain-grounded explanations that align with clinical guidelines, using metrics such as AlignmentDT to evaluate its effectiveness. The method is validated using the Physionet and ISRUC datasets, demonstrating its ability to achieve higher classification accuracy and better interpretability compared to existing methods. The paper also conducts a detailed ablation study to isolate the contributions of the different components of NormIntSleep.\n\n**Strengths**\n- The paper is well-written, easy to understand, and clearly articulates the problem of interpretability in sleep stage classification and the proposed solution.\n- The approach of combining neural network embeddings with a linear projection and decision tree classifiers is novel and represents an interesting method for interpretable machine learning.\n- The paper provides a comprehensive evaluation using two public datasets, demonstrating that the proposed method outperforms other existing methods in terms of classification accuracy and interpretability.\n- The method is well-motivated and addresses a significant challenge in the field, which is the integration of domain knowledge to enhance model interpretability.\n- The proposed metric $Alignment_{DT}$ is a novel approach to evaluate the alignment of decision trees with clinical guidelines and domain knowledge.\n\n**Weaknesses**\n- The paper lacks a detailed description of the clinical application of the proposed method, which is critical for evaluating its effectiveness and practical utility in clinical settings.\n- The decision tree classifier used in the study is relatively simple and may not be robust enough to handle complex datasets or provide accurate insights in scenarios where the decision boundaries are intricate.\n- The paper does not provide sufficient information about the selection of the features used in the study, such as the justification for the specific features chosen and the impact of other potential features on the results.\n- The novelty of the approach could be limited since it combines existing methods in a way that might not significantly advance the state-of-the-art.\n- There is a lack of detailed discussion on how the proposed method can be generalized to other domains beyond sleep stage classification.\n\n**Questions**\n- How does the proposed method handle the selection of features and their impact on the classification accuracy and interpretability?\n- Can the authors provide more details on how the proposed method was applied in a clinical setting and its effectiveness in real-world scenarios?\n- Could the authors clarify the novelty of their approach compared to other existing methods in the field?\n- How does the proposed metric $Alignment_{DT}$ compare to other established methods of evaluating model interpretability?\n- What are the specific advantages of the proposed method over other interpretable methods, such as SHAP, LIME, and Anchors?\n- How does the proposed method handle different types of data or domains outside of sleep stage classification?"
    },
    "kxebDHZ7b7": {
        "gold": "**Summary**\nThe paper introduces a novel optimization algorithm named Trust Region Aware Minimization (TRAM), which aims to integrate the benefits of Sharpness-Aware Minimization (SAM) with Trust Region methods. TRAM is designed to optimize for flat minima while enforcing constraints in the representation space to maintain smoothness and prevent significant deviations from pre-trained models. This could potentially enhance the transferability and generalization of models in fine-tuning scenarios. The proposed approach is evaluated through experiments on language and vision tasks, showcasing improvements over existing methods like SAM and its variants.\n\n**Strengths**\n- The paper effectively summarizes existing approaches and illustrates how the proposed method builds upon them.\n- The combination of SAM and Trust Region methods is well-motivated, interesting, and intuitive.\n- Detailed and comprehensive experimental settings are provided, with extensive experiments conducted on multiple NLP tasks demonstrating the effectiveness of the proposed method.\n- The paper is clearly written, making it easy to follow, and contributes interesting perspectives on fine-tuning techniques in NLP, which is a critical area in model training.\n- Integrates the proposed method with Fisher-SAM to reduce the count of forward-propagation when implemented to the same count as in vanilla SAM.\n- Empirical validations reflect the method's transfer capability in foundational models and large-scale NLP datasets.\n\n**Weaknesses**\n- The paper lacks theoretical motivation for unifying SAM and Trust Region methods and fails to provide a clear distinction between these methods' applications in the proposed approach.\n- Some results show high variance across runs, suggesting the need for additional runs to better characterize performance.\n- The core idea of adaptively changing the neighborhood radius based on certain distance measures does not align well with the established ideas of Trust Region Regularization, leading to unclear methodology and impact.\n- It's unclear why using such a distance measure for neighborhood radius could instill 'trust', and there are missing clarifications on what 'trust' indicates in the proposed method.\n- Equations and some methodological concepts (like in Figures and Tables) are not clearly defined or explained, undermining the comprehension and robustness of the findings.\n- No computational/memory complexity analysis is provided, which is crucial for understanding the practical applicability of the method.\n- Generalization to modalities other than text, such as images, is not demonstrated, raising questions about the method's versatility.\n\n**Questions**\n- Given the paper\u2019s reliance on SAM-like updates, can you provide experiments or evidence that benchmark the new method against the original SAM on tasks where SAM was previously successful, to verify the comparative effectiveness?\n- Is ASAM-type of updates really necessary, or would a SAM version of the proposed method (TRAM) perform similarly?\n- How crucial is having a pre-trained model for TRAM to function effectively, especially considering different stages of model training (beginning vs. end)?\n- Could you clarify the interpretation of the slopes in Figure 1 and the methodological significance of the statistical absence for other TRAM variants in Table 5?\n- How well does TRAM transfer to other modalities like images, and what guidelines can be provided for selecting hyper-parameters for out-of-distribution generalization?\n- Could you discuss why forward KL divergence was chosen for your analysis over other forms like reverse KL or Renyi divergence, and the role of the noise variable in your equations?\n- Why was only accuracy considered in Table 4, and how does this reflect on the dataset's balance?",
        "5_5": "**Summary**\nThe paper introduces Trust Region Aware Minimization (TRAM), a novel fine-tuning algorithm designed to optimize for both flat minima and smooth, informative representations without forgetting pre-trained structures. TRAM integrates sharpness-aware minimization and trust region optimization, which aims to address the challenge of forgetting task-agnostic representations during fine-tuning. The authors evaluate TRAM on cross-domain language modeling and cross-lingual transfer tasks, demonstrating its effectiveness in improving generalization to out-of-domain data. Despite the reported improvements, concerns were raised about the novelty of combining trust region methods with SAM, as well as the choice of baselines and metrics, and the clarity of the experimental setup and results presentation.\n\n**Strengths**\n- The paper is well-organized, clearly written, and easy to follow, making it accessible to a broad audience.\n- The authors provide a clear explanation of the motivation behind the work, which enhances the paper's readability and comprehension.\n- The experimental design is robust, with a comprehensive set of experiments that cover multiple domains and tasks, and the results are well-presented, showing consistent improvements over baselines.\n- The paper introduces a novel method by combining sharpness-aware minimization and trust region optimization, which could be beneficial for future research in this area.\n\n**Weaknesses**\n- The novelty of combining trust region methods with sharpness-aware minimization (SAM) is questionable, as similar approaches have been explored in prior works, and the paper does not sufficiently distinguish its contributions from these existing methods.\n- The choice of baselines and metrics for evaluation is limited, which could affect the robustness and reliability of the experimental results.\n- The experimental setup is not fully transparent, particularly regarding the details of the tasks used, the models employed, and the hyperparameters tuned, which could impact the reproducibility and credibility of the findings.\n- The paper could benefit from additional analysis, such as a deeper exploration of the trade-off between in-domain performance and out-of-domain performance, to better understand the implications of the proposed method.\n- Some of the figures and tables in the paper are difficult to read or interpret, which could hinder the comprehension of the results.\n\n**Questions**\n- Can the authors provide more detailed explanations and justifications for their methodological choices, particularly regarding the selection of baselines and evaluation metrics?\n- How do the authors ensure the reproducibility of their results, and what steps are taken to verify the reliability of their findings?\n- What is the rationale behind using specific metrics for evaluation, and how do these metrics align with the objectives of the proposed method?\n- Could the authors elaborate on the potential limitations of their method, particularly in scenarios where there might be conflicting objectives between in-domain performance and out-of-domain performance?\n- Is there a possibility of extending the experiments to include additional tasks or models to further validate the effectiveness and generalizability of the proposed method?",
        "5_3": "**Summary**\nThe paper introduces Trust Region Aware Minimization (TRAM), a novel optimization algorithm that integrates sharpness-aware minimization (SAM) and trust region methods. TRAM aims to leverage the benefits of both approaches by optimizing within a trust region around the previous model parameters, which helps in avoiding catastrophic forgetting and improving generalization to out-of-distribution domains. The paper explores the application of TRAM in language modeling tasks, specifically zero-shot cross-domain language modeling and cross-lingual transfer tasks. The experiments demonstrate that TRAM can improve performance across various tasks, showing a potential to enhance generalization and stability in model training. Despite the innovative approach, the paper faces criticism for its experimental design, the lack of thorough comparisons with existing methods, and the unclear benefits of the proposed algorithm over simpler alternatives.\n\n**Strengths**\n- The paper is well-written, easy to follow, and provides a comprehensive overview of the problem, the proposed method, and the experimental setup.\n- The integration of sharpness-aware minimization (SAM) and trust region methods into a single algorithm is novel and well-motivated, with potential for significant impacts on the field.\n- The paper is well-structured, with a clear presentation of related work, problem formulation, and experimental results.\n- The proposed algorithm is easy to implement, and the methodology is clearly explained, making it accessible to a broad audience.\n- The experimental results show that the proposed method performs well on various tasks, demonstrating its effectiveness.\n- The paper explores a promising direction of combining SAM and trust region methods, which could lead to improvements in fine-tuning and domain generalization.\n\n**Weaknesses**\n- The paper lacks detailed experimental comparisons with existing methods, which makes it difficult to assess the effectiveness and novelty of the proposed method.\n- The motivation for combining SAM and trust region methods is unclear, and the paper does not sufficiently address how these two methods complement each other.\n- The experimental results do not convincingly demonstrate the benefits of combining SAM and trust region methods, and the gains appear to be marginal.\n- The paper does not sufficiently discuss the limitations and potential drawbacks of the proposed method, such as its computational cost and the impact of hyperparameters.\n- The paper does not provide a thorough analysis of the trust region method, particularly its use in the proposed algorithm.\n- There are concerns about the fairness of the comparisons made in the experiments, as the proposed method may have been tested with an unfair advantage over the baseline methods.\n\n**Questions**\n- Can the authors provide more detailed experimental comparisons with existing methods to better evaluate the effectiveness of the proposed method?\n- How do the authors justify the combination of SAM and trust region methods, and what are the specific advantages of this approach?\n- Can the authors clarify the unclear benefits of the proposed method over simpler alternatives?\n- How does the proposed method compare to other methods that use trust regions, such as R3F and MESA, and how does it perform in scenarios where the trust region is not centered around the current model parameters?\n- Can the authors discuss the limitations and potential drawbacks of the proposed method, such as its computational cost and the impact of hyperparameters?\n- How does the proposed method affect the computational complexity and memory requirements of the training process?\n- Can the authors provide more detailed results on the cross-lingual transfer task and discuss how the proposed method compares to other methods in this context?"
    },
    "LixtB4TYY2": {
        "gold": "**Summary**\nThe paper presents an evaluation of vision-language instruction-tuning datasets using a novel \"tune-cross-evaluation\" paradigm, where models are tuned on one dataset and evaluated on others. The evaluation introduces the \"Meta Quality\" (MQ), \"Dataset Quality\" (DQ), and \"Sample Quality\" (SQ) metrics, which assess various aspects of dataset and sample efficacy. The findings, derived from these metrics, informed the construction of a superior dataset from high-quality samples across the existing sets. This work is poised to impact the field by providing methods to assess and enhance the utility of datasets in the generative multimodal modeling sphere.\n\n**Strengths**\n- The paper successfully constructs several concurrent vision-language instruction tuning (VLIT) datasets, allowing for an in-depth comparative evaluation.\n- Introduces an innovative evaluation metric that demonstrates potential as an efficient data selection strategy by proving training models with half of the selected data can still achieve comparative results to using complete datasets.\n- The proposed method's motivation is highly relevant and intriguing, promising enhancements in current vision language model (VLM) research by considering both sample-wise and dataset-level aspects.\n- The entire methodology is presented in a clear and straightforward manner.\n- The idea of formulating a novel evaluation strategy specifically designed for VLIT datasets is well-motivated and can significantly aid in assessing the quality of emerging VLIT datasets.\n\n**Weaknesses**\n- The evaluation of whether the proposed metric itself is effective remains indirect and somewhat nebulous, making it difficult to quantify precisely how well the metrics work.\n- The 'Meta Quality' score still relies on traditional and potentially outdated statistical metrics like BLEU and METEOR, raising concerns about their relevance and effectiveness in the new LLM/LVLM era.\n- The empirical evidence and experiments provided are somewhat lacking in demonstrating that selected data subsets indeed improve overall performance.\n- It is unclear whether the methodology and the selected dataset using QFormer metric can be generalized across different frameworks, such as LLaVA.\n- Relying on VLIT datasets where most ground-truth responses are generated by models like ChatGPT/GPT4 without manual verification, poses a challenge due to potential inaccuracies and biases in these datasets.\n- The experimental design might neglect aspects of model capability when it excludes specific tuning datasets from the evaluation.\n- Equation modifications and settings in the evaluation method may dismiss challenging yet important samples while also including some biased or unchallenged results.\n\n**Questions**\n- Could you elaborate on how direct evaluations of your proposed evaluation metrics could be performed to establish clearer validation?\n- Given your reliance on BLEU and METEOR, how do you justify their continued use in the context of modern LLMs and what modifications (if any) might better adapt them to your needs?\n- Can you provide a comparison of performance improvements when utilizing the entire dataset versus selective high-quality subsets identified by your metric?\n- How generalizable is your proposed metric across various models and frameworks beyond QFormer and LLaVA?\n- In consideration of the quality reliability of existing VLIT datasets, how can you ensure they are suitable for use as high-quality evaluation datasets?\n- Could you offer empirical comparisons between the traditional ChatGPT-based evaluation metrics and your newly proposed methods, especially addressing aspects of accuracy and human subjectivity reduction?",
        "5_5": "**Summary**\nThe paper introduces a novel approach to evaluating Vision-Language Instruction-Tuning (VLIT) datasets by proposing a tune-cross-evaluation paradigm. This paradigm involves training models on one dataset and evaluating them on others, allowing for a comprehensive analysis of the dataset's capabilities and quality. The paper further defines metrics such as Meta Quality (MQ), Dataset Quality (DQ), and Sample Quality (SQ) to quantify these aspects. A new dataset, REVO-LION, is constructed using the proposed evaluation paradigm and is claimed to enhance model performance compared to simply merging existing datasets. Despite its innovative approach, the paper faces criticism for its limited novelty, unclear explanations, and lack of thorough empirical validation.\n\n**Strengths**\n- The paper introduces an innovative evaluation paradigm for Vision-Language Instruction-Tuning (VLIT) datasets, employing a tune-cross-evaluation methodology that trains on one dataset and evaluates on others to assess the datasets' capabilities comprehensively.\n- The paper defines new metrics such as Meta Quality (MQ), Dataset Quality (DQ), and Sample Quality (SQ) to quantify the comprehensiveness of each dataset and sample, which are considered original contributions to the field.\n- It includes a thorough review of related work and conducts extensive experiments to validate the effectiveness of the proposed evaluation paradigm.\n- The authors have released a new dataset, REVO-LION, which is designed to enhance model performance, and includes an evaluation set that can serve as a benchmark for future research in the field.\n- The paper is well-organized, easy to follow, and provides a clear motivation for the research, contributing to a better understanding of VLIT datasets and their evaluation.\n\n**Weaknesses**\n- The paper's novelty is somewhat limited as the evaluation paradigm and metrics seem to be derived from existing methods, with the primary contribution being the application of these to the field of VLIT.\n- The paper lacks a detailed explanation of the proposed evaluation paradigm and the rationale behind the choices made in the experiments, such as the selection of specific datasets and the justification for using BLEU as a metric.\n- The evaluation section is unclear and lacks empirical evidence to support the claims made about the effectiveness of the proposed evaluation paradigm.\n- The paper does not sufficiently address the limitations of the proposed approach and does not provide a comprehensive discussion of the implications of using the new dataset and evaluation paradigm.\n- The organization and structure of the paper could be improved for better clarity and flow, particularly in the presentation of related work and experimental results.\n- There is a lack of diversity in the datasets used for evaluation, which may not adequately represent the complexity and variability of real-world applications.\n\n**Questions**\n- How does the proposed evaluation paradigm differ from existing approaches, and what specific advantages does it offer in terms of comprehensiveness and accuracy?\n- Could the authors provide more details on the selection of datasets for evaluation and the specific reasons behind choosing BLEU as a metric?\n- How do the authors address the limitations of the proposed approach, and what implications does the use of the new dataset and evaluation paradigm have for the broader field of VLIT?\n- Could the authors clarify the motivation behind using the proposed evaluation paradigm and provide empirical evidence to support its effectiveness?\n- In light of the criticism regarding the novelty of the approach, can the authors provide a more detailed explanation of how their work contributes uniquely to the field of VLIT?\n- Could the authors discuss the potential issues or limitations of the proposed evaluation paradigm and provide suggestions for future work to address these challenges?",
        "5_3": "**Summary**\nThis paper introduces a novel approach for evaluating Vision-Language Instruction-Tuning (VLIT) datasets through a tune-cross-evaluation paradigm. This paradigm involves a two-stage learning process, where datasets are initially used for model tuning and subsequently serve as evaluation benchmarks. The authors propose a set of metrics, including Meta Quality (MQ), Dataset Quality (DQ), and Sample Quality (SQ), to quantify the quality of these datasets. By refining existing datasets, the authors created a new dataset named REVO-LION, aiming to provide a comprehensive evaluation framework for VLIT models. Despite its innovative approach and potential utility in the field, the paper suffers from several shortcomings, including unclear motivation, incomplete comparisons with existing datasets, and a lack of rigorous experimental validation. Additionally, the paper's methodology and conclusions have been critiqued for their practical implications and theoretical soundness.\n\n**Strengths**\n- The paper introduces a novel tune-cross-evaluation paradigm that innovatively utilizes existing VLIT datasets for both model development and evaluation, which is a significant advancement in the field.\n- The proposed evaluation framework is comprehensive, including metrics like MQ, DQ, and SQ, which are supported by clear, well-structured tables and figures, enhancing the clarity and utility of the paper.\n- The creation of a new dataset, REVO-LION, which integrates the best samples from existing datasets, is a valuable contribution to the community, potentially serving as a benchmark for future research.\n- The paper is well-written, making it easy to follow and understand, with a detailed explanation of the methodology and the rationale behind the proposed metrics.\n\n**Weaknesses**\n- The motivation behind the proposed evaluation framework is unclear, lacking a thorough explanation of why existing datasets are insufficient for evaluating VLIT models.\n- There is a significant overlap with existing datasets, which undermines the novelty and effectiveness of the new dataset REVO-LION.\n- The evaluation metrics (MQ, DQ, and SQ) rely on BLEU, METEOR, and ROUGE-L, which may not be optimal for evaluating the performance of VLIT models, especially given the differences in text style and complexity between generated texts and reference texts.\n- The paper lacks rigorous experimental validation, particularly in terms of demonstrating the superiority of the proposed evaluation framework over existing methods.\n- The discussion on the practical implications and theoretical soundness of the proposed approach is limited, making it difficult to fully assess the contributions of the work.\n- There are several presentation and formatting issues, such as unclear figures and tables, and a lack of clarity in the methodology section.\n\n**Questions**\n- Can the authors clarify the motivation behind the proposed evaluation framework and provide a detailed comparison with existing methods to highlight the advantages of their approach?\n- What are the specific differences between the new dataset REVO-LION and existing datasets, and how does it improve upon them?\n- How does the proposed evaluation framework handle the differences in text style and complexity between generated texts and reference texts?\n- Could the authors provide more details on the experimental setup, including the specific metrics used and the evaluation process?\n- In terms of the theoretical underpinnings, can the authors elaborate on how the proposed evaluation framework ensures the accuracy and reliability of the results?\n- Could the authors discuss the practical implications of their approach and how it can be applied in real-world scenarios?"
    },
    "MCNqgUFTHI": {
        "gold": "**Summary**\nThe paper introduces the Plug-and-Play Dialogue Policy Planner (PPDPP), designed for enhancing proactive dialogues within large language models (LLMs). PPDPP integrates both supervised fine-tuning and reinforcement learning to adapt LLMs to varied dialogue scenarios effectively. The proposed system utilizes a plug-in mechanism that allows easy adaptability and showcases its superiority over existing models in multiple proactive dialogue domains like negotiation, emotional support, and tutoring. Evaluation through empirical experiments on three datasets demonstrates promising results in automatic and human evaluations, highlighting the system's efficient transferability. The approach notably helps LLMs transition from passive instruction-following to actively steering conversations in goal-oriented dialogues.\n\n**Strengths**\n- The paper introduces an innovative plug-and-play dialogue policy planner using Large Language Models (LLMs) for proactive learning, which showcases flexible adaptability across different dialogue domains.\n- Empirical results across three datasets demonstrate commendable outcomes in both automatic and human evaluations, indicating good transfer capabilities.\n- The integration of the LLM as a reward function for reinforcement learning (RL)-based dialogue planning provides a novel approach to dynamic prompt selection and adaptability.\n- The study combines supervised fine-tuning with online RL for training the dialogue policy ranker, optimizing the dialogue action prediction and enhancing overall system performance.\n\n**Weaknesses**\n- The dialogue LLM operates within a restricted action/prompt space, potentially limiting its adaptability and application across varying dialogue domains.\n- The distinctiveness of the approach from other Reinforcement Learning from AI Feedback (RLAIF) methodologies appears minimal, primarily centering around mapping the LLM\u2019s text output to scalar rewards, raising concerns about the uniqueness and revolutionary nature of the proposed system.\n- The need for individual training of dialog policies for each domain restricts the system's generality and scalability.\n- The proposed system appears somewhat improvised as the policy planner (PPDPP) is segregated from the dialogue LLM and relies heavily on pre-defined prompts rather than generating new, context-specific prompts dynamically.\n\n**Questions**\n- Could you explain the negative relative success rate noted in Figure 2 of the study?\n- How is the reward LLM utilized during the real-time inference within each dialogue turn, particularly relating to the decision-making process?\n- Can you detail the process and rationale behind the conversion of reward LLM\u2019s textual output into scalar reward values and how these integrate into the dialogue policy planning during individual dialogue interactions?\n- The supervised fine-tuning applied to the PPDPP: could you elaborate more on this process, its aims, and benefits?\n- In Equation 6, you mention sampling goal-oriented AI feedback multiple times; does this method observe a significant variance in the rewards provided by the LLM, and if so, what strategies are employed to mitigate this variance?",
        "5_5": "**Summary**\nThe paper introduces a Plug-and-Play Dialogue Policy Planner (PPDPP) aimed at enhancing proactive dialogue systems using Large Language Models (LLMs). PPDPP leverages a novel training framework that combines supervised fine-tuning and reinforcement learning from goal-oriented AI feedback to optimize dialogue policy planning. This approach is evaluated across three different proactive dialogue applications, demonstrating superior performance over existing methods. The framework includes the use of LLMs as user simulators and reward models, offering a novel interactive evaluation protocol for assessing the effectiveness of dialogue systems. Despite its promising results, the paper faces criticism for unclear presentation, insufficient technical contributions, and the limited scope of experimental evaluations.\n\n**Strengths**\n- The proposed Plug-and-Play Dialogue Policy Planner (PPDPP) is a novel and innovative approach that integrates supervised fine-tuning and reinforcement learning to optimize dialogue policy planning, showing significant improvements over existing methods.\n- The paper is well-structured and easy to follow, making it accessible to readers.\n- PPDPP introduces a new training framework that allows for the tuning of a language model plug-in, enhancing the adaptability of the system to different dialogue applications.\n- The use of LLMs as user simulators and reward models is highlighted as a significant technical contribution, offering a novel interactive evaluation protocol that assesses the effectiveness of dialogue systems.\n\n**Weaknesses**\n- The paper suffers from clarity issues, particularly in the introduction, which lacks a clear explanation of the problem and the proposed solution, making it difficult for readers to understand the context and significance of the research.\n- The technical contributions of the paper are perceived as incremental, mainly involving the application of existing methods to dialogue systems without substantial innovation.\n- The experimental evaluation is limited in scope and does not adequately cover a broad range of dialogue applications, raising concerns about the generalizability of the results.\n- There is a lack of ablation studies and discussion on the impact of different components of the proposed framework, such as the role of LLMs as user simulators and reward models.\n- The paper does not sufficiently discuss the ethical implications of using LLMs in dialogue systems, particularly in scenarios involving sensitive or critical decisions.\n\n**Questions**\n- Can you provide a clearer explanation of the problem addressed by PPDPP and how the proposed solution aims to address it?\n- How do the technical contributions of this paper differentiate from existing methods, and what innovative aspects do they bring to the field of dialogue systems?\n- What are the specific dialogue applications used in the experimental evaluation, and can you explain the rationale behind selecting these particular applications?\n- Could you elaborate on the design choices made in the PPDPP framework, particularly the roles of LLMs as user simulators and reward models, and their impact on the system's performance?\n- In light of the ethical concerns raised by the use of LLMs in dialogue systems, what measures do you propose to ensure the responsible deployment of these systems in real-world scenarios?",
        "5_3": "**Summary**\nThe paper introduces Plug-and-Play Dialogue Policy Planner (PPDPP), a novel approach for improving LLM-powered dialogue systems by integrating a tunable language model plug-in for dialogue policy planning. PPDPP utilizes a self-play dialogue simulation to optimize the policy agent's behavior based on scalar rewards derived from an LLM-based reward model. The system is tested across three proactive dialogue tasks, showing promising results over existing baselines. Despite its innovative application of reinforcement learning in dialogue policy planning and the introduction of a novel training framework, concerns have been raised regarding the clarity of the paper, the generalizability of the approach, and the novelty of the method.\n\n**Strengths**\n- The paper presents an innovative method by integrating reinforcement learning (RL) into dialogue policy planning, specifically utilizing an LLM as the reward model, which provides an interesting perspective for future research.\n- The proposed Plug-and-Play Dialogue Policy Planner (PPDPP) framework is designed to enhance the dialogue policy planning capabilities of Large Language Models (LLMs) by incorporating a tunable language model plug-in, which is shown to outperform baseline methods in multiple proactive dialogue tasks.\n- The paper introduces a novel training framework that combines supervised fine-tuning and RL from goal-oriented AI feedback, aiming to enhance the generalizability of the dialogue policy planner across various dialogue tasks.\n- The approach is evaluated across three different proactive dialogue tasks, demonstrating the effectiveness of the proposed method in terms of dialogue-level metrics such as success rate and average turns.\n\n**Weaknesses**\n- The paper lacks a clear explanation of the role and functionality of the tunable language model plug-in within the PPDPP framework, making it difficult to understand its specific contribution to the system.\n- The novelty of the approach is questioned, as similar RL-based methodologies have been previously explored in other works, such as the paper by Fu et al. cited in the review.\n- The experimental evaluation is not comprehensive, as it primarily focuses on a single dataset (CraigslistBargain) for negotiation dialogues and lacks a broader set of comparative baselines.\n- The paper's presentation could be improved by providing more detailed explanations of the methods and results, and by addressing the potential limitations and future research directions more explicitly.\n- The generalizability of the approach to other domains or dialogue tasks beyond the ones tested is not clearly demonstrated, raising concerns about the robustness of the method.\n\n**Questions**\n- Could the authors clarify the specific role and functionality of the tunable language model plug-in within the PPDPP framework?\n- How does the proposed method compare to other existing RL-based methods in dialogue policy planning, particularly in terms of its effectiveness and efficiency?\n- Is the performance of the proposed method significantly different when using different LLMs as the reward model or the policy agent?\n- Can the authors provide more detailed explanations of the experimental setup, including the choice of datasets and baselines, and the metrics used for evaluation?\n- How does the proposed method handle out-of-domain tasks, and what are the potential limitations or challenges when applying this method to different dialogue tasks or domains?"
    },
    "OJoMzslBIa": {
        "gold": "**Summary**\nThe paper under review proposes a novel reweighting scheme in the context of Out-of-Distribution (OOD) detection, inspired by supervised contrastive learning to better manage the inter-class distance and intra-class variance. Named ReweightOOD, this method dynamically adjusts weights for hard positives and negatives based on similarity scores to enhance OOD detection efficacy. The methodology leverages contrastive optimization to create an OOD-friendly embedding space, with experiments conducted on benchmark datasets such as CIFAR100 and ImageNet100 showing performance gains. While the approach counters the common issue of class overlap in traditional distance-based OOD detections by enforcing minimum enclosing spheres and higher inter-class separations, there are concerns about its novelty, experimental comprehensiveness, and results presentation clarity.\n\n**Strengths**\n- The motivation behind the study is clear, and the presentation throughout the paper is coherent and easy to follow.\n- The proposed method, which includes dynamic adjustment of weights for positives and negatives based on the similarity score, is novel and straightforward.\n- Empirical evidence is provided to demonstrate the effectiveness of the method, highlighted by performance gains on CIFAR10/100 and ImageNet100 as well as improved metrics like MES and inter-class dispersion.\n- The paper addresses a crucial issue, enhancing the safety and reliability of Out-of-Distribution (OOD) detection in neural networks.\n- The method's simplicity contributes to its practicality and ease in implementation, particularly in integrating reweighting with contrastive optimization.\n\n**Weaknesses**\n- The novelty of the proposed method is somewhat limited, as the concept of hard sample mining and weighting has been extensively explored in fields like deep metric learning.\n- The method's performance comparison is restricted primarily to CIFAR100 and ImageNet100, lacking broader validation on more diverse datasets such as ImageNet-1K.\n- Despite impressive claims, the actual improvement over state-of-the-art methods is not significant, particularly when compared to recent OOD detection baselines like ReAct and ASH.\n- Detailed comparisons and additional baseline evaluations (e.g., CIDER, ASH, GradNorm) are missing, which could provide a clearer perspective on the method's relative performance.\n- Some figures and tables (like Figure 5 and Table 2) are criticized for their design and content, which could be improved for clarity and effectiveness.\n- The paper is missing comprehensive ablation studies on effects of parameters changes, additional backbones or datasets variations, and experiments demonstrating scalability concerning category numbers.\n\n**Questions**\n- Can the authors clarify the differences between their work and prior studies such as CurricularFace and AdaFace in terms of hard samples re-weighting?\n- Why is there only one cluster depicted in Figure 5(b), and can the authors provide feature visualizations for comparative models like SupCon or CIDER?\n- Are results from other methods on ImageNet100 besides SupCon available for comparison? If not, why were these not included in the study?\n- What is the rationale behind the specific settings of the hyperparameters in the linear transformation layers, particularly for different datasets or neural network architectures?\n- Could the article benefit from exploring learnable temperatures or other methods to enhance inter-class separation, and how might these compare to the current instance weighting approach?\n- How does the proposed method perform when adapted to different numbers of classes or when applied to transformer-based architectures?",
        "5_5": "**Summary**\nThe paper introduces a novel method called ReweightOOD, which aims to improve out-of-distribution (OOD) detection in neural networks by optimizing the contrastive loss function through a reweighting mechanism. This method focuses on enhancing the separation between in-distribution (ID) and OOD samples in the embedding space by maximizing inter-class dispersion and minimizing the Minimum Enclosing Sphere (MES) for each class. The paper presents experiments conducted on various datasets, comparing ReweightOOD with existing methods and demonstrating its effectiveness. The approach leverages the concept of similarity optimization, prioritizing the optimization of less-optimized contrasting pairs and assigning lower importance to already well-optimized contrasting pairs. This innovative reweighting scheme is evaluated through empirical experiments, showing significant improvements in OOD detection.\n\n**Strengths**\n- The paper is clearly written, easy to follow, and well-organized, which facilitates comprehension and engagement with the content.\n- The methodological approach is sound, well-motivated, and grounded in a reasonable theoretical foundation, providing a solid basis for the proposed techniques.\n- The paper addresses a significant and challenging problem in the field of OOD detection, which is crucial for improving the reliability and trustworthiness of machine learning models.\n- The experimental setup is robust, including extensive ablation studies and thorough evaluations using various datasets and metrics, which helps to validate the effectiveness and generalizability of the proposed method.\n- The paper provides a comprehensive review of related works and effectively situates the proposed method within the existing literature, demonstrating a good understanding of the current state-of-the-art.\n\n**Weaknesses**\n- The novelty of the proposed method is somewhat limited, as the approach primarily involves reweighting the loss function, which has been explored in prior works. The specific application to OOD detection, while relevant, may not constitute a groundbreaking innovation.\n- The paper could benefit from a more detailed explanation of the chosen similarity metric, particularly how it relates to the cosine similarity used in standard contrastive learning frameworks. This would help in understanding the rationale behind the chosen metric and its implications for the method's performance.\n- The experimental setup lacks a clear comparison with recent and relevant works, particularly those that also address OOD detection using contrastive learning. This omission weakens the paper's ability to demonstrate its superiority over existing methods.\n- The paper does not provide sufficient details on the implementation of the proposed method, such as the specific hyperparameters used or how the method is integrated into existing contrastive learning frameworks. This lack of clarity could hinder reproducibility and practical application of the proposed method.\n- There are concerns about the generalization capabilities of the proposed method across different datasets and network architectures, as the experiments primarily focus on a specific scenario with a ResNet-18 architecture and CIFAR-100 dataset.\n\n**Questions**\n- Can the authors clarify the choice of the similarity metric used in the proposed method and explain how it aligns with the cosine similarity commonly used in contrastive learning?\n- How does the proposed method compare with other recent works that also employ contrastive learning for OOD detection? Could the authors provide a more detailed comparative analysis to establish the relative strengths and weaknesses of their approach?\n- What specific hyperparameters were used in the experiments, and how were they determined? Additionally, can the authors provide more details on the implementation of the proposed method within existing contrastive learning frameworks?\n- Could the authors address the concerns regarding the generalization capabilities of the proposed method across different datasets and network architectures? Are there plans to conduct experiments on a broader range of datasets and architectures to better establish the method's robustness and applicability?\n- Given the focus on OOD detection using contrastive learning, how does the proposed method compare with other methods in terms of computational efficiency and scalability, particularly in large-scale datasets and complex network architectures?",
        "5_3": "**Summary**\nThe paper introduces a novel method called ReweightOOD for Out-of-Distribution (OOD) detection, focusing on the reweighting of contrastive learning loss based on the similarity between positive and negative samples in the embedding space. The proposed method aims to enhance the inter-class dispersion and minimize the Minimum Enclosing Sphere (MES) radius, thereby improving the detection of OOD samples. Extensive experiments on various datasets demonstrate the effectiveness of ReweightOOD compared to existing methods. However, the paper's novelty is questioned as the reweighting mechanism is somewhat similar to existing methods, and the theoretical underpinnings are lacking. Furthermore, there are concerns about the clarity of the paper and the experimental setup.\n\n**Strengths**\n- The proposed method is intuitive, and the paper is well-written, making it easy to understand.\n- The proposed method shows promising experimental results, outperforming existing methods.\n- The approach of applying a reweighting function to contrastive learning loss is novel and offers an interesting perspective.\n- The paper is clearly structured, with a good summary and conclusion, making it easy for readers to grasp the key points.\n- The use of the sigmoid function to model the reweighting function is well-motivated and provides a novel perspective on the optimization problem.\n\n**Weaknesses**\n- The novelty of the paper is questionable as the reweighting mechanism appears similar to existing methods, particularly in the use of a sigmoid function.\n- The theoretical analysis is lacking, and the paper does not provide a clear explanation of why the proposed method should work or how it improves upon existing approaches.\n- The experimental results are not convincing, particularly the improvement over the baseline is marginal, and the results on ImageNet100 are inconsistent.\n- There are concerns about the clarity and organization of the paper, with some sections being difficult to follow and the figures and tables being confusing.\n- The paper does not sufficiently discuss related work, and the literature review is not comprehensive.\n- The paper's claims about the performance of the proposed method are not well-supported, and the experimental setup is unclear, particularly concerning the training and testing datasets used.\n\n**Questions**\n- Can the authors provide a more detailed explanation of why the proposed method should work and how it improves upon existing approaches?\n- What is the rationale behind the choice of the sigmoid function, and how does it differ from existing methods?\n- Could the authors clarify the experimental setup, particularly regarding the training and testing datasets used?\n- Why was the ImageNet100 dataset chosen for fine-tuning the pre-trained models, and what are the implications of this choice?\n- How does the proposed method compare to other reweighting methods, such as those in prior works, and what are the advantages of the proposed method?\n- Could the authors provide a more comprehensive literature review and discuss related work in more detail?\n- Is it possible to provide more convincing experimental results, such as a detailed analysis of the performance improvements over the baseline?"
    },
    "oTRekADULK": {
        "gold": "**Summary**\nThe paper introduces SparseDiff, a novel approach to enhance the scalability of graph diffusion models by combining sub-graph sampling and sparse message-passing neural networks. SparseDiff extends existing models like DiGress by employing a noise model that preserves sparsity during diffusion, using a sparse transformer for denoising, and computing loss on a subset of all node pairs. Despite these innovations, the contributions are viewed as incremental, mainly extending prior works such as DiGress and EDGE. The method suffers from presentation issues, including unclear methodology and formatting problems, and lacks comprehensive empirical validation, especially in scaling to very large graphs.\n\n**Strengths**\n- The proposed approach innovatively uses techniques to leverage the sparsity of the graphs during training, addressing scalability issues in diffusion model graph generation, which has been a notable challenge.\n- The development and architectural design of the model are clearly and comprehensively demonstrated, making its operational logic convincing.\n- The paper contributes to a rapidly growing interest in deep models for diffusion-based graph generation, with the core concept of sampling a fraction of node pairs for inclusion in message-passing being a reasonable approach.\n- The paper comprehensively covers related works, providing a good foundation and context for the research.\n\n**Weaknesses**\n- The contributions, while valuable in addressing sparsity, appear largely incremental as many elements are derived or extended from existing models such as DiGress and EDGE.\n- Despite claims of scalability, the method involves quadratic complexity in graph generation (sampling) which remains a performance bottleneck.\n- The paper suffers from numerous presentation issues, including unclear writing in places, grammatical errors, and inconsistent formatting. Specific description problems, such as typos on several pages and unclear notation, impact the readability and professionalism of the manuscript.\n- The experimental section lacks a comprehensive empirical study, particularly missing deeper analysis on very large graphs and the effect of including large graphs in training datasets. There is also a concerning inconsistency in the use of baselines across datasets.\n- Theoretical support for the model's efficacy, such as guarantees on the generative capabilities or thorough time complexity analysis, is missing.\n\n**Questions**\n- 1. Could the authors provide additional clarification on the model architecture and the specific roles of components like PNa and FiLM, given that the absence of an appendix creates confusion?\n- 2. Throughout the different calls to the model during sampling, is the edge list updated each time, and if so, how does this impact performance and complexity?\n- 3. It would be beneficial to understand better why there is significant performance improvement in certain datasets over DiGress if the method is an extension of it. What are the underlying factors leading to these improvements?\n- 4. How can the authors justify the exclusion of GraphARM and SaGess in the large graph experiments, and could inclusion of such models offer a more balanced comparison?\n- 5. For a clearer understanding of the method's approach and scalability, could the training and sampling procedures be outlined more clearly in the text, possibly with algorithms detailed in the main document rather than the appendix?\n- 6. The paper mentions avoiding distribution shifts by exploiting sparsity only during the training phase. Can the authors clarify how the model maintains accuracy without introducing significant shifts in the distribution it learns?",
        "5_5": "**Summary**\nThe paper introduces SparseDiff, a scalable denoising diffusion model for graph generation that leverages sparsity during training and sampling phases. The model comprises a sparse diffusion process, a noise model that preserves sparsity, and a sparse graph transformer, all designed to handle edge list representations efficiently. Experimental results demonstrate that SparseDiff achieves comparable or better performance to state-of-the-art methods on small and large graphs. Despite these strengths, the paper suffers from several significant weaknesses, including poor clarity, lack of novelty, and insufficient comparison with existing methods. The paper also fails to address scalability issues in the sampling phase and lacks detailed ablation studies.\n\n**Strengths**\n- The paper addresses the scalability issue in graph generation by proposing a novel approach that leverages sparsity, enabling the generation of graphs with a larger number of nodes compared to previous methods.\n- The use of sparse diffusion models allows for efficient training and sampling, which is critical for large-scale graph generation tasks.\n- The methodology is well-motivated and the paper is clearly written, making it easy to follow.\n- The experimental results demonstrate that SparseDiff achieves state-of-the-art performance on both small and large graphs.\n- The proposed method is versatile and can handle different types of graphs, including molecular graphs and protein graphs.\n\n**Weaknesses**\n- The paper lacks a detailed explanation of the methodology, particularly the sparse diffusion process and the sparse graph transformer, which are crucial components of the model.\n- The novelty of the proposed method is questionable as it builds upon existing work without sufficient differentiation or explanation of its unique contributions.\n- The paper does not adequately address scalability issues in the sampling phase, which is a significant concern for large-scale graph generation tasks.\n- The experimental evaluation is limited and lacks a comprehensive comparison with existing methods, particularly those that also exploit sparsity.\n- The paper contains several typos and unclear statements that detract from its readability and professional quality.\n- The ablation studies are insufficient, and the paper does not provide a thorough analysis of the impact of different components of the model.\n\n**Questions**\n- Could the authors clarify the differences between the sparse diffusion process and the sparse graph transformer, and provide more details on how these components interact with each other?\n- How does the proposed method handle scalability issues in the sampling phase, and what strategies are employed to address these challenges?\n- What are the specific advantages of the proposed method over other existing methods that also exploit sparsity, and how do these advantages translate into practical benefits for graph generation tasks?\n- Can the authors provide a more detailed explanation of the motivation behind the use of sparse diffusion models in graph generation, and how this approach is expected to improve scalability and performance?\n- What are the key differences between the proposed method and other state-of-the-art graph generation methods, and how do these differences impact the performance and scalability of the model?",
        "5_3": "**Summary**\nThe paper introduces SparseDiff, a novel generative model for graphs that utilizes sparse diffusion techniques to enhance scalability and efficiency in generating large-scale graph structures. It incorporates a sparse message-passing neural network and a sparsity-preserving noise model, enabling the model to efficiently process sparse graph data. The paper evaluates SparseDiff across various graph datasets, demonstrating its capability to produce high-quality results and outperform existing methods in terms of both speed and performance. However, the paper faces criticism for its unclear motivation, particularly the justification of its sparse diffusion approach, and its lack of comparative analysis with other scalable models.\n\n**Strengths**\n- The paper is well-organized, clear, and easy to read, with the use of pseudocode enhancing the readability and understanding of the proposed method.\n- The authors provide a detailed description of the proposed method, including the architecture, training, and inference processes, which is well-supported by a comprehensive set of experiments.\n- The experimental results demonstrate that the proposed method is capable of generating high-quality results across various graph datasets, indicating its effectiveness in graph generation.\n- The paper is well-written, making it easy to follow, and the inclusion of a visualization of the iterative sampling process provides a clear overview of the model's operation.\n- The introduction of a novel approach to scalability in graph generation by leveraging sparsity, which is a novel and interesting direction in the field.\n\n**Weaknesses**\n- The paper lacks a clear motivation for the use of sparse diffusion in graph generation, and the rationale behind this approach is not adequately explained.\n- There is a lack of a comparative analysis with other scalable models, which limits the evaluation of the proposed method's effectiveness in the context of current scalable models.\n- The experimental evaluation seems limited, primarily focusing on datasets with small to medium-sized graphs. The scalability and applicability of the method to larger graphs, such as those with over 1,000 nodes, are not adequately demonstrated.\n- The paper does not address the computational complexity and efficiency of the proposed method, particularly how it compares with other models in terms of training and inference time.\n- Some methodological details, such as the use of message-passing neural networks and the handling of graph features during training, are not sufficiently explained or justified.\n- The paper does not discuss related works comprehensively, particularly those that also address scalability in graph generation, which could provide a richer background for the proposed method.\n\n**Questions**\n- Could the authors clarify the motivation behind using sparse diffusion in graph generation? What specific advantages does this approach offer over traditional methods?\n- How does the proposed method compare to other scalable models in terms of training and inference efficiency? Can the authors provide a detailed analysis of the computational complexity of their approach?\n- The paper mentions a novel approach to scalability using sparsity; can the authors provide more details on how this approach differs from existing methods and its advantages in terms of scalability and efficiency?\n- Could the authors expand on the experimental evaluation to include larger graphs and a broader range of datasets to better demonstrate the method's scalability and effectiveness?\n- How does the method handle graph features during training, and can the authors provide more details on the message-passing neural network used in the study?\n- In terms of the sparsity-preserving noise model, could the authors clarify its specific design and implementation within the proposed method?"
    },
    "P895PSh41Z": {
        "gold": "**Summary**\nThe paper introduces Relaxed State-Adversarial Offline Reinforcement Learning (RAORL), a novel approach in offline RL that creatively integrates adversarial robust reinforcement learning with a model-free framework. RAORL optimizes policy robustness by constructing an uncertainty set of plausible dynamics, leveraging adversarial perturbations to ensure risk-aware policy performance. The method is validated on the D4RL benchmark, demonstrating its effectiveness and potential for risk-sensitive applications. Despite its theoretical contributions and empirical achievements, reviewers noted concerns, including its similarities to existing methods, unclear presentation, and inadequate state-of-the-art comparisons.\n\n**Strengths**\n- The paper introduces an innovative concept by adapting an existing online robust RL algorithm (RAPPO) to the offline setting, integrating adversarial robust reinforcement learning with offline model-free reinforcement learning within a state-adversarial optimization framework.\n- It presents robust theoretical foundations and provides theoretical guarantees for an idealized version of the algorithm.\n- The performance of RAORL on D4RL is impressive and shows strong results, especially evident in the AntMaze tasks, demonstrating the algorithm\u2019s efficacy compared to previous methods.\n- It offers a lower bound guarantee which distinguishes and potentially significantly contributes to the field of reinforcement learning.\n\n**Weaknesses**\n- The paper's structure and organization could be improved to clearly convey its primary contributions, as the narrative is somewhat difficult to follow due to convoluted writing.\n- The distinctions between RAORL and RAPPO are not substantially articulated, specifically regarding offline application, solver differences, and hyperparameter tuning.\n- There is a lack of comparison with state-of-the-art algorithms like SAC-N, EDAC, and LB-SAC, reducing the persuasiveness of the experimental results.\n- The content occasionally engages in excessive self-promotion which might detract from its academic tone.\n- Some theoretical results appear very similar to existing works (e.g., MoREL paper), and these similarities or differences are not adequately discussed.\n- The experimental setup does not include stochastic tasks, despite the claims of addressing environments where model-based algorithms struggle.\n- The paper does not incorporate or thoroughly compare with related robust RL approaches, such as RORL and S4RL, which are critical for establishing novelty and significance.\n\n**Questions**\n- Could you clarify whether the expectation over s, a in Definition 1 covers all transitions in the offline dataset?\n- In Definition 3, do the transition probabilities require re-normalization if the argmin defining Z\u03c3\u03c0 contains more than one state?\n- How were the perturbations selected in section 5.3?\n- How effectively does RAORL bridge the performance gap in real-world applications as claimed?\n- What is the primary advantage of RAORL, and can you provide more evidence or explanation to support its claimed advantages over other offline model-free algorithms?\n- Can you detail the learning objectives for both value functions and policy, and provide more implementation details in the Appendix to facilitate reproduction of the results?\n- Could a comparison with the prior state adversarial baseline RORL be included in the state perturbation experiments?\n- How was the attack budget (\u03b5) determined in RAORL, and what impacts do the hyperparameters \u03b5 and \u03b1 have on performance?",
        "5_5": "**Summary**\nThe paper introduces a novel approach called Relaxed State-Adversarial Offline Reinforcement Learning (RAORL), which integrates a model-free offline RL method with a state-adversarial perturbation to enhance policy robustness and adaptability to varying transition dynamics. RAORL employs a conservative value function to address model uncertainty in offline settings, which is supported by both theoretical analysis and empirical evidence. The method has been evaluated against state-of-the-art methods on established offline RL benchmarks, showing competitive performance. The core idea revolves around the application of the relaxed state-adversarial approach to offline RL, which allows the policy to perform well in a variety of environments.\n\n**Strengths**\n- The paper is well-written, clear, and easy to follow, making it accessible to a broad audience.\n- The proposed method combines robust RL principles with model-free offline RL, which is a novel and promising approach that shows potential for handling offline RL challenges.\n- Theoretical analysis and empirical results support the efficacy of the proposed method, demonstrating its effectiveness in improving offline RL performance.\n- The method's ability to improve upon existing offline RL methods like TD3+BC and ReBrac by reducing the performance gap and enhancing the robustness of the learned policy is noteworthy.\n- The paper is well-organized, making it easy to understand and follow, and the authors provide a good comparison with other related methods in the literature.\n\n**Weaknesses**\n- The paper does not sufficiently differentiate its contributions from existing works, particularly those that address robustness in offline RL settings.\n- The experimental evaluation is limited in scope and does not include a diverse set of benchmarks, which could potentially limit the generalizability of the results.\n- The theoretical analysis, while comprehensive, may not fully account for all possible scenarios, such as non-linear dynamics or high-dimensional state spaces, which could impact the practical applicability of the proposed method.\n- The method's reliance on assumptions such as the Lipschitz continuity of the value function may limit its applicability in certain real-world scenarios.\n- The paper does not provide sufficient details on the experimental setup, including the choice of hyperparameters and the specifics of the offline datasets used.\n\n**Questions**\n- Can the authors clarify the specific contributions of this work in the context of existing literature on robust offline RL?\n- Why is the performance of RAORL on the door-cloned dataset not comparable to other methods? Is there a specific reason for this, and could it be related to the nature of the dataset or the method used?\n- How do the authors address the potential limitations of their theoretical analysis, particularly regarding non-linear dynamics and high-dimensional state spaces?\n- Could the authors provide more details on the experimental setup, including the choice of hyperparameters and the specifics of the offline datasets used?\n- In terms of reproducibility, can the authors provide the source code for the experiments and the exact details of the datasets used?\n- Could the authors discuss the implications of the assumptions used in their theoretical analysis and how they might affect the practical applicability of the proposed method?",
        "5_3": "**Summary**\nThis paper introduces RAORL, a novel offline reinforcement learning (RL) algorithm that integrates a model-free approach to address the robustness and adaptability of RL policies in offline settings. The method is designed to handle the discrepancies between offline datasets and real-world environments by employing a state-adversarial transition kernel, which provides a model-free solution to the robust offline RL problem. The paper provides theoretical guarantees and experimental results on various continuous control tasks, showing that RAORL can outperform existing methods in some benchmarks. However, the paper faces criticism for its limited scope in addressing more complex or dynamic environments and for not fully comparing its performance with the latest state-of-the-art methods.\n\n**Strengths**\n- The paper introduces a novel approach by integrating the relaxed state-adversarial method into offline RL, enhancing the robustness of the policy.\n- The proposed method is model-free, which simplifies the implementation and reduces the risk of model errors.\n- The paper provides a theoretical foundation and a thorough experimental validation, which strengthens the credibility of the results.\n- The approach is flexible and can be easily integrated with existing model-free offline RL methods, allowing for a variety of policy optimization techniques to be combined.\n- The paper is well-written, making it easy to follow and understand.\n\n**Weaknesses**\n- The paper lacks a detailed explanation and formal definition of key concepts such as the uncertainty set U, the worst-case transition kernel P*, and the state-adversarial transition kernel.\n- The experimental results and comparisons are limited, particularly in terms of the environments tested and the variety of baseline methods considered.\n- The paper does not address how the proposed method performs in more complex or dynamic environments, such as those with multiple agents or continuous action spaces.\n- There are concerns regarding the novelty of the approach, as it primarily integrates known techniques into offline RL settings.\n- The paper's claims about the generalization ability of the algorithm are not adequately supported by the experimental evidence.\n- The robustness of the policy against adversarial perturbations is not convincingly demonstrated, as the results presented are not significantly different from those of the baseline methods.\n\n**Questions**\n- Can the authors clarify the formal definitions and explanations of the uncertainty set U and the state-adversarial transition kernel?\n- How does the proposed method perform in more complex or dynamic environments, such as those with multiple agents or continuous action spaces?\n- What are the specific challenges faced by the proposed method in these environments, and how does it address these challenges?\n- Why is the proposed method not compared against more recent and relevant baseline methods, such as RORL and ReBrac?\n- Can the authors provide more detailed experimental results, including comparisons with additional baseline methods and a more thorough analysis of the performance in different environments?\n- How does the proposed method ensure the robustness of the policy against adversarial perturbations, and what specific measures are taken to achieve this?"
    },
    "qi88abxiE4": {
        "gold": "**Summary**\nThe paper proposes a new methodology for scaling spectral graph neural networks through the sparsification of Laplacian polynomials, aiming to retain essential spectral properties and enable both fast and end-to-end training across various datasets, including a very large-scale graph dataset. The proposed framework leverages prior work on random-walk-based spectral sparsification to make spectral GNNs more scalable by approximating the propagation matrix of Laplacian filters, which could potentially enhance the effectiveness of these neural networks on node classification tasks. Additionally, the paper attempts to bridge theoretical and experimental gaps by providing mathematical proofs to support its methodologies, although the paper has been critiqued for its practicality given the multitude of hyperparameters and potentially restrictive assumptions regarding the spectral GNNs addressed.\n\n**Strengths**\n- The paper addresses the critical issue of scalability in spectral graph neural networks and provides a clear motivation for this study. The relevance of scalability in large-scale applications is well established.\n- Empirical results demonstrated on Ogbn-papers100M emphasize the method's scalability. Additionally, the paper covers experiments with datasets of different sizes, showcasing the method's applicability to very large datasets.\n- There is a rigorous mathematical foundation provided, demonstrating through proofs the efficacy of spectral sparsification aimed at improving scalability in the training phase of GNNs.\n- The methodological explanation is clear, and the paper presents a theoretically analyzed approach. The experimental data often indicates improvement over the typical out-of-box GNN methods when using the sparsification strategy.\n\n**Weaknesses**\n- The paper's scope appears limited as it mainly applies to APPNP and GPR GNNs and does not provide results for other types of spectral GNNs, such as JacobiConv.\n- It is unclear whether the proposed methods would apply to non-linear models of spectral GNNs, particularly when they involve stacking layers of polynomial spectral filters interleaved with nonlinear activation functions like ReLU.\n- Although the study emphasizes scalability, there is insufficient comparison concerning computational efficiency (memory usage and wall-clock time) across various methods and datasets, missing a direct linkage to the scalability claims.\n- The theoretical underpinnings, while rigorous, are mostly derivative of prior works, with little novelty or critical insights into unique challenges posed by spectral sparsification.\n- Several methodological assertions and the experimental setup lack depth in explanation and comparative analysis, notably how spectral GNNs with sparsification fare against established benchmarks or similar recent approaches.\n- The writing needs improvement for clarity and coherence, with several sections requiring better structuring and reduction of redundant elements. Attention to details like proper and consistent notation, references, and proof environments in appendices is also necessary.\n\n**Questions**\n- 1. Is the proposed spectral GNN design applicable to models involving multiple layers with interleaved non-linearities such as ReLU? How would this affect the theoretical analysis?\n- 2. Could you provide specifics on the efficiency improvements (memory and computation time) realized by the node-wise sampling method described in Section 3.3, possibly including these details in an appendix?\n- 3. At what stage is the sampling (sparsification) procedure applied\u2014every forward pass or just at the initiation of training?\n- 4. How do you address the inconsistency between the sparsification approach benefiting only a few heterophilous datasets, with some datasets even showing degraded performance? What is the percentage of edges retained after sparsification, and how does this correlate with training efficiency and final model performance?\n- 5. To advance the understanding of scalability, could you discuss the thresholds or criteria used to determine the degree of sparsification or spectral similarity in practical scenarios? How do these choices affect GNN accuracy and overall performance metrics?\n- 6. Are comparison metrics against established or concurrent spectral GNN methodologies available, particularly those that also address scalability or utilize different forms of sparsification or polynomial approximations?",
        "5_5": "**Summary**\nThe paper introduces a novel method for graph sparsification using Laplacian sparsification techniques, aiming to enhance the scalability of spectral Graph Neural Networks (GNNs) by precomputing graph propagation matrices. The proposed method, which includes static and learnable variants, utilizes multi-hop neighbor interactions to reduce computational complexity while maintaining spectral properties of the graph. The authors provide theoretical proofs and empirical evidence demonstrating the effectiveness of their method across various graph datasets. However, the paper has been critiqued for its limited novelty, unclear presentation, and insufficient comparative analysis with other existing methods.\n\n**Strengths**\n- The paper introduces a novel approach to graph sparsification by employing Laplacian sparsification techniques, which enhances the scalability of spectral GNNs.\n- Theoretical proofs are provided, which support the correctness of the proposed methods and demonstrate that they generate Laplacian sparsifiers for the random-walk matrix polynomial.\n- Empirical results presented in the paper demonstrate the effectiveness of the proposed methods, showing stable improvements over the corresponding baselines across different real-world datasets.\n- The paper is well-written and easy to follow, with clear presentation of the methods and results, making it accessible to readers.\n- The proposed method can be applied to a wide range of GNNs, including spectral GNNs with learnable polynomial filters, which is a significant advantage.\n\n**Weaknesses**\n- The novelty of the paper is limited as it builds upon existing methods and techniques such as SGC, GLSGC, and APPNP-LS, with a lack of significant new theoretical contributions.\n- The paper does not adequately discuss the impact of the pre-computation on the performance of the GNNs, which is critical for understanding the effectiveness of the proposed method.\n- There is a lack of comparative analysis with other existing methods, which could provide a more comprehensive understanding of the proposed method's advantages and limitations.\n- The paper does not provide sufficient details about the training time, complexity, and scalability of the proposed methods, which are essential for evaluating the practical applicability of the method.\n- The experimental setup and results lack clarity, making it difficult for readers to understand the significance and impact of the proposed methods.\n\n**Questions**\n- Can the authors provide more detailed results on the training time and complexity of the proposed methods, especially in comparison with other methods?\n- How does the pre-computation of graph propagation matrices affect the performance of the GNNs, and what are the implications of this for the scalability and effectiveness of the proposed method?\n- Could the authors provide a more detailed comparative analysis with other existing methods to better highlight the advantages and limitations of the proposed method?\n- How does the proposed method perform on graphs with high-dimensional input features, and what are the implications for the scalability and effectiveness of the method in such scenarios?\n- Can the authors provide more information on the experimental setup and results, particularly the details of the datasets used and the hyperparameter settings, to aid in understanding the significance and impact of the proposed methods?",
        "5_3": "**Summary**\nThe paper introduces a Laplacian Sparsification method for enhancing the scalability of Spectral Graph Neural Networks (GNNs). It proposes a novel sampling algorithm based on the approximation of a polynomial filter on the Laplacian matrix, which allows for faster and more efficient training on large graphs. The approach is theoretically backed and empirically validated, showing potential improvements in performance and training speed over existing methods. However, the paper's clarity and organization were critiqued, with reviewers noting that certain sections were difficult to follow and that the experimental setup lacked depth. The paper also fails to adequately compare its method with other existing approaches, making it difficult to gauge its novelty and effectiveness.\n\n**Strengths**\n- The paper is well-motivated and addresses the important issue of scalability for spectral GNNs, which is critical for real-world applications.\n- Theoretical proofs are provided to support the method, enhancing the credibility and reliability of the approach.\n- The proposed method is simple to implement and has shown superior performance in experiments, indicating its practical utility.\n- The paper is well-written and clearly structured, making it easy to follow, and the results are clearly presented, which aids in understanding the effectiveness of the proposed method.\n\n**Weaknesses**\n- The paper lacks a detailed and rigorous comparison with existing works, particularly those mentioned in the literature review which could have strengthened the novelty and impact of the proposed method.\n- The theoretical proofs provided are limited in scope and do not cover all the assumptions and scenarios discussed in the paper, which might affect the general applicability of the method.\n- The method's effectiveness in specific scenarios, such as homogeneous graphs, is not clearly demonstrated, and the experimental results for some datasets are not convincing.\n- The paper has issues with clarity and organization, particularly in the introduction and related work sections, which could hinder understanding of the core contributions.\n- The experimental setup is somewhat limited, focusing mainly on node classification tasks and not adequately exploring other tasks like link prediction or graph classification.\n- There are concerns about the generalizability and practical application of the method, especially in more complex or dynamic graph environments.\n\n**Questions**\n- Could the authors clarify the specific contributions of the paper and how they differ from existing works, such as those mentioned in the related works section?\n- Can the authors provide more detailed explanations and proofs for the assumptions made in the theoretical analysis, particularly those that were not covered in the provided proofs?\n- How does the proposed method perform on other tasks such as link prediction and graph classification, and what are the implications for scalability and applicability in different scenarios?\n- In light of the concerns about the method's effectiveness and practicality, can the authors provide more convincing experimental results, especially for homogeneous graphs?\n- What are the potential applications of the proposed method in more complex or dynamic graph environments, and how does it compare to other spectral GNN methods in terms of scalability and performance?"
    },
    "qIn2IgMWYg": {
        "gold": "**Summary**\nThe paper introduces a method known as Iterative Search Attribution (ISA) that combines gradient descent and ascent to assess the relevance of input features in neural network predictions, enhancing model interpretability. It claims improvements over existing methods by offering more accurate and interpretable attribution, using a scale parameter in the iterative process that prioritizes significant parameters over others in subsequent iterations. Its effectiveness is demonstrated via experiments on datasets like ImageNet, and it reportedly outperforms state-of-the-art methods in insertion score evaluations. The authors provide a description of an innovative approach to constructing gradients integration paths and the method's efficacy is validated via comparative analysis with baseline methods.\n\n**Strengths**\n- The paper introduces an innovative approach by combining gradient descent (GD) and gradient ascent (GA) to construct integration paths in gradient-based attribution methods, potentially improving the interpretability and accuracy of saliency maps.\n- Promising qualitative results are shown in Figure 2, illustrating the effectiveness of the proposed method.\n- The paper is well-organized and clearly articulates key contributions, aiding in reader comprehension and highlighting the main innovations.\n- The corresponding code has been released, enhancing the paper's utility and facilitating reproducibility.\n- State-of-the-art experimental results are achieved, and detailed ablation studies validate the proposed methodology.\n\n**Weaknesses**\n- The paper's discussion on the distinction between local and global attribution methods is unclear, specifically regarding how these properties relate to input space.\n- It lacks a thorough theoretical analysis, particularly in justifying the chosen constraints in Section 4.3 and the effectiveness of the insertion and deletion metrics.\n- Some sections of the paper, including the algorithm description and Figure 1, contain typos and confusing statements that reduce readability and clarity.\n- There is a need for more rigorous justification for various ad-hoc design choices and hyper-parameters; the impacts of these elements on the attribution results are not well-explained.\n- The comparison with other methods is not extensive enough, with a limited range of models and newer methods could have been included to benchmark the proposed method's efficacy.\n- The efficiency of the methodology has not shown significant improvement due to its iterative nature, which could limit its practical applicability in some scenarios.\n\n**Questions**\n- Could you provide clearer definitions and comparisons regarding local versus global attribution methods?\n- Can you clarify the connections and the rationale behind the feature attribution discussed in Section 4.2?\n- Could you provide more in-depth theoretical justification for the constraints mentioned in Section 4.3? What implications arise if the hyper-parameter $S$ is not introduced?\n- Is it possible to include a more detailed quantitative analysis supporting the claim that the insertion score is a more representative indicator of the performance of attribution algorithms?\n- How does the proposed methodology perform in non-CNN models, given the assertion of poor performance of methods like Grad-CAM and Score-CAM in such models?\n- Could you discuss the sensitivity of the step size, learning rate, and scale parameters observed in Figure 3? What are the implications of this sensitivity on the method's robustness and reliability?",
        "5_5": "**Summary**\nThe paper introduces the Iterative Search Attribution (ISA) method for improving the interpretability of deep neural networks. ISA combines gradient ascent and gradient descent to iteratively identify and refine the importance of features in model inputs, aiming to enhance attribution results. The approach involves clipping relatively unimportant features and introducing a scale parameter to ensure the significance of the next iteration's parameters over the current. This method is compared to existing state-of-the-art attribution methods, demonstrating its effectiveness through experiments on the ImageNet dataset. However, the paper is criticized for its lack of clarity in writing and presentation, as well as insufficient ablation studies to substantiate the claims. Furthermore, it does not address the potential issues with the scale parameter's influence on attribution results and lacks a thorough comparison with other methods, such as SHAP and LIME, which are critical for establishing the robustness of the ISA method.\n\n**Strengths**\n- The paper is well-written, making it accessible and easy to follow, with clear explanations and effective use of visual aids like figures and tables to enhance comprehension.\n- The proposed method introduces a novel approach to feature importance estimation by combining gradient ascent and gradient descent, which is a logical and innovative concept in the field of explainable artificial intelligence (XAI).\n- The experimental results show that the proposed ISA method outperforms existing state-of-the-art attribution methods in image recognition interpretability tasks, highlighting the potential of this new approach.\n- The authors have performed comprehensive experiments to demonstrate the effectiveness of the proposed method, which include ablation studies to evaluate the influence of different parameters and various comparisons with existing methods.\n\n**Weaknesses**\n- The paper lacks a clear and detailed explanation of the motivations behind the proposed method, specifically why combining gradient ascent and gradient descent is necessary and how it addresses the limitations of existing methods.\n- The novelty of the approach is not convincingly demonstrated, with the paper heavily relying on existing literature and not providing sufficient evidence or justification for the superiority of the proposed method over others like SHAP and LIME.\n- The experimental design and analysis are not robust enough to fully support the claims made about the effectiveness of the ISA method. Notably, the paper does not address potential issues such as the influence of the scale parameter on the accuracy of feature importance estimation.\n- There are several inconsistencies and ambiguities in the presentation of the paper, including the use of similar terms like \"features\" and \"parameters\" which could lead to confusion.\n- The related work section is insufficiently detailed, lacking a comprehensive review of existing literature, which is necessary for contextualizing the contribution of the paper.\n\n**Questions**\n- 1. Could the authors provide more details on the motivations and rationale behind combining gradient ascent and gradient descent in the proposed method?\n- 2. What are the specific advantages of the proposed ISA method over existing methods like SHAP and LIME, and can the authors provide a more detailed comparison of these methods?\n- 3. How does the scale parameter in the ISA method affect the accuracy of feature importance estimation, and can the authors provide empirical evidence or theoretical analysis to address this concern?\n- 4. Could the authors clarify the apparent contradictions and inconsistencies in the presentation of the paper, particularly in the use of terminology and the explanation of methodologies?\n- 5. Can the authors discuss the potential limitations of the ISA method and how it could be improved or extended to address these limitations?",
        "5_3": "**Summary**\nThe paper introduces ISA, a novel method for attributing feature importance in deep neural networks. ISA employs both gradient ascent and descent to iteratively refine feature attributions, starting with a random input and adjusting parameters to maximize confidence in the predicted class. The method claims to outperform existing techniques by incorporating both ascending and descending gradient updates, which are believed to enhance the fidelity of attribution. However, despite its claims of superior performance, the paper lacks rigorous experimental validation and comparative analysis with other state-of-the-art methods. Several reviewers noted that the method's complexity and lack of clear algorithmic explanation make it difficult to fully grasp and replicate. Furthermore, the paper\u2019s theoretical underpinnings and empirical results are not convincingly robust, raising concerns about its overall contribution to the field.\n\n**Strengths**\n- The ISA method incorporates both gradient ascent and gradient descent strategies to iteratively refine feature attributions, which is a novel approach in the field of deep learning attribution.\n- The paper is well-organized, making it easy to follow, and includes a comprehensive literature review that provides a solid foundation for the proposed method.\n- The experimental setup is well-designed, and the ISA method demonstrates superior performance compared to other baseline methods.\n- The paper introduces the concept of diffusion-like iterative search, which is an innovative aspect that could potentially enhance the interpretability of deep neural networks.\n\n**Weaknesses**\n- The ISA method's complexity and lack of clear algorithmic explanation make it difficult to fully grasp and replicate, particularly for readers not familiar with the specific terminology used.\n- The theoretical underpinnings of the ISA method are not convincingly robust, with several claims about the method's advantages over other methods lacking solid experimental or theoretical support.\n- The paper does not adequately compare the ISA method with other state-of-the-art methods, making it difficult to gauge the true effectiveness and relevance of the proposed approach.\n- The experimental results are not convincing due to the small number of samples used (1000) and the lack of statistical significance testing.\n- The paper's overall contribution is unclear, and the paper does not sufficiently discuss the limitations of the ISA method, which is essential for evaluating its potential applications and future improvements.\n- There are significant issues with the paper's writing quality, including grammatical errors, unclear definitions, and insufficient details about the algorithm, which could hinder understanding and replication of the proposed method.\n\n**Questions**\n- Could you clarify the definition of \"attribute\" used in the paper and provide a detailed explanation of how it is utilized in the ISA method?\n- What specific problems does the ISA method aim to solve, and how does it address these issues compared to other existing methods?\n- Can you provide a more detailed explanation of the ISA method, particularly how the iterative refinement process works and how it differs from other methods like AGI and BIG?\n- Why was the decision made to use a diffusion-like iterative search strategy in the ISA method, and what are the potential benefits of this approach?\n- In the experimental setup, why were only 1000 samples used, and could you provide more details on the statistical significance testing that was conducted?\n- How does the ISA method handle different types of data, such as tabular data or text data, and what are the potential limitations of the method in these contexts?"
    },
    "qKKwQvepx0": {
        "gold": "**Summary**\nThe paper introduces a framework named Natural Language Constraints and Parameters (NLCP) aimed at enhancing the explainability and steerability of machine learning models using natural language. The proposed method represents statistical model parameters as natural language predicates, such as \"has a casual style,\" which can be steered and explained through optimization algorithms that handle both the continuous and discrete aspects of these predicates. The framework is evaluated across four statistical models (Clustering, Contrastive Learning, Regression, and Topic Modeling) using three different datasets. Evaluations leverage denotation and surface similarity scores judged using GPT-4. The authors demonstrate the practical application of NLCP in generating understandable image clusters and detecting variations in major topics, thereby hoping to provide an innovative approach to control and explain model behavior effectively.\n\n**Strengths**\n- The paper proposes an innovative idea of using natural language explanations based on different criteria, allowing explanations of cluster nodes for image clustering based on the style of images or type of objects.\n- The use of natural language sentences as binary feature extractors is considered novel.\n- The paper is well-written, easy to follow, and introduces a new framework leveraging the denotational semantics of natural language.\n- Demonstrations of proof-of-concept applications are provided, showing controllably generating explainable image clusters and describing major topic variations.\n- The idea of using a large language model (LLM) to generate natural language predicates to explain and guide model predictions is intriguing.\n\n**Weaknesses**\n- Some figures (e.g., Figure 1) and visualizations are unclear, particularly where learned parameter explanations are involved, and certain visualizations appear identical.\n- The contributions of the paper are not distinctly outlined in the introductory section which could be improved for clarity.\n- Mathematical notation used in the paper is confusing (e.g., [[c]] (\u03c6) and [[\u03c6]] (x)), making it difficult to distinguish and follow the roles of variables early in the document.\n- Theoretical justification for methods like OptimizeWandPhi and Discrete is weak and needs strengthening.\n- The experimental section seems limited and somewhat superficial (\"toyish\"), raising concerns about the practical applicability of the method in the current state of machine learning.\n- Extensive reliance on large language models for various steps throughout the approach raises issues about computational feasibility and potentially undermines the paper's contribution as appearing ad hoc.\n- Insufficient variety and volume in datasets used for experiments make it difficult to evaluate the effectiveness of the method fairly.\n- The method's overall structure and accommodations for different parameters are not well illustrated or explained.\n\n**Questions**\n- How can the evaluation of the method be ensured to be reliable and representative, particularly when relying on algorithms like GPT-4 for similarity ratings?\n- How are constraints like \"I want to cluster based on style\" determined and ensured to be representative?\n- Would it be possible and advantageous to assign natural language predicates to clusters in a post-hoc fashion?\n- Regarding equation (5), does it assign a zero probability to all sentences that don't match a certain topic? How computationally intensive is the process to verify each sentence against each predicate \u03c6i?\n- Could you expand on the subsection \"Modeling Uninformative Nuisances with a Base Distribution\"? How is the base distribution typically defined?\n- How exactly is the continuous unit vector \u03c6~k obtained, and why is there no need for a gradient estimator for back-propagation through non-differentiable discretization in your model?\n- Have more challenging tasks beyond the three datasets been explored to test the applicability of the proposed method?\n- Could you clarify if the primary goal of the paper is to use an LLM to generate explainable predicates, or if there are other optimization methods considered for generating these predicates?\n- How can this approach be integrated in an iterative human-in-the-loop setting, and does it allow re-utilizing previous predicates when incorporating new constraints?",
        "5_5": "**Summary**\nThe paper introduces a novel framework called NLCP (Natural Language Parameters with Constraints) aimed at improving the explainability and steerability of statistical models in text. NLCP employs a two-step optimization process, initially using gradient descent to optimize a continuous relaxation of natural language parameters, followed by a refinement step that converts these into discrete parameters. This approach is demonstrated across various statistical models such as clustering, topic modeling, and regression, utilizing datasets like the New York Times and AG News. The paper claims that this framework enhances the model's ability to learn from constraints and interpret its parameters in natural language, making the models more understandable and controllable.\n\n**Strengths**\n- The paper is well-written and provides a clear, intuitive explanation of the approach, making it easy to follow.\n- The proposed approach is novel and addresses the significant challenge of integrating natural language into statistical modeling, enhancing explainability and steerability.\n- The methodology is described as sound and the results are promising, with good performance reported on the datasets used.\n- The paper provides a comprehensive review of related work, which helps contextualize the research within the existing literature.\n- The inclusion of multiple baselines and various statistical models in the experiments adds depth to the evaluation.\n\n**Weaknesses**\n- The paper's focus on text modeling could benefit from including visualizations, such as word clouds or topic distributions, to better illustrate the results.\n- The use of a large language model (LLM) for feature extraction is not sufficiently justified, especially considering the potential for biased or irrelevant features.\n- The paper lacks detailed experimental results for certain models and datasets, which could be addressed by including additional tables or figures.\n- The paper could benefit from a more thorough discussion on the practical applications and limitations of the proposed method.\n- The comparison of the proposed method with other methods is not entirely fair, as some baselines use different datasets, which could skew the evaluation results.\n- The optimization of natural language parameters and the use of LLMs for feature extraction are not sufficiently explained, which could affect the reproducibility of the results.\n\n**Questions**\n- How does the paper ensure the robustness of the results, particularly concerning the use of LLMs for feature extraction?\n- Could the authors provide more details on the experimental results for all models and datasets, and explain the rationale behind the choice of baselines and datasets?\n- How does the proposed method handle the scalability of the model, especially in terms of computational efficiency?\n- What are the practical applications of the proposed method, and what are its limitations?\n- In the context of using natural language parameters, how does the paper ensure that these parameters are accurately and reliably extracted from the LLMs?\n- Could the authors elaborate on how the proposed method compares with other existing methods, and what advantages or disadvantages it offers over these methods?",
        "5_3": "**Summary**\nThe paper explores a novel method for enhancing explainability in machine learning models by optimizing natural language constraints (NLCs) within a neural language-conditioned probabilistic framework. The authors introduce the Neural Language Conditional Probabilistic (NLCP) model, which combines language models and probabilistic models to generate interpretable parameters, effectively allowing the model to reason about the data and incorporate domain knowledge. The model's performance is demonstrated through various experiments involving text clustering, topic modeling, and regression, showing its potential for improving explainability and controllability in machine learning systems. However, the paper faces criticism for its unclear presentation, lack of rigorous evaluation, and inadequate comparison with existing methods.\n\n**Strengths**\n- The paper is well-written, clear, and easy to follow, making it accessible to a broad audience.\n- It addresses a significant problem in explainable AI (XAI) by integrating natural language constraints with probabilistic modeling.\n- The method is innovative and allows for better interpretability of the model's predictions, enhancing the user experience.\n- The paper is technically sound, with a good balance between theoretical foundations and practical application.\n- The idea of using natural language constraints to improve model performance and interpretability is novel and intriguing.\n\n**Weaknesses**\n- The paper lacks rigorous evaluation, with most experiments using small datasets and not fully addressing the impact of different model sizes.\n- There is a significant gap in comparing the proposed method with existing baselines, especially those that do not rely on language models.\n- The paper does not clearly define or distinguish between \"explainability\" and \"controllability,\" which are used interchangeably.\n- The method's dependency on language models and its robustness to potential biases in these models are not sufficiently discussed.\n- The proposed method's scalability and applicability to larger, more complex datasets are not demonstrated.\n- The paper contains several grammatical errors and unclear definitions, which detract from its overall quality.\n- The evaluation metrics and methods used are not well-explained, and the results do not consistently demonstrate superior performance over existing methods.\n\n**Questions**\n- Could the authors clarify the distinction between \"explainability\" and \"controllability\" in the context of the paper?\n- How does the method ensure robustness against potential biases in language models used?\n- Can the authors provide more details on the evaluation metrics and methods used in the experiments?\n- What are the scalability and applicability of the method to larger, more complex datasets?\n- How does the method perform when compared to other existing methods that do not rely on language models?\n- Can the authors address the unclear definitions and grammatical errors noted in the paper?\n- What are the specific contributions of the paper, and how do they advance the state-of-the-art in XAI?"
    },
    "RXU6qde675": {
        "gold": "**Summary**\nThis paper introduces the Adversarial Enhanced Representation (AER), a novel graph embedding framework designed for link prediction in multi-layer networks. AER incorporates a representation generator, a layer discriminator, and a link predictor to manage both intra-layer and inter-layer representations through adversarial training. The representation generator leverages these learned representations to further enrich the intra-layer embeddings. Real-world datasets were employed to demonstrate the performance of AER, with some showing notable improvements over established baselines. Despite these strengths, there are concerns regarding the novelty of the approach, sufficiency in experimental comparisons, and overall coherence in methodological presentation.\n\n**Strengths**\n- The paper is well-organized and clear, making it easy for readers to understand the model and its intended applications in multi-layer network settings.\n- Extensive experiments demonstrate the effectiveness and efficiency of the proposed method in capturing relevant information across different layers of multi-layer networks.\n- The paper identifies an interesting and relevant problem in the domain of multi-layer networks, proposing a novel layer discriminator that appears promising in this context.\n- The experimental results show some improvement over existing baselines, and ablation studies underscore the necessity of the layer discriminator.\n- The paper considers an intriguing adversarial setting to learn edge representations that are \"layer-invariant\" and yet effective for intra-layer link prediction.\n\n**Weaknesses**\n- The novelty of the proposed approach is limited, as it heavily relies on well-known models and operators such as GCN and CNN without adequately motivating the reason for their combination.\n- The proposed approach and certain component choices (e.g., layer discriminator and link predictor) lack clear motivation and sufficient differentiation from existing methods.\n- The manuscript suffers from issues in writing clarity and organization, with some sections containing redundant information and lacking necessary citations.\n- The selection of baselines for experimental comparison is incomplete, missing both traditional link prediction models and relevant state-of-the-art (SOTA) multi-layer GNN models mentioned in existing literature.\n- The datasets used for evaluating the model are relatively small, which raises concerns about the scalability and applicability of the proposed methods to real-world, large-scale networks.\n- There are minor issues with readability and notational clarity which could hinder the comprehension of the methodological details and experimental setups.\n- Some methodological choices in the proposed models are not well-justified, and the paper lacks comprehensive ablation studies to validate these choices.\n- The reproducibility of the results is questionable as the paper does not provide sufficient details for replication, and no auxiliary material is utilized to bridge this gap.\n\n**Questions**\n- Could you provide a more specific description of the multi-layer networks discussed in the introduction and clarify how they differ from typical graph-level datasets used in GNN research?\n- Why are CNNs applied after GCNs for both intra- and inter-layer node embeddings, and what distinct advantages do they offer in this setting?\n- Can you explain the differences between the layer discriminator and the link predictor, particularly in terms of their roles and functionalities within the model?\n- What is the rationale behind the combination of an adversarial loss with a binary classification loss in the model, and how do you ensure a balanced optimization of these loss components?\n- Given the small size of the datasets used, how can you ensure that the proposed methods can scale effectively to larger, more complex networks?\n- Why were certain relevant works on link prediction in heterogeneous graphs and embeddings for knowledge graphs not discussed or compared in the study?\n- What steps have been taken to ensure fair comparisons with baselines, particularly in terms of model complexity and computational requirements?\n- The paper mentions several losses and model parameters\u2014can you provide details on how model convergence was assessed, including typical values and behaviors of these parameters during training?",
        "5_5": "**Summary**\nThe paper presents a novel graph embedding method called Adversarial Enhanced Representation (AER) aimed at link prediction in multi-layer networks. AER employs a three-module framework comprising a representation generator, a layer discriminator, and a link predictor. These modules work together through adversarial training to learn and fuse inter-layer and intra-layer representations effectively. The representation generator aims to deceive the layer discriminator by generating transferable representations, while the discriminator attempts to accurately identify layer sources. The adaptive fusion between these representations enables the link predictor to make informed decisions about missing links. The method is evaluated on real-world datasets, demonstrating its efficacy compared to several baseline methods.\n\n**Strengths**\n- The paper is well-written, easy to follow, and provides a clear motivation for the proposed method.\n- The proposed method, AER, is innovative and demonstrates a novel approach to link prediction in multi-layer networks, employing an adversarial training mechanism which is well-described.\n- The experimental results are thorough and show that the proposed method outperforms several baseline methods, indicating the effectiveness of the approach.\n- The use of a layer discriminator in the AER framework is a unique contribution, helping to identify layer sources of learned representations, which is a novel aspect in multi-layer network research.\n\n**Weaknesses**\n- The paper lacks a detailed explanation of the dataset, particularly the types of datasets used, which could be beneficial for readers to understand the applicability and context of the research.\n- The paper does not include a comprehensive literature review on multi-layer networks, which could have provided a richer background for the study.\n- There are unclear elements in the paper, such as the definition of \"multi-layer networks\" and the role of the \"link predictor\" in the proposed framework, which could be better defined and explained.\n- The paper's description of the AER framework is insufficiently detailed, especially regarding the training process and the specific roles and interactions between the different components like the representation generator and the layer discriminator.\n- The paper does not sufficiently discuss the limitations of the study and does not compare the results with other recent state-of-the-art methods, which could help in evaluating the robustness and positioning of the proposed method.\n\n**Questions**\n- Can you provide a detailed explanation of the datasets used in your study, including their types and characteristics?\n- How does the proposed method handle datasets with varying numbers of layers? Is there a specific strategy for handling datasets with different numbers of layers?\n- Could you clarify the definition of \"multi-layer networks\" used in your study? This would help in understanding the scope and application of the proposed method.\n- What is the role of the \"link predictor\" in the AER framework, and how does it interact with other components of the framework?\n- Could you elaborate on the training process of the AER framework, specifically how the representation generator and the layer discriminator interact and influence each other?\n- In the ablation study, why is there a significant performance drop for AER- compared to AER? What are the implications of this finding for the proposed method?\n- How does the proposed method compare with other recent state-of-the-art methods in terms of performance and efficiency?\n- What are the specific limitations of the proposed method, and how do these impact the applicability and effectiveness of the method in real-world scenarios?",
        "5_3": "**Summary**\nThis paper presents a novel approach to link prediction in multi-layer networks, termed Adversarial Enhanced Representation (AER). AER employs an innovative minimax two-player game strategy between the representation generator and the layer discriminator to learn inter-layer transferable representations and intra-layer representations. The paper introduces an adaptive fusion mechanism to combine these representations for enhanced link prediction. Experimental results across several multi-layer networks demonstrate the superiority of AER over traditional and state-of-the-art models. Despite its strengths, the paper has been critiqued for lacking clarity in methodology, insufficient theoretical backing, and inadequate novelty.\n\n**Strengths**\n- The paper is well-written, easy to understand, and provides a clear motivation for the proposed method.\n- The paper addresses the problem of link prediction in multi-layer networks, a topic that is both relevant and challenging.\n- The proposed method introduces a new approach to link prediction using adversarial training, which is well-motivated and potentially effective.\n- The experimental results are promising, showing the effectiveness of the proposed method.\n- The paper is well-organized, making it easy to follow and understand the proposed method.\n\n**Weaknesses**\n- The methodology section is somewhat unclear, particularly in the description of the minimax two-player game and the role of the layer discriminator.\n- The paper lacks theoretical backing for the proposed method, particularly in terms of why the adversarial training approach is expected to work.\n- The novelty of the proposed method is questionable, as similar approaches have been previously proposed in other contexts.\n- The paper does not sufficiently justify the use of adversarial training for link prediction in multi-layer networks.\n- The paper is limited to a small number of datasets, which may not be sufficient to establish the generalizability of the proposed method.\n- The paper does not adequately compare the proposed method with existing methods, particularly in terms of computational complexity.\n- There are some unclear and potentially incorrect statements in the paper, such as the statement regarding the use of the layer discriminator.\n\n**Questions**\n- Can the authors clarify the methodology section, particularly the description of the minimax two-player game and the role of the layer discriminator?\n- Why is the adversarial training approach expected to work for link prediction in multi-layer networks?\n- How does the proposed method compare with existing methods in terms of computational complexity?\n- Can the authors provide more justification for the use of adversarial training in this specific context?\n- How many parameters are used in the model, and how does this compare to other models?\n- Can the authors clarify the statement regarding the use of the layer discriminator?\n- How does the proposed method perform on different types of multi-layer networks, such as temporal networks or dynamic networks?\n- Can the authors provide more details on the experimental setup, including the datasets used and the specific evaluation metrics employed?"
    },
    "uvFhCUPjtI": {
        "gold": "**Summary**\nThe paper introduces an Evolving Fourier Transform (EFT) suited for temporal graphs by addressing the complexities associated with evolving graph structures. This transform is an alternative spectral method, optimizing over the graph's Laplacian dynamics and effectively decomposing the spatial and temporal domains to reduce computational demands. Theoretical guarantees validate EFT's approximation to a true variational solution. Additionally, empirical results showcase EFT's ability to filter noise and enhance signal interpretation, even within large-scale dynamic settings. Challenges remain concerning the theoretical underpinnings of learning within this framework and the approach's generalizability to dynamic graphs undergoing node changes.\n\n**Strengths**\n- The concept of Evolving Graph Fourier Transform (EFT) for analyzing spatio-temporal graphs is novel and theoretically grounded, providing an innovative approach to handling time-evolving graph data.\n- The theoretical properties of EFT are elaborately established with proofs and approximations which afford provable guarantees, enhancing the method's credibility.\n- EFT's practical effectiveness is demonstrated through benchmarks and simulations, where it shows promise in applications like filtering noise, amplifying useful signals, and integrating into transformer models for sequential link prediction.\n- The method is computationally efficient with a complexity noted as \\(O(T + T\\log(T))\\), and it separates the vertex and time domain analysis which may simplify the computational demands in practice.\n\n**Weaknesses**\n- The presentation of the paper can be improved. It suffers from being dense, with crucial points such as the coupling of filtering in vertex and time domains relegated to appendices instead of being highlighted in the main text. Font sizes in tables and clarity of equations need attention to enhance readability.\n- The paper lacks extensive empirical evaluation against other established methods and does not discuss limitations related to dynamic graphs that experience node additions or drops.\n- While theoretical underpinnings are strong, practical uncertainties about EFT's performance in real-world scenarios lacking comparison to baselines are unaddressed.\n- EFT's assumptions and generalizability are concerns not sufficiently addressed in the main text. Necessary conditions for its application, such as the bounded rate of graph changes and unique eigenvalues, are significant and should be better highlighted.\n- The novel decoupling approach in spatio-temporal data analysis is not new to the broader community, suggesting a need for a clearer articulation of EFT's unique contributions over prior models.\n\n**Questions**\n- Can the efficiency of EFT's computation be empirically verified, especially against conventional baselines? How does this performance translate in large-scale scenarios?\n- What are the implications of EFT in scenarios beyond link prediction, such as predicting node features or embedding timespan of edges? How flexible is EFT in adapting to such extended applications?\n- Could the authors provide more intuitive examples or small case studies to illustrate the working and benefits of EFT? What would the harmonics look like for specific graph structures, such as a ring of ring graphs?\n- In what ways does EFT potentially outperform or fall short when compared against methods like spectral clustering for dynamic networks?\n- What does conducting the EFT \"dimension-wise\" imply, and how does this approach affect its application across different data scales and structures?",
        "5_5": "**Summary**\nThe paper introduces an Evolving Graph Fourier Transform (EFT), a novel approach to handling temporal graphs by decomposing them into vertex and time domains and applying a spectral transformation. The EFT aims to filter out noise from signals on these graphs by focusing on low-frequency components. The authors provide both theoretical underpinnings and empirical evidence to support the efficacy of this method, showing it to be computationally efficient and capable of outperforming existing methods in tasks such as denoising and link prediction. However, concerns were raised regarding the clarity of the writing, the theoretical foundation, and the empirical evaluations, particularly the selection of datasets and baseline comparisons.\n\n**Strengths**\n- The paper is well-written and easy to follow, making it accessible to readers familiar with spectral graph theory.\n- The authors provide both theoretical analysis and empirical evaluations, which are crucial for understanding the performance and limitations of the proposed method.\n- The proposed method is novel and appears to be well-motivated, with a clear focus on denoising temporal graph signals.\n- The computational efficiency of the proposed method is highlighted, which is a significant advantage given the complexity of the problem addressed.\n- The authors provide a clear explanation of the method, with detailed derivations and a comprehensive experimental setup, including both synthetic and real-world datasets.\n\n**Weaknesses**\n- The paper suffers from significant clarity issues, particularly in the motivation and theoretical underpinnings. Key concepts such as the Laplacian matrix and the pseudospectrum are not clearly defined, and the paper lacks a thorough comparison with existing methods.\n- The experimental setup is not robust, with too few datasets and baseline comparisons, which makes it difficult to assess the method's effectiveness and scalability.\n- The paper claims to handle dynamic graphs but focuses only on static graphs, which may mislead readers regarding the scope of the research.\n- The novelty of the method is questionable, as similar approaches have been previously proposed in other contexts, such as the Joint Fourier Transform (JFT) and the Joint Fractional Fourier Transform (JFFT).\n- The paper's claims about computational efficiency are not substantiated with adequate experimental evidence, making it difficult to verify the actual benefits of the proposed method.\n- There are concerns about the practicality of the proposed method, particularly in real-world applications, given the assumptions of the Laplacian matrix and the pseudospectrum.\n\n**Questions**\n- Can the authors clarify the definition and usage of the Laplacian matrix and the pseudospectrum in the context of this paper?\n- How does the proposed method compare to existing methods in terms of performance and computational efficiency?\n- Why is the proposed method considered novel, and how does it differ significantly from previous approaches like JFT and JFFT?\n- Could the authors provide a more detailed explanation of the experimental setup, particularly the choice of datasets and baseline comparisons?\n- How does the proposed method perform in scenarios with more complex or dynamic graph structures, such as those with multiple edges between nodes or with nodes entering or exiting the graph over time?\n- Are there any plans to include more diverse and challenging datasets in future work to better evaluate the method's effectiveness and scalability?",
        "5_3": "**Summary**\nThe paper introduces a novel graph neural network (GNN) framework, termed EFT (Evolutionary Frequency Transform), designed to process dynamic graphs. It proposes a novel spectral graph transform, grounded in theoretical foundations, which can be used to capture evolving spectra along both graph vertex and time dimensions. The authors provide theoretical bounds and experimental validation, demonstrating the framework's effectiveness in filtering noise and enhancing task performance. However, there are significant concerns regarding the clarity of the paper's presentation, the novelty of the approach, and the experimental setup. The paper's contribution to the understanding of temporal graph processing and its experimental results on standard datasets are questioned, with the reviewers suggesting a need for more detailed explanations and additional experimental validation.\n\n**Strengths**\n- The paper introduces a novel method for dynamic graph processing, which is theoretically sound and presents an interesting perspective on processing dynamic graphs through frequency analysis.\n- The proposed method is described as straightforward and easy to implement, which could facilitate its adoption by the community.\n- The paper includes a comprehensive set of experimental results that demonstrate the effectiveness of the proposed method in handling dynamic graphs.\n- The authors provide a clear and concise explanation of the proposed method and the underlying theory, making it accessible and understandable.\n\n**Weaknesses**\n- The paper suffers from poor writing quality, with several grammatical errors and unclear descriptions, which could hinder the understanding of the content.\n- There is a lack of novelty in the proposed method, as it appears to be a combination of existing methods and techniques, which may not significantly advance the state-of-the-art in the field.\n- The experimental setup is not sufficiently convincing, as the paper relies on a single dataset and does not provide a comprehensive comparison with other state-of-the-art methods.\n- The paper does not adequately discuss the limitations and potential drawbacks of the proposed method, which is crucial for understanding its applicability and reliability.\n- The paper lacks a clear and detailed discussion of related work, which could provide context and differentiate the proposed method from existing approaches.\n\n**Questions**\n- Can the authors clarify the specific contributions of the proposed method and how it differs from existing approaches?\n- Why is the proposed method expected to perform better than other methods, and what are the theoretical or empirical justifications for this claim?\n- What are the limitations of the proposed method, and how can these limitations be addressed?\n- Could the authors provide more detailed explanations and examples of the experimental setup and results, particularly in relation to the filtering and wavelet components?\n- How does the proposed method compare with other state-of-the-art methods, and what are the specific advantages of using the proposed method over others?\n- Can the authors clarify the use of the term \"grounded in theory\" in the context of their method, and how does this relate to the theoretical foundations of the method?"
    },
    "whFQe4MRIY": {
        "gold": "**Summary**\nThis paper delves into the development of a unified NeRF model, MI-NeRF, designed for learning from monocular videos of talking faces across multiple identities. The core innovation is a multiplicative module that effectively distinguishes between identity and expression information, inspired by TensorFaces, and allows for disentangled learning of these features. The method's key strength is its ability to handle multiple identities using a single model, significantly reducing training times and computational resources. It leverages a structure that involves an element-wise product between identity embeddings and expression embeddings for this purpose. Experiments conducted demonstrate superior performance in facial expression transfer and lip synchronization tasks, showing promising results over current state-of-the-art methodologies. However, concerns arise regarding the handling of varying expressions and lighting conditions across different identities, and the model's robustness under real-world scenarios has been questioned.\n\n**Strengths**\n- The proposed method, MI-NeRF, robustly adapts to unseen expressions and identities, requiring minimal retraining, which saves computational time and effort.\n- MI-NeRF effectively separates identity from expression thanks to its multiplicative module, ensuring consistent portrayal even with dynamic expressions, which is a challenge for some other models.\n- The method is simple and effective, built on top of earlier multi-identity NeRF methods, featuring a multiplicative structure between identity embeddings and expression embeddings.\n- Experiments and ablation studies validate the design of the multiplicative structure, showing that it helps improve factor disentanglement and visual quality.\n- The paper presents results that outperform competitors' approaches in visual quality and lip synchronization, and significantly reduces the training time.\n\n**Weaknesses**\n- The paper\u2019s descriptions are unclear regarding how face expressions and different lighting conditions are managed, sparking concerns about real-world application viability.\n- Concerns arise about the handling of time-varying information, as it's not clearly explained how the model ensures these codes don't inadvertently encode identity or expression information.\n- The implementation of the high-degree interaction module is not justified, as there is no visible use or experimental analysis mentioned.\n- Comparisons with similar multi-identity NeRF-based methods, especially in expression transfer experiments, are lacking or incomplete.\n- Ethical considerations concerning data privacy are not addressed adequately, particularly in terms of the usability and public release of the collected video data.\n- While MI-NeRF's uniqueness largely stems from its multiplicative module, the dependence on this single component could limit overall robustness in complex real-world scenarios.\n\n**Questions**\n- Could the authors explain how different expressions for various identities are aligned or handled within the model? Is there a canonical face model being used for this purpose?\n- How does the method handle different lighting conditions during model training and application?\n- Can the authors provide a more detailed comparison between MI-NeRF and other state-of-the-art methods, particularly GAN-based methods in the context of face video synthesis?\n- Is there a comparison or benchmarking for training time with other identities methods, like HeadNeRF?\n- Could the authors clarify the nature of the per-frame latent codes and how they ensure that these codes do not contain identity or expression specifics?\n- What steps are taken to prepare the data before its integration into MI-NeRF to ensure the integrity of the dataset and reproducibility of the results?\n- Can the authors discuss any potential limitations or challenges faced by the multiplicative module in complex real-world scenarios?",
        "5_5": "**Summary**\nThe paper introduces a novel approach, MI-NeRF, that aims to train a single dynamic neural radiance field (NeRF) model from monocular talking face videos of multiple identities. The model incorporates a multiplicative module to capture non-linear interactions between identity and non-identity specific information, which is trained on multiple videos simultaneously to reduce training time significantly. The method allows for further personalization for a target identity and demonstrates state-of-the-art performance in facial expression transfer and audio-driven talking face video synthesis. However, the paper is criticized for insufficient comparisons with other multi-identity NeRFs, lack of clarity in methodology, and limited novelty in the technical contributions.\n\n**Strengths**\n- The paper addresses an important problem in the NeRF community, specifically the challenge of learning a single dynamic NeRF from multiple identities, which is significant for real-world applications.\n- The proposed method demonstrates a notable reduction in training time and achieves state-of-the-art results in facial expression transfer and audio-driven talking face video synthesis.\n- The paper is well-structured, making it easy to follow and understand the content, which is further enhanced by the inclusion of supplementary videos for better visualization.\n- The method's simplicity and straightforward approach make it accessible and understandable, which is supported by comprehensive experimental results and clear illustrations in the figures.\n\n**Weaknesses**\n- The novelty of the proposed method is questionable as the idea of learning a single NeRF for multiple identities is not entirely new, and the technical contribution appears limited.\n- The paper lacks comparisons with other multi-identity NeRFs, which would have strengthened the claims of the method's effectiveness and efficiency.\n- There is a lack of detailed methodology and mathematical definitions in the paper, particularly in Section 3.1, which could lead to confusion about the exact steps and parameters involved in the experiments.\n- The experimental results, although promising, are not sufficiently comprehensive to fully support the claims made in the paper. Specifically, the paper does not include detailed comparisons with other state-of-the-art methods or provide ablation studies on the number of training identities.\n- The writing and formatting of the paper need improvement for clarity and professional presentation. There are inconsistencies and errors in notation and terminology throughout the document.\n\n**Questions**\n- How does the proposed method compare to other multi-identity NeRFs in terms of performance and efficiency?\n- Can the authors provide more detailed mathematical definitions and explanations, particularly in Section 3.1, to clarify the methodology and parameters used in the experiments?\n- How does the performance of the proposed method change with varying numbers of training identities? What is the optimal number of identities for achieving the best results?\n- In light of the limited novelty and technical contribution, can the authors elaborate on the significance and novelty of their proposed method compared to existing works?\n- What are the main challenges and limitations of the proposed method, and how can they be addressed to further improve the performance and applicability of the method in real-world scenarios?",
        "5_3": "**Summary**\nThe paper introduces a method named MI-NeRF, which learns a single dynamic Neural Radiance Field (NeRF) from monocular talking face videos of multiple identities. The key innovation is a multiplicative module that facilitates disentanglement of identity and non-identity specific information, enabling the model to handle a variety of identities efficiently. This method significantly reduces training time compared to traditional single-identity NeRFs. The paper demonstrates this method's effectiveness through facial expression transfer and talking face video synthesis, achieving results comparable to or surpassing those of existing methods.\n\n**Strengths**\n- The paper introduces a novel method that learns a single dynamic NeRF from monocular talking face videos of multiple identities, which is a significant advancement in the field.\n- The approach of using a multiplicative module to disentangle identity and non-identity specific information is innovative and well-explained.\n- The method shows robustness in handling unseen identities and expressions, demonstrated through extensive experiments and visual results.\n- The paper is well-written, clearly organized, and easy to follow, making it accessible and comprehensible for readers.\n- The results achieved by the proposed method are competitive with or even better than existing methods, as shown in quantitative and qualitative evaluations.\n- The idea of training a generic NeRF model from a large number of identities is novel and could be beneficial for broader applications in the field.\n\n**Weaknesses**\n- The paper lacks a thorough discussion and comparison with existing methods, particularly those that use similar approaches such as multiplicative modules and shared latent codes.\n- The experimental setup is limited, primarily focusing on facial expression transfer and lip-syncing, which may not adequately demonstrate the method's versatility across different applications.\n- There are inconsistencies and unclear explanations in the paper, such as the use of different metrics and the comparison of results across various sections and tables.\n- The paper does not include code or supplementary materials, which is crucial for reproducing and verifying the results.\n- Some sections of the paper are confusing, such as the explanation of the training process and the role of different components like the Hadamard product.\n- The evaluation metrics used may not adequately reflect the quality of the generated videos, particularly in terms of realism and visual appeal.\n\n**Questions**\n- How does the proposed method compare with other methods that use multiplicative modules and shared latent codes? What are the specific advantages of the proposed method over these approaches?\n- Can you provide more details on the experimental setup, particularly how the model is trained and evaluated for each specific application like facial expression transfer and lip-syncing?\n- In the training process, how are the input conditions for different identities managed, and what impact does this have on the overall performance of the model?\n- How does the model perform when handling very short videos or videos with poor quality, and what are the implications for the training and testing phases?\n- Could you clarify the use of different metrics in the evaluation and provide a more detailed explanation of how the results were computed and compared?\n- Are there plans to make the code and supplementary materials available to facilitate reproducibility and further research by the community?"
    },
    "wOb0xFwdpr": {
        "gold": "**Summary**\nThe paper examines the effectiveness of various GPT models from OpenAI, such as GPT-3, InstructGPT, GPT-3.5, and GPT-4, in detecting sarcasm using the SARC 2.0 dataset from Reddit. Intending to establish performance benchmarks, it compared twelve variants of these models in fine-tuned and zero-shot scenarios with and without domain context prompts. The study revealed that while larger models generally performed better, the incorporation of domain context did not significantly enhance model performance. The results also highlighted the variability of performance across different versions and settings of these models, indicating potential areas for future investigation in NLP sarcasm detection.\n\n**Strengths**\n- The study effectively utilizes OpenAI GPT models for sarcasm detection, which signifies an advancement in NLP for detecting figurative language.\n- The research results are promising, with the fine-tuned GPT-3 davinci model outperforming prior sarcasm detection models.\n- The paper is well-written and easy to follow, providing a comprehensive investigation into the utilization of GPT-based LLMs for sarcasm detection.\n- The analysis of the results is detailed and rigorous, and the conclusions drawn have the potential to guide future directions in sarcasm detection methodologies.\n\n**Weaknesses**\n- The study focuses only on one balanced dataset, which does not represent the usual distribution of sarcastic vs. non-sarcastic conversations on social media platforms, reducing the generalizability of the results.\n- The results exclusively utilize GPT models from OpenAI, limiting the representativeness of the findings across the broader spectrum of LLMs.\n- The experimental results are mainly reliant on a single table, lacking in-depth visual representations or further analytic details that could strengthen the conclusions.\n- The use of domain context and prompt design seems underexplored, which could potentially influence the model's performance significantly.\n- Some methodological concerns were raised regarding the statistical significance and the appropriate reporting of quantitative measures.\n- The analysis does not fully explore the effects and mechanisms when using situational context to detect sarcasm, missing an opportunity to delve deeper into this critical aspect.\n\n**Questions**\n- Why were other LLMs beyond OpenAI's GPT models not considered for this study? Could their inclusion potentially affect the study's conclusions?\n- What impact might different prompt designs or additional forms of domain context have on the performance of the models? Could exploring these variations offer more insights?\n- Is it possible to provide a comparative performance analysis against other traditional and modern sarcasm detection models to contextualize the effectiveness of the GPT models employed in this study?\n- Given the significant emphasis on the use of a single dataset, could the inclusion of more diverse datasets provide a more comprehensive understanding of the models' capabilities?\n- Can a deeper examination be provided regarding the claim of domain context reducing the number of missed observations, specifically how these conclusions were drawn from the presented data?",
        "5_5": "**Summary**\nThe paper examines the effectiveness of various GPT models, including GPT-3, GPT-3.5, and GPT-4, in detecting sarcasm within a dataset known as the Self-Annotated Reddit Corpus (SARC 2.0). It assesses these models through both fine-tuning and zero-shot methods, comparing their accuracy and F1-score against traditional models and other baseline classifiers. The paper highlights the performance variability of GPT models across different releases, noting that while some newer versions like GPT-4 exhibit better performance, others, like GPT-3.5, show a decline. The research also explores the impact of domain context on model performance, albeit with mixed results. However, the paper's approach is critiqued for its limited novelty and narrow focus on sarcasm detection, which may not contribute significantly to the broader field of NLP research.\n\n**Strengths**\n- The paper is well-written and easy to follow, making it accessible to readers.\n- The experiments are clearly defined, well-executed, and the results are easy to interpret.\n- The paper provides a straightforward and concise analysis of the GPT models' performance across different releases.\n- The authors have demonstrated a good understanding of the strengths and limitations of the models tested, providing a nuanced discussion on the implications of their findings.\n\n**Weaknesses**\n- The paper's scope is too narrow, focusing only on sarcasm detection in Reddit comments, which limits its general applicability and contribution to the broader NLP community.\n- The use of GPT models for sarcasm detection is not novel, as this has been a common approach in recent years, and the paper does not significantly advance the state-of-the-art.\n- The paper lacks a thorough discussion on the potential limitations of the GPT models, such as their potential biases or the impact of data distribution on model performance.\n- There is no detailed analysis of the dataset used, which is necessary for a robust evaluation of the models' performance.\n- The paper's methodology and experimental design could benefit from more clarity and detail, particularly regarding the fine-tuning procedures and the handling of domain context in the experiments.\n- The paper does not adequately compare the performance of the GPT models against traditional baseline models or other recent state-of-the-art models, which would provide a more comprehensive understanding of their relative performance.\n\n**Questions**\n- Can you elaborate on the fine-tuning procedures used for the GPT models? Specifically, how were the models fine-tuned, and what were the specific hyperparameters used?\n- How does the paper address the potential biases in the GPT models? For example, how do the models handle different types of sarcasm or sarcasm in diverse contexts?\n- Could you provide more details on the dataset used, including its size and diversity, and discuss how it was used for training and testing the GPT models?\n- How does the paper justify the use of the GPT models for sarcasm detection, and what are the main advantages of using these models compared to traditional or other recent models?\n- In terms of the performance metrics reported, could you clarify the specific metrics used and how they were calculated?\n- How do the results presented in the paper compare to those obtained using other state-of-the-art models, such as the models discussed in the works cited in the reviews?",
        "5_3": "**Summary**\nThe paper investigates the effectiveness of language models (LMs) in identifying sarcasm in text, focusing on the use of GPT models. The authors tested various GPT models on the Self-Annotated Reddit Corpus (SARC 2.0) across different settings including fine-tuning and zero-shot tests. They report that while fine-tuned models perform best, even the largest model, davinci, with 175 billion parameters, struggles to outperform a simple baseline. In the zero-shot scenario, the performance varies significantly across different GPT models, with GPT-4 showing the best results. The paper explores how performance changes with model updates and whether including domain context in training improves the models' ability to detect sarcasm.\n\n**Strengths**\n- The paper is well-written, easy to follow, and the motivation is clearly articulated, making it accessible to a broad audience.\n- The methodology is clearly explained, and the experiments are designed to answer the research questions effectively.\n- The results are presented in a straightforward and easy-to-understand manner, with a clear discussion on the implications of the findings.\n- The paper effectively explores the performance of different GPT models in detecting sarcasm in text, providing valuable insights into the capabilities of these models.\n- The paper is well-structured, with each section contributing to the overall narrative and flow of the content.\n\n**Weaknesses**\n- The paper lacks a comprehensive literature review, particularly in recent years, which could enhance its relevance and contextual understanding within the field.\n- The experiments conducted are limited in scope, primarily focusing on sarcasm detection and using only the SARC 2.0 dataset. Including other datasets and exploring various tasks could provide a more robust validation of the findings.\n- The results do not consistently demonstrate the superiority of larger models in sarcasm detection, and the performance of some models is comparable to or even worse than smaller models.\n- The paper does not fully address the limitations of the study, particularly in terms of model generalization and the effectiveness of domain context in improving model performance.\n- There are some inconsistencies and potential errors in the experimental design and data presentation, such as the inclusion of domain context in training and the reporting of results with significant discrepancies.\n\n**Questions**\n- How does the inclusion of domain context in training affect the performance of the models? Could the authors provide more details on the impact of domain context on model performance?\n- Can the authors explain why the zero-shot model results for the \"pol-bal\" dataset are not reported in Table 2, and how does this impact the overall analysis of the findings?\n- Why were only the \"pol-bal\" and \"pol-pol\" datasets selected for analysis, and how might the inclusion of other datasets alter the conclusions drawn?\n- Could the authors clarify the inconsistencies in model performance observed in the results, particularly the unexpected performance of the GPT-3.5 model compared to other models?\n- Is there a possibility that the results could be influenced by the specifics of the prompt used in the experiments? If so, could the authors explore alternative prompts to validate the robustness of their findings?\n- How do the authors justify the use of McNemar's test for comparing model performance, and could they provide more detailed statistical analysis to substantiate their claims?"
    },
    "xJ5N8qrEPl": {
        "gold": "**Summary**\nThis research presents a new single-loop Hessian-free algorithm for bi-level optimization (BLO) problems involving lower-level (LL) constraints coupling both upper and lower-level variables. This innovative approach utilizes the Moreau envelope value function, enabling a single-level reformulation with smooth constraints. This results in the proposed Lagrangian Value function-based Hessian-free Bi-level Algorithm (LV-HBA), which relaxes the strongly convex assumption on the lower-level problem to general convexity. The paper provides a detailed non-asymptotic convergence analysis and validates the effectiveness of the algorithm through extensive numerical experiments across various practical applications, highlighting its superior performance and computational efficiency.\n\n**Strengths**\n- The paper is well-written, with clear organization and elucidation of assumptions, which makes it easy to follow and understand both the primary concepts and the technical intricacies of the proposed approach.\n- The paper introduces the first single-loop Hessian-free algorithm for solving the bilevel optimization (BLO) problem, which includes a novel use of the Moreau envelope value function leading to an efficient gradient-based algorithm.\n- A new potential function associated with monotonically decreasing step sizes is presented, and methods to select these step sizes to ensure sufficient descent are demonstrated.\n- The authors include non-asymptotic convergence analysis for the proposed method and relax the lower level problem's requirements from strongly to only convex, increasing the method's applicability.\n- Extensive experimental results on five machine learning tasks validate the performance and demonstrate the efficiency of the proposed methods.\n\n**Weaknesses**\n- The paper includes many hyperparameters, which complicates practical implementation and parameter selection.\n- Some of the assumptions such as Assumption 3.1(i) and 3.3(ii) are considered too strong or unclear, which might limit the applicability of the proposed method in practical scenarios where these conditions are not met.\n- Comparisons with some recent significant works in constrained BLO through the value function approach are missing, which could provide a deeper contextual understanding of the paper's position within current research.\n- It is unclear whether the performance of the algorithm is overly sensitive to the stepsize parameters, and the choice of certain parameters like 'r' for the truncated proximal Lagrangian value function is not discussed.\n- The paper could benefit from more examples of bilevel optimization in machine learning with non-smooth and weakly convex lower level functions to better motivate and illustrate the approach.\n\n**Questions**\n- 1. Can the authors elaborate on why there is no need to assume Lipschitz continuity of the upper-level function F(x,y), which is typically necessary in bilevel optimization?\n- 2. How is the exact form of \u03c1f determined, especially in practical applications where it is potentially smaller than Lf?\n- 3. Can the authors clarify whether the optimal solutions of the reformulated and the original constrained BLO problem are equivalent, as suggested by Theorem A.1?\n- 4. How should the parameter 'r' be chosen in practical applications as mentioned in reformulation (5)?\n- 5. Could the authors provide insights into the central benefit of using the Moreau envelope as opposed to the optimal value function in the technical aspects of this work?\n- 6. How are the hyperparameters, including 'r', chosen in the experimental setups, and what guidance can the authors provide for their selection in practice?",
        "5_5": "**Summary**\nThe paper introduces a novel method for solving constrained bi-level optimization problems by employing a smooth proximal Lagrangian value function to reformulate the lower-level problem into a single-level optimization problem with smooth constraints. This transformation enables the development of a Hessian-free gradient-based algorithm named LV-HBA, which offers a single-loop solution to constrained BLO problems. The paper also provides non-asymptotic convergence analysis for LV-HBA, eliminating the need for strong convexity assumptions at the lower level. Empirical results validate the algorithm's practical performance across various machine learning applications. The approach combines elements of previous methods and extends the value function reformulation to constrained problems, yet the novelty and depth of technical contributions are questioned, particularly in terms of its originality and the incremental nature of the proposed methods.\n\n**Strengths**\n- The paper introduces a new method for solving constrained bilevel optimization problems (BLOs) using a smooth proximal Lagrangian value function to reformulate the lower-level problem into a single-level optimization problem.\n- It presents a non-asymptotic convergence analysis for the proposed algorithm, which does not require strong convexity at the lower level, addressing a significant technical challenge.\n- The approach combines elements of existing methods and extends the value function reformulation to constrained problems, which could be beneficial for practical applications.\n- Empirical results provided in the paper demonstrate the practical performance of the algorithm in various machine learning applications.\n\n**Weaknesses**\n- The paper lacks a detailed comparison with existing methods and does not clearly articulate the main novelty of the proposed algorithm, making it difficult to understand its advantages over prior works.\n- The technical contributions are described as incremental, with the new method appearing to be a minor extension of previous works.\n- The presentation of the paper could be improved for clarity and readability, as some sections are difficult to follow.\n- The assumptions on the problem structure are restrictive, and it is unclear whether the results can be generalized to more complex scenarios.\n- The convergence analysis provided is limited to specific assumptions and does not consider more general or practical scenarios.\n\n**Questions**\n- Could you clarify what is the main novelty of your method and how it differs from and improves upon previous works?\n- How does the proposed algorithm perform in scenarios where the lower-level problem is non-convex or has more complex constraints?\n- Can you elaborate on the practical applicability of your method, especially in scenarios where the assumptions on problem structure are not met?\n- How does the proposed method handle scenarios where the lower-level problem is not strongly convex, and can you provide more details on the convergence behavior in such cases?\n- Could you provide a more detailed comparison with existing methods, particularly in terms of the computational efficiency and the assumptions required for convergence?\n- In the experimental section, how do the results compare with other methods like those cited in recent studies, such as those by Gao et al. (2023) and Kwon et al. (2023)?",
        "5_3": "**Summary**\nThis paper introduces a novel Hessian-free algorithm, termed LV-HBA, designed for solving constrained Bi-Level Optimization (BLO) problems. The algorithm employs a proximal Lagrangian value function to handle constrained lower-level problems, converting them into a single-level optimization problem. LV-HBA does not require strong convexity of the lower-level problem and is capable of handling non-singleton scenarios. The convergence of LV-HBA is analyzed under specific assumptions, and the paper also includes experimental results that validate the practical performance of the algorithm. However, the paper's novelty and the significance of the improvements over existing methods are questioned, with concerns raised about the clarity and organization of the presentation.\n\n**Strengths**\n- The paper is well-written and easy to follow, which facilitates understanding of the content.\n- The proposed method is described as novel and simple to implement, which could enhance its adoption in practical scenarios.\n- The authors have provided a thorough convergence analysis and have conducted experiments that support the algorithm's practical effectiveness.\n- The paper introduces a novel approach using a proximal Lagrangian value function, which simplifies the problem formulation and enables the development of a Hessian-free gradient-based algorithm.\n- The use of a proximal Lagrangian value function to handle the constrained lower-level problem is an interesting and innovative approach.\n\n**Weaknesses**\n- The paper lacks a detailed discussion of the convergence analysis, particularly concerning the assumptions and their impact on the results.\n- The novelty of the proposed algorithm is questioned, as it appears to be an extension of previous works with limited new contributions.\n- There is a significant overlap between the proposed algorithm and existing methods such as those in Liu et al. (2023), making it difficult to discern the new contributions.\n- The paper does not address the practical implementation of the algorithm, particularly how to handle constraints in a real-world setting.\n- The performance of the algorithm is only compared with a single existing method (GAM), which does not provide a comprehensive evaluation of its effectiveness.\n- The clarity and organization of the paper are concerns, as some sections (e.g., Section 4.2) are difficult to follow, and the use of notation and terminology is inconsistent.\n- The motivation for using a proximal Lagrangian value function is unclear, and its specific advantages over other methods are not well-explained.\n\n**Questions**\n- 1. Can the authors clarify the assumptions made in the convergence analysis and explain their impact on the results?\n- 2. What are the main differences between the proposed algorithm and existing methods, and what new contributions does this paper make?\n- 3. How does the algorithm handle constraints in practical scenarios? Is there a need for additional assumptions or modifications to the algorithm?\n- 4. Could the authors provide more detailed experimental results, including comparisons with other existing methods, to better evaluate the performance of the algorithm?\n- 5. In Section 4.2, the authors mention that the algorithm has a single-loop structure. Can this be clarified, and is there a specific advantage of this structure?\n- 6. The paper uses a proximal Lagrangian value function, but it is unclear how this approach differs from or improves upon other methods. Can the authors provide more details on this?\n- 7. There are several notation and terminology inconsistencies throughout the paper. Could the authors clarify these and ensure consistency throughout the document?"
    },
    "ziDFH8TPPK": {
        "gold": "**Summary**\nThe paper introduces the Long-Term Typhoon Trajectory Prediction (LT3P) framework, which innovatively utilizes a data-driven model based on various weather and typhoon reanalysis data for real-time typhoon trajectory prediction. LT3P leverages a cross-attention mechanism between encoded past trajectory points and global meteorological data like geopotential and wind directions, eliminating the dependency on high-quality reanalysis data at runtime. The central coordinates of a typhoon are predicted using a real-time Numerical Weather Prediction (NWP) dataset, distinctly differentiating LT3P from alternative methods. Despite currently being tested solely on typhoons, the methodology shows potential for broader applications. Extensive evaluations and performance testing against state-of-the-art physics-based methods highlight its effectiveness. The model, along with its training and test code, will be open-sourced.\n\n**Strengths**\n- The paper presents a novel data-driven model for real-time typhoon trajectory prediction, differentiating it through the use of a real-time NWP dataset and applying innovative methodologies including cross-attention mechanisms and error correction schemes.\n- Significant empirical gains are reported over conventional physics-based baselines, showcasing the model's state-of-the-art performance.\n- The decision to open-source the data, training, and testing codes along with pre-trained weights will greatly contribute to reproducibility and advancements in the field of climate AI.\n- The method shows promise by initially learning the prediction of physical variables maps using reanalysis data before combining these with trajectory predictions, resulting in effective and accurate predictions.\n\n**Weaknesses**\n- The paper suffers from a lack of clarity and numerous grammatical errors that could significantly hinder comprehension and reproducibility. Detailed explanations on the network architecture, loss functions, and ablation studies are either vague or entirely absent.\n- The application of the model is currently restricted to typhoons and has not been demonstrated on other types of tropical cyclones. Moreover, the study's generality is limited to specific regions, raising questions about its applicability in different geographical conditions.\n- Over-reliance on the availability and accuracy of the real-time NWP dataset might limit the model's performance in less ideal conditions. Additionally, the dependence on updated reanalysis data, which has inherent delays, introduces concerns regarding the lead time in predictions.\n- There are inconsistencies in reported results and trends compared to other models cited in existing literature, with insufficient explanations provided for the observed differences, particularly the substantial improvements claimed.\n- The manuscript includes potential overstatements regarding its novelty and the feasibility of training models from scratch on datasets like ERA5, which have been accomplished in other studies.\n\n**Questions**\n- Given the dependence on real-time NWP data, how does the LT3P model's performance fare in scenarios with sparse or inaccurate data? Specifically, how is data accuracy managed in real-time to ensure reliable predictions?\n- How well does the LT3P model generalize across different regions and varying conditions of typhoon occurrences? Are there specific adaptational challenges when applying the model to other geographical locations?\n- Can you provide detailed clarifications on the methodological implementation aspects, such as the exact implementation of the ensemble methods, ablation study configurations, and the handling of bias correction in practical scenarios?\n- What insights can be drawn from Figures 4 and any other visual comparisons in the paper, particularly regarding the effectiveness of bias correction using ERA5 and UM datasets?\n- Several conceptual and terminological clarities are needed. For instance, the use of different alphabets for varying components in equations, precise definitions of error metrics, and clearer depiction of implementation details like the number of layers and compute times. Could these be addressed comprehensively in the revision?",
        "5_5": "**Summary**\nThe paper introduces a novel approach for typhoon trajectory prediction using a physics-conditioned encoder and a trajectory predictor. The model leverages Unified Model (UM) data, which is available in real-time, to predict typhoon trajectories up to 72 hours in advance. The authors claim that this method outperforms both state-of-the-art data-driven methods and numerical weather prediction models. The paper also includes a dataset consisting of ERA5 reanalysis data, typhoon best-track data, and UM forecast data, which is released to support further research in this domain. Despite its promising results, the paper has been critiqued for its lack of clarity in methodology, insufficient baseline comparisons, and the need for more detailed experimental evaluations.\n\n**Strengths**\n- The paper introduces an innovative approach to typhoon trajectory prediction, using a physics-conditioned encoder and a trajectory predictor, which is well-documented and easy to understand.\n- The method incorporates real-time Unified Model (UM) data, which is not widely used in the field, and the approach is supported by a comprehensive dataset released to the public.\n- The authors have shown that the proposed method outperforms baseline models, and the manuscript is well-written and clear, making it accessible to a broad audience.\n- The use of the UM dataset and its bias correction is highlighted as a novel approach, which could be of interest to the community.\n\n**Weaknesses**\n- The paper lacks a detailed description of the UM dataset, particularly its quality and potential biases, which could impact the accuracy of the results.\n- There is insufficient comparison with existing methods, particularly those that utilize UM data, which makes it difficult to gauge the novelty and effectiveness of the proposed method.\n- The experimental evaluation is limited, with only a single dataset used for testing, and the results do not include error bars or statistical measures, which could affect the interpretation of the findings.\n- The methodology section could be improved by providing more details on the training process and the architecture of the models used.\n- The paper suffers from a lack of clarity in its presentation, particularly in the description of the method and its components, which could confuse readers or researchers attempting to replicate the study.\n\n**Questions**\n- Can the authors clarify whether the UM dataset used is publicly available and what the data processing steps are for the UM dataset?\n- How does the proposed method compare to existing methods that use UM data? Specifically, could the authors provide more comparative analysis or results from such studies?\n- Is there a possibility to provide more detailed information on the UM dataset's quality and potential biases to better understand the results?\n- Could the authors provide a more detailed description of the experimental evaluation, including error bars or statistical measures, to enhance the credibility and reliability of the findings?\n- Would it be possible to include more baseline comparisons or different experimental settings to better demonstrate the effectiveness and robustness of the proposed method?",
        "5_3": "**Summary**\nThe paper introduces a novel approach for predicting typhoon trajectories using a combination of Unified Model (UM) and ERA5 reanalysis data. The methodology involves a data-driven model that incorporates UM data, processed to include ERA5 and typhoon best-track information, and is trained on the UM dataset from 2010-2018. The UM data undergoes bias correction to enhance its accuracy, and the model is evaluated using various metrics like ADE and FDE. The authors claim improvements over existing methods, including state-of-the-art data-driven approaches and traditional numerical weather prediction models. However, the paper has been criticized for its lack of novelty, poor writing quality, and insufficient empirical validation, especially concerning the bias correction methods and the handling of historical data.\n\n**Strengths**\n- The paper addresses a significant and relevant topic, focusing on typhoon trajectory prediction, which is crucial for disaster preparedness and mitigation.\n- The use of Unified Model (UM) and ERA5 data is highlighted, providing a robust dataset for model training and evaluation.\n- The introduction of a bias correction method for UM data is innovative and potentially valuable for improving trajectory predictions.\n- The paper is well-structured, making it accessible and easy to follow, and provides a clear summary of the related work.\n- The proposed methodology appears to improve upon existing methods, demonstrating enhanced performance metrics such as ADE and FDE.\n\n**Weaknesses**\n- The novelty of the approach is questioned, as it seems to be a straightforward combination of existing methods without significant innovation.\n- The paper suffers from poor writing quality, with numerous grammatical errors, unclear definitions, and inconsistencies in terminology.\n- The use of historical data, particularly the UM dataset from 2010-2018, is problematic as it may not reflect current typhoon patterns or dynamics.\n- There is a lack of detailed empirical validation for the bias correction method, which raises concerns about its effectiveness and reliability.\n- The paper does not adequately address the limitations and potential biases introduced by the UM and ERA5 data, such as the impact of data processing on the accuracy of trajectory predictions.\n- The evaluation metrics and comparisons with other models are not sufficiently robust, and the paper lacks detailed experimental results and statistical significance tests.\n- The paper's presentation and organization need significant improvements to enhance clarity and readability.\n\n**Questions**\n- Could you clarify the specific contributions of this paper in terms of novelty and technical advancements?\n- How does the bias correction method improve the accuracy of typhoon trajectory predictions, and what is the justification for its use?\n- What is the rationale behind using a UM dataset from 2010-2018, and how does this affect the generalizability and applicability of the model to current and future typhoon trajectories?\n- Can you provide more detailed empirical evidence to support the effectiveness of the bias correction method and address the concerns about its reliability?\n- How do you address the limitations and potential biases introduced by the UM and ERA5 data, and what measures are taken to ensure the accuracy of trajectory predictions?\n- Could you elaborate on the evaluation metrics and comparisons with other models, including the statistical significance tests used?\n- What are the specific improvements and enhancements made to the manuscript to address the reviewers' concerns about writing quality and presentation?"
    },
    "nrDRBhNHiB": {
        "gold": "**Summary**\nThe paper explores extending regularization paths from linear models to deep neural networks (DNNs) by introducing a multi-objective optimization framework that combines empirical loss with sparsity regularization. The authors propose a novel algorithm composed of a stochastic gradient descent coupled with a proximal mapping and a multi-objective update, aiming to efficiently approximate the Pareto front of solutions. The methodology is validated using experiments conducted on the MNIST dataset. This paper provides a new insight into handling sparsity constraints in DNNs through its predictor-corrector approach to navigate along the regularization path effectively, addressing the issue of model overfitting by incorporating sparsity into the training process.\n\n**Strengths**\n- The paper presents a novel approach using an approximation of the Pareto front to enhance multi-objective optimization for non-linear, high-dimensional deep learning models, potentially avoiding overfitting and achieving low loss with sparsity.\n- The incorporation of a predictor-corrector scheme is innovative, helping to avoid clustering around unregularized and very sparse solutions, a significant improvement over the weighted sum approach.\n- The method is validated with a commonly used dataset, providing some empirical evidence of the technique's effectiveness.\n- Extensive background information and a clearly outlined methodology make the paper accessible and comprehensible.\n- The idea of considering multi-objective optimization to tackle the sparsity constrained problem is novel and effectively challenges the traditional single-objective frameworks in deep learning.\n\n**Weaknesses**\n- The paper does not provide adequate comparisons with existing regularization path generation methods, which is crucial for situating the novel contributions within the broader research landscape.\n- There is a lack of comprehensive experimental validation across more complex datasets and with deep neural networks that include non-linear layers, which undermines the generalizability of the results.\n- Key references are missing, including those related to the extension of regularization paths from linear models to deep neural networks, potentially overlooking valuable prior work and context.\n- The experimental setup and results need to detail computational time metrics to substantiate efficiency claims.\n- The method's applicability seems limited to two-objective problems, questioning its utility for more complex multi-objective settings.\n- The experiments conducted appear insufficient, especially considering the simplicity of the used networks and datasets which might not convincingly demonstrate the method's efficacy in more challenging scenarios.\n\n**Questions**\n- Can the authors explain how they plan to extend their method to handle more complex datasets and deeper neural networks with non-linear layers, as briefly mentioned in their discussion?\n- What strategies are proposed for efficiently determining initial points and handling random multi-starts in complex network structures without causing significant bottlenecks?\n- How does the proposed method compare in computation time and accuracy with traditional approaches to regularization path generation which incrementally increase L1 penalties?\n- Given the method's reliance on stochastic gradients, are there concerns about variability in performance or iteration times due to different initial points?\n- Are there plans to explore the use of non-convex penalties like SCAD/MCP instead of the L1 penalty, which is known to introduce bias in weight estimates?\n- How do the authors justify the absence of multiple loss functions in their experiments considering their claim of addressing multi-objective optimization?\n- Could the proposed methodology be effectively applied to find the Pareto front of a series of Lottery Ticket Subnetworks?",
        "5_5": "**Summary**\nThe paper discusses a novel continuation algorithm for computing the regularization path in deep neural networks, addressing the trade-off between the empirical loss and the L1-norm of the model parameters. This method extends previous work by Bieker et al. (2022) to handle non-convex objectives, achieving a reduction in computational cost and improving efficiency. The paper presents numerical results on the MNIST dataset, demonstrating the efficacy of the proposed algorithm. However, the paper has received criticism for its lack of rigorous theoretical analysis and experimental validation, particularly in comparing the performance of the proposed method against existing techniques. Furthermore, the paper's claim of efficiency is questioned due to the potentially high computational costs involved in solving optimization problems at each step of the regularization path.\n\n**Strengths**\n- The paper is well-written, clear, and easy to understand, making complex concepts accessible.\n- The authors successfully extend the regularization path methodology to a non-convex setting, addressing a significant issue in the field.\n- The proposed continuation algorithm is described as efficient, with a potential reduction in computational cost compared to previous methods.\n- The numerical results presented are promising, suggesting that the method is effective in finding the regularization path.\n- The paper is well-organized and structured, making it easy to follow.\n\n**Weaknesses**\n- The paper lacks a rigorous theoretical analysis of the proposed method, specifically concerning the convergence properties and the impact of hyperparameters.\n- There is a lack of experimental validation, particularly a comparison with other existing methods that compute regularization paths.\n- The paper does not address the scalability of the proposed method, particularly in terms of its applicability to large-scale datasets.\n- The method's efficiency claims are questioned due to the potential high computational cost associated with solving optimization problems at each step of the regularization path.\n- There is a lack of clarity in the experimental setup and results, specifically concerning the choice of hyperparameters and the performance metrics used.\n- The paper does not discuss the sensitivity of the results to hyperparameters or the impact of the non-convex nature of the objective function on the regularization path.\n- There is a concern regarding the reproducibility of the results, as the code is not provided, and the method's applicability to other datasets is not demonstrated.\n\n**Questions**\n- Could the authors provide a more detailed theoretical analysis of the proposed method, including convergence proofs and sensitivity analysis regarding hyperparameters?\n- Can the authors compare the proposed method with other existing methods that compute regularization paths to validate the claimed efficiency and effectiveness?\n- How does the proposed method scale to larger datasets, and what are the computational costs involved?\n- What are the specific performance metrics used in the experiments, and how do these metrics relate to the objectives of the study?\n- Why were specific hyperparameters chosen for the experiments, and how do these choices affect the results?\n- Could the authors discuss the impact of the non-convex nature of the objective function on the regularization path, and provide insights into how this affects the method's performance?\n- Can the authors provide more details on the experimental setup, including the choice of network architectures and the datasets used?",
        "5_3": "**Summary**\nThe paper discusses a novel approach to train deep neural networks (DNNs) by treating the empirical loss and sparsity (\u21131 norm) as conflicting objectives in a multiobjective optimization problem. The authors propose an algorithm that efficiently approximates the entire Pareto front for these objectives using continuation methods. The paper provides numerical examples that demonstrate the effectiveness of this method over traditional weighted sum approaches, particularly in terms of computational efficiency and the ability to identify sparse network configurations that balance training loss and sparsity. Despite its innovative approach and promising results, the paper faces criticism for its clarity, especially in the algorithm's description, and for insufficient comparative analysis with existing methods.\n\n**Strengths**\n- The paper presents a novel approach to training deep neural networks (DNNs) by treating the empirical loss and sparsity (\u21131 norm) as conflicting objectives in a multiobjective optimization problem, which is an innovative perspective.\n- The algorithm is computationally efficient and is shown to be capable of handling a large number of degrees of freedom, making it applicable to high-dimensional DNNs.\n- The paper provides a detailed numerical analysis that demonstrates the effectiveness of the proposed method in terms of computational efficiency and ability to identify sparse network configurations that balance training loss and sparsity.\n- The method's ability to identify sweet spots on the Pareto front is highlighted, which is particularly useful for achieving a balance between competing objectives in machine learning applications.\n- The paper is well-structured and easy to follow, with clear motivation and presentation of the main contributions.\n\n**Weaknesses**\n- The paper lacks a clear and detailed algorithm description, particularly in terms of the predictor step and the convergence analysis of the algorithm.\n- There is insufficient discussion on the choice and impact of hyperparameters such as \u03bb and the step size h, and how these affect the performance and efficiency of the algorithm.\n- The experimental results do not provide sufficient comparative analysis with existing methods, which undermines the strength of the claims regarding the efficiency and effectiveness of the proposed method.\n- The paper has unclear and incomplete references, with several references not being properly cited or being in the wrong format.\n- The algorithm description in the paper is not detailed enough to fully understand its implementation and potential application in real-world scenarios.\n- The writing and structure of the paper could be improved for better clarity and comprehensibility, particularly in the methodology section.\n\n**Questions**\n- Could you provide more details on the predictor step of your algorithm, particularly how it is designed to work with non-smooth functions such as the \u21131 norm?\n- How does the choice of hyperparameters such as \u03bb and the step size h impact the performance and efficiency of the algorithm? What are the optimal values for these parameters?\n- Can you provide more comprehensive comparative analysis of your method against existing methods, including a detailed discussion on the computational efficiency and performance metrics?\n- How does the algorithm handle scenarios where the objective functions are non-convex, and what are the implications of this on the Pareto front?\n- Could you clarify the reference to \"continuation methods for multiobjective optimization problems\" mentioned in the introduction? Is this referring to a specific existing method or technique?\n- Please provide a detailed explanation of the notation used in the paper, particularly the usage of symbols like x^\u2217 and \u03bb."
    },
    "Ue93J8VV3W": {
        "gold": "**Summary**\nThe paper introduces eight graph datasets each containing 7-31 features per node and evaluates various machine learning models against these benchmarks, focusing on heterogeneous node features. Named 'TabGraph', the benchmarks provide a mix of feature types, node numbers, average degrees, and domains. The paper discusses the implementation of models like GNNs, tabular deep learning, and tree models, alongside a hybrid approach. Various recommendations and analyses are given for both tabular and graph machine learning fields. The contribution centers around bridging the gap between traditional tabular data modeling and newer graph-based machine learning techniques. However, the paper lacks in-depth theoretical insights and substantial novelty in methodology, bringing into question its authenticity and potential impact on the field.\n\n**Strengths**\n- The new datasets include useful node-level features, especially enriching existing benchmarks with additional attributes that add realism to the graph datasets.\n- The paper provides several benchmark datasets useful for machine learning models focusing on both tabular and graph-based approaches, along with combinations of the two.\n- There are valuable insights and recommendations for researchers and practitioners working with a mix of tabular and graph data.\n- The introduction of performance comparison across various machine learning models for tabular data and graph-based models highlights the applicability in real-world scenarios.\n- The paper effectively fills the gap between machine learning for tabular data and graph machine learning by comprising datasets of different kinds and attempting a comprehensive evaluation of major models.\n- The structure of the paper is commendable, making it a readable and approachable resource.\n\n**Weaknesses**\n- The paper lacks in-depth discussion on the rationale for dataset construction and does not thoroughly analyze the qualitative properties of newly created datasets.\n- There is a significant need for greater insight into the empirical study, which currently only presents results from base models without further analytical discussion.\n- The document does not effectively differentiate between transductive and inductive settings in its analysis, a distinction crucial for the applicability of graph neural networks and graph-based machine learning.\n- The paper's focus and contribution towards \"research\" are weak, leaning more towards being a dataset paper rather than offering significant advancements in graph learning.\n- There are unaddressed limitations, such as the conversion of relational data into graphs, the computational costs associated, and the non-inclusion of certain data types like strings or texts which are crucial in tabular data.\n- The methodology for dataset selection and preprocessing lacks clarity and comprehensiveness.\n- Insights provided are not entirely convincing due to the dataset being preprocessed by undisclosed rules.\n\n**Questions**\n- What was the specific criteria for the selection of these eight tabular datasets?\n- How does the paper address the difference between transductive and inductive learning methods, particularly in performance comparison?\n- Can the authors provide clarity on the comparative model performances on homogeneous features versus heterogeneous features to demonstrate the efficacy of the proposed datasets?\n- Why were strings or text data types not included in TabGraph, and how does this omission affect the benchmarks provided?\n- Could the authors explain their decision-making process regarding which features to include or exclude during dataset preprocessing, such as the number of votes in GBDT experiments?\n- What is the rationale behind the choice of thresholds for different datasets as mentioned in Section 3.1?\n- Is there a plan for adding at least one dataset from the science domain for node classification and regression tasks?\n- Can the importance of different types of features (number, binary, categorical) be comparatively analyzed in the paper?\n- What are the expected dates for the release of the source code and the datasets?\n- Could the authors elaborate on the resource implications of converting tabular data into graphs, considering computational limits and other constraints?",
        "5_5": "**Summary**\nThe paper introduces a benchmark named TabGraphs, designed to evaluate machine learning models on tabular data structured as graphs, emphasizing the incorporation of heterogeneous features. This benchmark aims to fill the gap in existing datasets by offering a diverse set of graph datasets with heterogeneous node features, focusing on practical, real-world applications. The authors conducted extensive experiments using a variety of machine learning models, including traditional tabular models, deep learning models, and graph neural networks (GNNs). Their findings highlight the potential of graph models in enhancing predictive performance over traditional tabular models, particularly with the integration of feature embeddings and specific GNN architectures.\n\n**Strengths**\n- The paper addresses an important and timely issue of combining tabular and graph machine learning, which is highly relevant in the current research landscape.\n- The introduction of the TabGraphs benchmark, featuring a diverse set of datasets with heterogeneous features, is a significant contribution to the field, helping to bridge the gap between tabular and graph machine learning.\n- The experimental setup is thorough, providing a comprehensive evaluation of various machine learning models, including traditional tabular models, deep learning models, and graph neural networks.\n- The paper offers a clear and detailed explanation of the datasets and experimental setup, making it accessible and understandable to a broad audience.\n- The results presented in the paper are encouraging, showing that graph models can outperform traditional tabular models in many scenarios.\n\n**Weaknesses**\n- The paper lacks a clear motivation and justification for using tabular data structured as graphs, particularly in the context of the datasets used, which are not inherently graph-structured.\n- The experimental results are presented in a way that does not clearly distinguish between different models' performance, which could lead to confusion about the effectiveness of various approaches.\n- The literature review is insufficiently comprehensive, particularly regarding recent studies on node property prediction and graph learning for tabular data.\n- The paper does not sufficiently discuss the limitations of the proposed benchmark and does not compare the performance of the TabGraphs benchmark against other existing datasets or benchmarks.\n- Some of the terminology and notation used in the paper are unclear or inconsistent, which could hinder understanding and replication of the work.\n- The paper does not provide a clear justification for the choice of specific datasets or the exclusion of other relevant datasets, which could impact the perceived validity and generalizability of the results.\n\n**Questions**\n- Could you provide more details on the motivation behind using tabular data structured as graphs, especially considering the datasets used in your study?\n- How do you justify the choice of specific datasets for your study, and why were other datasets not included?\n- Could you clarify the notation used in the paper, particularly the use of \"R\" in equations and the notation of datasets?\n- Can you explain the decision-making process behind selecting the specific machine learning models for evaluation in your study?\n- Why was the evaluation of the benchmark limited to the models mentioned, and could you consider including a broader range of models in future studies?\n- Could you provide more details on the experimental setup, particularly the choice of metrics and the methodology for comparing the performance of different models?",
        "5_3": "**Summary**\nThe paper presents a benchmark for graph datasets with heterogeneous features, specifically focusing on tabular data. The authors introduce a collection of datasets derived from various sources, including academic and proprietary data, to study graph-structured data with tabular features. The benchmark aims to explore the performance of machine learning models, particularly graph neural networks (GNNs), on these datasets. Key findings indicate that GNNs can outperform traditional methods like decision trees in certain scenarios. However, the paper faces criticism for its limited novelty, unclear motivations, and a lack of comprehensive experimental results. The benchmark, while promising, requires more rigorous testing and validation, particularly across different tasks and model types.\n\n**Strengths**\n- The paper introduces a novel benchmark dataset which can serve as a valuable resource for the community.\n- The paper is clearly written, making it accessible and easy to follow.\n- The benchmark covers a wide range of tabular datasets and evaluates a diverse set of models, including GNNs, providing a comprehensive evaluation of existing methods.\n- The experimental setup is well-structured, enhancing reproducibility and facilitating future research in this area.\n\n**Weaknesses**\n- The novelty of the paper is limited as it primarily combines existing datasets without significant new contributions or insights.\n- The motivation behind the creation of the benchmark is unclear and not well articulated, particularly why tabular data is treated as a graph.\n- The paper lacks a detailed discussion of the challenges and limitations of the benchmark, which is crucial for its utility and adoption by the community.\n- The experimental results are insufficiently detailed, with limited discussion on model performance across different datasets and tasks.\n- There is a lack of comprehensive testing, particularly in terms of the number of runs and the evaluation of hyperparameters, which undermines the reliability of the results.\n- The paper does not adequately address the differences between tabular and graph machine learning, nor does it provide sufficient justification for the focus on GNNs over other models.\n\n**Questions**\n- What motivated the authors to treat tabular data as a graph, and what specific challenges does this approach address?\n- Can the authors clarify the criteria used for selecting datasets and the rationale behind the choice of GNNs over other models?\n- How does the benchmark address the differences between tabular and graph machine learning, and what are the implications for the models evaluated?\n- In terms of experimental setup, could the authors provide more detailed information on the number of runs and the evaluation of hyperparameters?\n- Why were certain datasets excluded from the study, and what are the implications of this exclusion for the benchmark's validity?\n- Could the authors provide more insights into the performance of models across different datasets and tasks, and discuss any notable trends or challenges observed in the experimental results?"
    }
}