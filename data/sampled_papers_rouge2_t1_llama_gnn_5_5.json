{
    "0jsfesDZDq": {
        "gold_review": "**Summary**\nThis paper introduces a novel task-agnostic method called Lyapunov Noise Pruning (LNP) for designing sparse Recurrent Spiking Neural Networks (RSNNs) from an untrained and arbitrarily initialized dense network. The method utilizes the Lyapunov spectrum and spectral graph sparsification algorithms to prune synapses and neurons while retaining network stability, enabling the sparse network to be later trained for various tasks. The methodology has been shown to outperform alternative pruning approaches in terms of network efficiency, while maintaining similar performance levels on diverse down-streaming tasks and datasets. The paper\u2019s novelty lies in its approach to pruning prior to training, which is not commonly addressed in typical models that prune post-training.\n\n**Strengths**\n- The paper is well-written, providing clear illustrations of the methods and implementations, making it approachable for readers.\n- Introduces a novel, task-agnostic method for designing sparse RSNN (Recurrent Spiking Neural Networks), which significantly contrasts with conventional task-dependent pruning approaches.\n- Demonstrates that Lyapunov Noise Pruning (LNP) can enhance network efficiency over alternative methods like AP (Activity Pruning), which supports its potential utility in network pruning.\n- The proposed method utilizes the heterogeneous timescales of RSNNs, offering biological plausibility and further aiding the pruning process, proving to be not only task-agnostic but also learning-rule-agnostic.\n- Despite its novelty, the technique considers the equivalence between dense and sparse networks, which increases its suitability for models like HRSNN.\n\n**Weaknesses**\n- The paper does not fully explain the motivation behind focusing specifically on RSNNs or the significance of LNP within the broader field of SNNs.\n- Lack of clarity in differentiating between the dynamics of recurrent network structures and the intrinsic recurrency of spiking neurons.\n- The experimental design and the chosen network models might be too simplistic and might not reflect the prunability needed in more complex or real-world scenarios.\n- Inconsistencies and lack of clarity in the references and citations, suggesting a need for better organization of literature and referencing.\n- The results section lacks error bars for CIFAR-10, omitting necessary details about accuracy variance that could indicate performance reliability.\n- The contribution of each component of LNP is not clearly delineated through an ablation study, weakening the argument for the necessity of each in the overall performance of the method.\n\n**Questions**\n- 1. Could you clarify why RSNNs were chosen for applying LNP, particularly when considering the unique challenges posed by the dual dynamics inherent in these networks?\n- 2. How does LNP address the discontinuity characteristically associated with spikes in RSNNs, especially when analyzing the Lyapunov spectrum?\n- 3. What does \"heterogeneous\" signify in the context of timescales in RSNN? Is it merely referring to variable time constants, or is there a broader interpretation?\n- 4. Can the authors explain the impact of random initialization versus LNP initialization on the network dynamics during training?\n- 5. Given that some studies like that by Panda et al., have shown different results, what are the specific advantages or shortcomings of the LNP method in comparison?\n- 6. There is mention of using Lorenz and Rossler datasets which are not typical in SNN research. Could you provide justifications or citations for their use?\n- 7. Is it possible to apply the principles and methods of LNP to non-recurrent, purely feed-forward SNNs to test its generalizability across different network architectures?",
        "inference_review": "**Summary**\nThis paper introduces the Lyapunov Noise Pruning (LNP) method, a novel approach for pruning Recurrent Spiking Neural Networks (RSNNs) to enhance computational efficiency and accuracy. LNP employs spectral graph sparsification and the Lyapunov spectrum to identify and eliminate redundant neurons and synapses, ensuring network stability. The paper demonstrates the efficacy of LNP through experiments on both synthetic and real-world datasets, showcasing improved performance metrics over traditional methods. Furthermore, the paper explores the application of LNP to heterogeneous RSNNs (HRSNNs), which exhibit diverse neuronal timescales, thereby improving network performance.\n\n**Strengths**\n- The paper addresses a novel and significant problem of pruning spiking neural networks, which is a critical issue given the high computational costs of these networks.\n- The introduction of a Lyapunov-based pruning method is both innovative and timely, with a clear and well-presented algorithm.\n- The paper provides a thorough explanation and analysis of the proposed method, including its application to HRSNN, which demonstrates a better performance compared to other methods.\n- The results of the experiments are compelling, indicating that the proposed method outperforms existing techniques in terms of accuracy and computational efficiency.\n- The paper is well-written, providing a clear exposition of the research problem, methodology, and results, making it accessible and understandable.\n\n**Weaknesses**\n- The novelty of the approach is questionable as it primarily combines existing techniques (spectral graph sparsification and Lyapunov spectrum analysis) with no substantial theoretical contribution.\n- The paper lacks a detailed description of the datasets used in the experiments and does not provide sufficient details about the training process, such as the architecture of the models used.\n- There is a significant lack of experimental validation on real-world datasets, which is crucial for assessing the practical applicability of the proposed method.\n- The paper does not sufficiently explore the potential impact of the proposed method on model interpretability and does not address the computational cost associated with the pruning and training process.\n- The method's claim of being task-agnostic is not convincingly supported, as the pruning results are not consistently better across all tasks.\n- The paper does not discuss the impact of the pruning method on the training of spiking neural networks, particularly in scenarios where spiking networks are more suitable than non-spiking networks.\n\n**Questions**\n- Could the authors clarify the novelty of their approach and provide a detailed comparison with other existing methods?\n- How do the authors address the challenge of applying the proposed method to real-world datasets, and what are the specific advantages of using spectral graph sparsification in this context?\n- In the context of computational cost, how does the pruning and training process impact the overall efficiency of the model, and what are the implications for real-world applications?\n- How does the proposed method perform on other types of spiking neural networks, such as those with different types of neurons or network structures?\n- Can the authors provide additional experimental results, particularly on real-world datasets, to further validate the effectiveness and applicability of the proposed method?\n- How does the method address the issue of interpretability in spiking neural networks, and what are the potential implications for model understanding and trustworthiness?"
    },
    "30L0rr9W8A": {
        "gold_review": "**Summary**\nThe paper explores safe data-driven control with neural networks where true state access is unavailable. It innovatively embeds observations in a latent space using a Lipschitz autoencoder, on which a safe controller and dynamics are learned without explicit safe or unsafe set definitions. The approach involves learning the dynamics and control barrier function (CBF) in this latent space, using a QP-CLF based approach or directly regressing over gradients. These components are learned end-to-end, and experimental validations on common CBF benchmarks and the CARLA simulator are provided. There seems to be a significant focus on theoretical aspects, particularly around embedding dynamics and safe control optimization in a latent space, postulating an interesting mechanism to handle partial observability.\n\n**Strengths**\n- The idea of embedding the dynamics in a latent space and performing safe control optimization therein is innovative, allowing for the learning of both the dynamics and the safe controller without pre-specifying safe sets or dynamics.\n- The novelty of learning a Control Barrier Function (CBF) in the latent space shows significant potential, and the use of Lipschitz neural networks and Bjorck layers provides a robust framework for this purpose.\n- The presentation and the figures in the paper are of high quality, clearly demonstrating the results and adding credibility to the experimental outcomes, which are convincingly good, particularly highlighted by the results from the CARLA simulation.\n- The paper is generally well-written, making it accessible and easy to follow.\n\n**Weaknesses**\n- The discussion on safety, specifically regarding barrier certificates, is too brief and lacks clarity. The conditions for barrier certificates should explicitly pertain to the interior of the safe set, and this delineation is not adequately drawn out.\n- The manuscript fails to provide discussions or guarantees that the safety constraints in the latent space will map appropriately onto the actual physical space, raising concerns about real-world applicability and the robustness of safety claims.\n- There is a notable absence of a detailed explanation on the need for and advantage of using Lipschitz autoencoders over other potential data-driven control methods like reinforcement learning or Gaussian processes.\n- The practical benefits of this approach remain under-discussed, particularly in comparison to other existing methods, where some level of prior knowledge about dynamics can significantly enhance training realism and stability.\n- The paper lacks sufficient theoretical detail to ensure that the notions of traditional CBFs carry over effectively into the latent space, such as the ensuring of the injectiveness of the encoder or concerns regarding the dimensionality and topology of the latent space compared to the original state space.\n- Certain technical descriptions and mathematical expressions require refinement for better clarity and precision.\n- There is a lack of discussion about the training stability and details, including whether training was end-to-end, the robustness of the learning across various trials, and the specifics of the encoder training process.\n\n**Questions**\n- How does this work relate to traditional methods of data-driven output feedback control in terms of approach and effectiveness?\n- Can the latent-space embedding be considered a form of neural observer? If not, why does this distinction exist?\n- Is there a rigorous way to analyze the performance and safety of the decoded trajectories in real scenarios? What are the metrics for judging the reliability of safety in practical applications?\n- Considering that the true state might often be inaccessible, how does this model compete with systems where partial state information is utilized to enhance learning accuracy and efficiency?\n- Given the compromise on theoretical strictness (using a soft loss function for CBF), is there a methodology planned for reinforcing these approximate models via verification mechanisms?\n- Can details be provided about the epsilon-deviation behavior from safety boundaries during empirical evaluations and the implications for persistent safety?\n- Lastly, how do the authors address potential disconnects or topological disparities when mapping from the latent space configurations to the original state space structure, particularly in terms of safety set connectivity?",
        "inference_review": "**Summary**\nThe paper introduces the LatentCBF framework, which employs a data-driven control barrier function (CBF) to enhance safety in autonomous systems like cars and drones. The novel approach defines the CBF in the latent space, which is derived from observations through an autoencoder, and learns the system dynamics and control barrier functions simultaneously. The framework is tested in simulated environments, showcasing its ability to maintain safety without requiring full state information. The paper also proposes using a Lipschitz network-based AutoEncoder to ensure the Lipschitz continuity of the CBF, which is crucial for the theoretical safety guarantees of the framework. Despite its innovative approach, the paper has been critiqued for its lack of empirical validation in real-world scenarios, unclear theoretical contributions, and poor presentation that makes it difficult to follow.\n\n**Strengths**\n- The paper introduces a novel framework for safe control in autonomous systems, particularly focusing on using a data-driven control barrier function (CBF) that operates in the latent space, which is derived from observations through an autoencoder.\n- The use of a Lipschitz network-based autoencoder is highlighted as a significant contribution, ensuring the Lipschitz continuity of the CBF, which is crucial for theoretical safety guarantees.\n- The framework has been tested in simulated environments, demonstrating its ability to maintain safety without requiring full state information, which is a notable advancement over traditional methods that rely on full state knowledge.\n- The paper explores the use of a data-driven approach to learn the CBF, which could potentially lead to more practical and adaptable safety protocols in autonomous systems.\n\n**Weaknesses**\n- The paper lacks empirical validation in real-world scenarios, which is crucial to establish the effectiveness and robustness of the proposed framework in practical applications.\n- The theoretical contributions of the paper are not clearly outlined, making it difficult to discern the specific novel contributions of the framework.\n- The presentation of the paper is problematic, with a significant amount of content relegated to the appendix, making it difficult for readers to grasp the main ideas and contributions of the research.\n- The paper does not sufficiently justify the choice of using a Lipschitz network-based autoencoder, and the empirical performance of the proposed framework compared to other methods (like rCBLF-QP and BarrierNet) is not convincingly demonstrated.\n- There is a lack of detailed comparison with existing methods, particularly in terms of computational efficiency, which is a critical aspect for real-time applications.\n\n**Questions**\n- Could the authors provide empirical evidence of the framework's performance in real-world scenarios to validate its effectiveness and robustness?\n- How does the proposed framework compare in terms of computational efficiency with other methods like rCBLF-QP and BarrierNet?\n- What specific theoretical contributions does the paper offer, and how do these contribute to the field of safe control in autonomous systems?\n- Can the authors clarify the choice and necessity of using a Lipschitz network-based autoencoder in their framework?\n- Is there a detailed explanation or empirical evidence that supports the claim that the proposed framework is more suitable for defining a neural barrier function compared to traditional networks?"
    },
    "4y3GDTFv70": {
        "gold_review": "**Summary**\nThe paper provides a theoretical explanation for emergent abilities in large language models (LLMs), such as in-context learning, chain-of-thought prompting, and instruction fine-tuning, by linking these to Bayesian inference on latent intentions underlying the language. The authors argue that emergent capabilities arise from the compositional structures in language encoded within the distribution of LLMs, describing the relationship through a mixture model. They present some formal results and use synthetic data for experimental validation. However, the paper seems to make minor adjustments to existing frameworks (e.g., Xie, 2022) without adding substantial novelty. Reviewers critiqued the formalization of concepts and argued that certain sections lack specificity or formal arguments.\n\n**Strengths**\n- The paper tackles crucial concepts such as in-context learning, Chain of Thought (CoT), and instruction fine-tuning, which are significant in the study of large language models (LLMs).\n- The manuscript is well-written, clear, and follows a logical structure, making it easy for readers to follow the argumentation and analyses presented.\n- The study introduces a novel perspective on the role of language and underlying intentions in enabling emergent properties of LLMs.\n- The formal results and theoretical discussions, particularly the soundness of the theoretical results, are compelling and substantiate the arguments made.\n- The paper includes comparisons of the proposed model with different applications and capabilities of LLMs, enhancing the reader's understanding of the practical implications of the theory.\n\n**Weaknesses**\n- The paper struggles with novelty in theoretical results, as some of the concepts, including in-context learning as state or intention estimation, have been previously defined by Xie, 2022.\n- The characterization and definition of the CoT prompts and instruction fine-tuning sections are not rigorous, causing difficulties in understanding how they build on the foundational concepts of LLMs, particularly in-context learning.\n- Sections on Chain-of-Thought prompting and instruction fine-tuning are vague and lack formal specificity, particularly in how these sections tie back to the foundational model of generative cognition in LLMs.\n- The paper does not adequately address the implications of using different types of tokenizers (like character-based versus BPE tokenizers) in experimentation on the findings and their generalizability to standard LLM behaviors.\n- There is insufficient discussion on how the use of synthetic data impacts findings, and there\u2019s a lack of statistical significance tests or uncertainty estimates to substantiate the results.\n\n**Questions**\n- Can you clarify the definitions provided in Section 2 regarding the concept of \\(\\epsilon\\)-ambiguity and the terms and conditions used in characterization?\n- The proof of Theorem 1 references neural networks and SGD\u2014how do these fit into the discussion since the theorem itself does not specify architecture or training procedures?\n- How does the paper\u2019s approach to identifying and defining emergent behaviors compare to other contemporary theories, such as those proposed by Arora et al. (2023)?\n- Please elaborate on the hyperparameter selection for the LMs and the impact these parameters have on the findings presented in the paper.\n- Is there a noticeable difference between the outcomes when using character-based models versus BPE tokenizers in your experiments?\n- Could you discuss how well the model's findings might adapt or apply to natural language, outside the confines of structured experimental setups?",
        "inference_review": "**Summary**\nThe paper explores the capabilities of large language models (LLMs) through a novel lens, focusing on their ability to perform well on unseen tasks by leveraging their training on extensive datasets. It proposes a latent space theory to explain these emergent capabilities, specifically attributing them to Bayesian inference on the sparse joint distribution of languages. The authors argue that LLMs can perform effectively due to their ability to approximate the marginal distribution of languages, which is claimed to be sparse, thereby allowing for efficient inference. The paper is supported by both theoretical and simulated results, which are aimed at substantiating the claims made by the authors.\n\n**Strengths**\n- The paper is well-written and provides a clear explanation of the concepts involved, making it accessible to readers.\n- It proposes a novel latent space theory to explain the emergent capabilities of large language models (LLMs), which is an interesting and potentially impactful contribution to the field.\n- The authors provide a solid theoretical foundation for their claims, which is complemented by simulated results that help to substantiate their arguments.\n- The paper explores the properties of language generation through a latent space model, which is both an intuitive and effective way to study the problem.\n- The paper is well-motivated, providing a logical progression from the problem statement to the proposed solution, which makes it easy to follow and understand.\n\n**Weaknesses**\n- The paper does not clearly define what is meant by the \"emergent capabilities\" of LLMs, which could lead to confusion about the specific abilities being discussed.\n- The authors claim that the marginal distribution of languages is sparse, which is not supported by empirical evidence or existing literature. This claim is crucial to the validity of the paper's main argument.\n- The paper lacks a detailed discussion on the practical implications of the proposed latent space theory, which could limit its applicability in real-world scenarios.\n- There is a lack of clarity regarding how the theory relates to other existing works, such as the theory of in-context learning as Bayesian inference proposed by Xie et al. (2022). A more thorough discussion on the differences and similarities could enhance the paper's contribution.\n- The paper does not provide sufficient empirical evidence to support its claims, particularly regarding the sparsity of the marginal distribution and the effectiveness of the proposed approach.\n- The presentation of the paper could be improved, particularly in the organization and clarity of the theoretical sections.\n\n**Questions**\n- Could the authors clarify what is meant by \"emergent capabilities\" in the context of this paper?\n- How do the authors justify the claim that the marginal distribution of languages is sparse, and what empirical evidence supports this claim?\n- Can the authors provide more details on how the proposed latent space theory can be applied in practical scenarios, and what are the benefits of this approach compared to existing methods?\n- How does the proposed theory relate to the work by Xie et al. (2022) on in-context learning as Bayesian inference, and what are the key differences between the two approaches?\n- Could the authors provide more empirical evidence to support their claims, particularly regarding the sparsity of the marginal distribution and the effectiveness of the proposed approach?\n- How does the paper address the practical challenges of estimating the marginal distribution of languages, and what are the implications for the proposed latent space theory?"
    },
    "73dhbcXxtV": {
        "gold_review": "**Summary**\nThe paper introduces a novel framework, LOLAMEME, which aims to expand mechanistic understanding by integrating logic, memory, and nuanced language aspects through two manifestations: LoLa and MeMe languages. It presents a hybrid architecture named T HEX, which modifies the Hyena model by incorporating GPT-2 layers. Various experiments are conducted to benchmark T HEX against traditional GPT-2 and Hyena models, showing improvements in specific tasks and on targeted datasets. Despite these advancements, the paper lacks clarity in the motivation behind model design and requires substantial improvements in presentation, including addressing grammatical errors and inconsistencies in data description.\n\n**Strengths**\n- The research proposes an innovative hybrid architecture combining transformer-based GPT-2 and convolution-based Hyena, demonstrating improved performance on selected test datasets.\n- The creation of the LOLAMEME framework and its implementation in constructing multiple datasets with several billion tokens adds significant value and potential for future research in the field.\n- Comprehensive experiments have been conducted across these datasets and a related benchmark to evaluate the effectiveness of the new framework, showing promising results.\n\n**Weaknesses**\n- The motivation behind the model design and problem formulation is unclear, with insufficient explanation of the differences and relative strengths between T HEX, GPT-2, and Hyena architectures.\n- The novelty seems limited as the primary architectural changes involve straightforward layer replacements between the Hyena model and GPT-2.\n- The paper suffers from structural inconsistencies, unclear dataset construction details, and several typographical and grammatical errors in key sections, including the abstract and tables.\n- The related work section lacks a comprehensive review of existing literature, particularly in areas of mechanistic interpretability of large language models (LLMs).\n- Experiments lack depth in analysis, providing limited insight into why certain architectural changes lead to observed performance differences, and do not explore a broader range of existing datasets to validate findings.\n- Inconsistencies in experimental results and reporting, such as the unexplained loss metrics in section 6.5, need addressing to bolster the credibility of the results.\n\n**Questions**\n- Could you clarify the specific motivations and problem formulations that led to the development of the hybrid T HEX model?\n- What distinguishes the T HEX model from its components, GPT-2 and Hyena, and what are the advantages of this hybrid approach?\n- Why is there a lack of in-depth analysis or interpretation of the experimental results regarding the specific effects of architecture modifications?\n- Could an illustration of the LOLAMEME framework be provided to aid in understanding its structure and role within the research?\n- How can the experimental settings be improved to more reliably reflect model behaviors such as memorization and in-context learning, and why were these settings chosen?",
        "inference_review": "**Summary**\nThe paper introduces LoLaMeMe, a framework aimed at mechanistic evaluation of language models, particularly focusing on logical reasoning and memory. LoLaMeMe is designed to generate synthetic datasets with varying complexities to evaluate the models' performance. The framework includes a hybrid architecture, T Hex, which is shown to outperform GPT-2 and Hyena on the proposed tasks. However, the paper lacks a comprehensive evaluation across different datasets and architectures, which raises questions about its generalizability and scalability. Additionally, concerns are raised regarding the novelty of the proposed framework and the lack of thorough comparisons with existing benchmarks.\n\n**Strengths**\n- The paper addresses an important and timely topic in the evaluation of language models, focusing on mechanistic interpretability and the creation of a new framework.\n- It introduces a novel dataset and task design, which is crucial for benchmarking and advancing research in this field.\n- The inclusion of a new model architecture, T Hex, is a significant contribution, and its performance evaluation across different tasks is thorough and insightful.\n- The paper is well-structured and easy to follow, with clear explanations and a logical flow of ideas.\n- The proposed framework effectively incorporates logical reasoning and memory challenges, enhancing the depth and variety of the evaluations conducted.\n\n**Weaknesses**\n- The paper lacks a thorough evaluation of the proposed framework across a broader range of tasks and architectures, which limits the understanding of its generalizability and applicability.\n- The creation of synthetic datasets raises concerns about their realism and relevance to practical scenarios, which may affect the validity of the results obtained.\n- There is a lack of detailed analysis on the impact of different hyperparameters and architectural choices, such as the number of global variables, which could influence the performance and scalability of the models.\n- The paper does not adequately discuss the limitations of the proposed framework, nor does it provide a comparative analysis with existing benchmarks or frameworks, which is essential for establishing its effectiveness.\n- The novelty of the proposed framework is questioned, with some reviewers suggesting that it builds heavily on existing frameworks without sufficient differentiation or innovation.\n- The paper contains some inaccuracies and potential oversights in its literature review and experimental design, which could undermine the credibility and reliability of the findings.\n\n**Questions**\n- Can the authors clarify the choice of using synthetic datasets and discuss the potential limitations and biases this may introduce in the evaluation results?\n- How does the proposed framework compare with existing benchmarks and frameworks in terms of task coverage and evaluation metrics?\n- What are the specific challenges and considerations when scaling up the proposed framework to larger, more complex datasets or different types of language models?\n- Could the authors provide a more detailed analysis of the impact of different hyperparameters and architectural choices on the performance of the models?\n- How does the proposed framework address the issue of generalizability, and can it be applied to real-world datasets or scenarios?\n- In light of the concerns about the novelty of the proposed framework, can the authors elaborate on the unique contributions of their work and how it advances the state-of-the-art in mechanistic interpretability research?"
    },
    "BoLqnXEdSE": {
        "gold_review": "**Summary**\nThis paper introduces a novel fairness measure named probable demographic parity, aimed at handling continuous sensitive attributes like weight or age. This measure fundamentally critiques and seeks to improve upon the deficiencies of the Generalized Demographic Parity (GDP) measure by Jiang et al., which fails to account adequately for small population segments. Unlike GDP, the proposed method employs a sampling strategy ensuring each segment has a substantial measure, controlled by the hyperparameter alpha, enhancing the fairness measurement's sensitivity to smaller groups. The approach's theoretical basis is discussed, emphasizing its ability to provide a more accurate approximation of demographic parity than existing measures. However, the paper also faces criticism for lacking in thorough experimental validation against various baselines, and gaps in theoretical coverage that could potentially limit the reader\u2019s grasp of the proposed method's reliability and scope.\n\n**Strengths**\n- The paper tackles the underexplored area of fairness considering continuous sensitive attributes, presenting an interesting extension of demographic parity (DP).\n- The authors introduce a new measure that extends DP to address both mean prediction disparity and maximum prediction disparity, offering a potential balance between these two metrics.\n- Mathematically, the concept and the formulation are robust and clearly articulated, with Theorem 1 showing that for discrete attributes, the new definition aligns with traditional DP.\n- Empirical techniques for measuring the proposed metric are employed, highlighting benefits in computational complexity.\n- The paper involves a good discussion on feasible solutions and the modifications needed for quantized sensitive attributes under specific conditions.\n\n**Weaknesses**\n- The paper fails to adequately explain or justify the choice of alpha, a parameter crucial to their proposed measure.\n- There is a significant lack of experiments demonstrating the superiority of the proposed metric over existing methods like mean prediction disparity and maximum prediction disparity.\n- Insufficient related work discussion, particularly omitting existing literature that studies metrics like equalized odds for continuous sensitive attributes, which could enhance the paper's depth.\n- The claimed advantages of the proposed metric are not empirically validated against any established baselines.\n- Presentation of the theory, particularly around the assessment of underestimation and overestimation issues (as seen in Figure 1), could be better structured for clarity.\n- Theoretical aspects such as the conditions for convergence and the validation procedure for selecting alpha remain incomplete or unclear.\n\n**Questions**\n- How do you choose the appropriate alpha for the proposed metric, and what impact does it have?\n- Can you enhance the experimental section to demonstrate that your proposed metric indeed performs better than both mean prediction disparity and maximum prediction disparity?\n- Could you discuss and compare your metric against other contemporary approaches, such as distance covariance-based metrics cited from the literature (e.g., references [1], [2])?\n- How can this metric be effectively scaled or adapted to scenarios involving multiple continuous sensitive attributes?\n- Could you explain the practical implications and limitations of your method, particularly in real-world applications where sensitive attributes vary widely?",
        "inference_review": "**Summary**\nThe paper introduces \"Probable Demographic Parity,\" a novel metric for assessing fairness in machine learning models with continuous sensitive attributes. This metric measures the maximum disparity of predictions within probable segments of the sensitive attribute, rather than using mean or maximum disparities. The approach aims to balance the strengths of existing metrics like maximum and mean disparities by considering only probable segments with a minimum probability threshold. The paper also claims to improve upon previous metrics by reducing the effect of outliers and providing a more consistent estimation error. However, the paper suffers from issues such as unclear definitions, lack of detailed theoretical backing, and inadequate experimental results, making it difficult to assess the validity and effectiveness of the proposed metric.\n\n**Strengths**\n- The proposed metric is straightforward and intuitive, aiming to reduce the effect of outliers and providing a more consistent estimation error compared to previous methods.\n- The paper is well-structured and easy to follow, providing a clear and logical flow that enhances understanding.\n- The authors have provided a good motivation for the need for a new metric and have addressed the issue of continuous sensitive attributes in machine learning.\n\n**Weaknesses**\n- The definition of probable demographic parity and the concept of probable segments are unclear and not well-defined, leading to potential confusion and misinterpretation.\n- The theoretical analysis provided is insufficient, lacking detailed proofs and clear explanations that could substantiate the claims made about the metric's properties and advantages.\n- Experimental results are limited and lack sufficient statistical significance to convincingly support the proposed metric. The results also do not convincingly show that the proposed metric outperforms existing metrics.\n- The paper could benefit from a more detailed discussion on the selection and tuning of parameters like alpha, which is critical for the application of the proposed metric.\n- The connection between probable demographic parity and traditional demographic parity is not convincingly established, which raises questions about the metric's validity and relevance in practical scenarios.\n- The paper does not sufficiently discuss related work or provide a comprehensive comparison with existing fairness metrics, which could have strengthened the context and motivation for the proposed metric.\n\n**Questions**\n- Could you clarify the definition of probable demographic parity and provide a detailed explanation of the concept of probable segments?\n- What are the specific theoretical properties that the proposed metric aims to achieve, and how are these properties supported by the provided analysis?\n- Can you provide more detailed experimental results, including statistical significance and a comparison with existing fairness metrics?\n- How is the parameter alpha selected and tuned in practical applications of the proposed metric?\n- Could you discuss the practical relevance and applicability of the proposed metric in real-world scenarios, particularly in comparison to existing metrics?\n- What are the limitations of the proposed metric, and how does it compare to other fairness metrics in terms of computational complexity and effectiveness?"
    },
    "c1QBcYLd7f": {
        "gold_review": "**Summary**\nThis paper introduces a novel model called GraDK, which leverages graph neural networks (GNN) to enhance the modeling of influence kernels in marked point processes. Using GNN, the proposed model effectively captures various interactions between marks treated as nodes within a graph. This is achieved through a convolution of kernels over the time domain and graph structure, permitting flexible modeling of inter-event-category dependence. The paper highlights the superiority of its method through extensive simulations and empirical data, indicating enhanced predictive performance over existing methods. The method's ability to model non-stationary and multi-hop interactions is validated through real-world datasets and synthetic data analyses.\n\n**Strengths**\n- The paper introduces an innovative approach integrating graph neural networks (GNNs) with kernel-based influence models, offering potentially transformative insights into point process modeling over graphs.\n- The numerical experiments presented are well-executed, demonstrating the model\u2019s effective predictive performance across both synthetic and actual datasets.\n- The paper is very well-written, facilitating clarity in the presentation of concepts and ease of comprehension for the reader.\n- The scalability of the training algorithm, which linearly scales with data size, enhances the practical applicability of the proposed model.\n- The use of localized graph filters improves the scalability and practical implementation of the model when applied to large graph structures.\n\n**Weaknesses**\n- The paper would benefit from a deeper engagement with the foundational literature, particularly concerning existing GNN and kernel-based methods. Specifically, discussions on how this approach uniquely advances over methodologies documented in references like Learning neural point processes with latent graphs, Graph neural point process for temporal interaction prediction, etc., are needed.\n- The novelty of the proposal is questionable, given the existing body of work on GNNs and point processes. The incremental nature of the technical contribution needs a clearer articulation.\n- Explanations on graph construction and the criteria for node and edge definitions are lacking detailed clarity, particularly concerning their applicability across various real-world datasets.\n- The logic behind the observed minimal improvement in likelihood when compared to powerful baselines like transformers and graph attention mechanisms is not convincingly addressed, casting doubt on the statistical significance of the results reported.\n- The evaluation framework is incomplete without robust baseline comparisons. Significant existing models and methods seem omitted from comparative analysis, which could potentially skew the perceived effectiveness of the proposed model.\n- The intensity function's potential negativity, even with the use of log-barrier methods, raises concerns about the theoretical soundness and practical safety of the model.\n\n**Questions**\n- 1. Could you elaborate on the use of the FullyNN model in your experiments as a marked point process model, specifically in relation to handling marks of each event as outlined by Omi et al., 2019?\n- 2. On page 4, concerning the orthogonality of basis functions and their decomposition using a fully-connected neural network, how is uniqueness ensured without imposing orthogonality?\n- 3. What specific types of network interactions are best modeled by this approach, and what are the inherent limitations in complex graph structures, particularly as indicated by performance anomalies observed with the increase in the number of nodes?\n- 4. In light of existing works cited (such as Fang et al., 2023; Dong et al., 2022), how does your model distinctively incorporate or advance over the concepts of adjacency matrices and heterogeneity in nodes?\n- 5. Given that your model uses a combination of conventional methods noted, could you further discuss the independent contributions and theoretical advancements your approach offers to justify its novelty and effectiveness?",
        "inference_review": "**Summary**\nThe paper introduces a novel method for modeling point processes over graphs, utilizing a graph-based influence kernel to capture the dynamics of event interactions. This kernel is constructed using graph neural networks (GNNs), which allows for capturing the influence between different types of events. The authors provide a detailed analysis of the model's performance across synthetic and real-world datasets, showing competitive results against existing baselines. However, the paper suffers from several shortcomings, including unclear notations, poor writing quality, and an incomplete exploration of related works. The method's complexity and the justification for the choice of loss function and GNN architectures remain unclear, contributing to a lack of transparency and comparability with other models.\n\n**Strengths**\n- The paper introduces a novel method for modeling point processes over graphs using graph neural networks, which allows for capturing event interactions and influences between different types of events.\n- The paper demonstrates the effectiveness of the proposed model through extensive experiments on synthetic and real-world datasets, comparing it favorably against existing baselines.\n- The method incorporates a graph-based influence kernel to capture the dynamics of event interactions, which is a significant advancement in the field of point process modeling.\n\n**Weaknesses**\n- The paper suffers from poor writing quality, with many unclear notations and complex expressions that hinder the understanding of the method.\n- The complexity of the model is not adequately justified, particularly the choice of loss function and the selection of GNN architectures, which are crucial for the model's performance.\n- There is a lack of comprehensive related work discussion, particularly concerning graph-based point process models, which could provide a clearer context for the proposed method.\n- The paper does not provide a clear explanation of the choice of graph neural networks (GNNs) over other types of neural networks and fails to discuss the scalability of the proposed method.\n- There is an absence of detailed analysis of the computational complexity and time complexity of the proposed method, which is essential for practical applications.\n- The experimental evaluation is limited in scope and does not sufficiently demonstrate the robustness and generalization capabilities of the proposed method.\n- The paper contains several typographical errors and inconsistencies that need to be addressed to improve clarity and professionalism.\n\n**Questions**\n- Could the authors clarify the choice of the loss function and the selection of GNN architectures, providing a detailed justification for these decisions?\n- Why was the GNN architecture chosen over other types of neural networks, and how does it affect the performance of the model?\n- Can the authors provide a detailed analysis of the computational complexity and time complexity of the proposed method?\n- How does the proposed method compare with other graph-based point process models in terms of scalability and performance?\n- Could the authors discuss the limitations of the current method and provide insights into potential future research directions?\n- What are the practical applications of the proposed method, and how can it be effectively used in real-world scenarios?"
    },
    "Dw6y6bEtXm": {
        "gold_review": "**Summary**\nThe paper presents a novel framework designed to generate high-resolution data from coarse-grained measurements using surrogate models that integrate physical priors. The models leverage an encode-process-decode approach, supported by a training routine that includes physics-informed losses, to ensure fidelity to underlying physical laws governing the dynamics of the system. Employing U-Net and Fourier neural network models, the proposal aims to apply super-resolution techniques to dynamically model systems described by partial differential equations (PDEs). Despite efforts towards clarity and experimental validation across various PDE contexts, the paper struggles with clear articulation of objectives, comparison with non-Fourier based methods, and the overall organization.\n\n**Strengths**\n- The paper is innovative in addressing real-world applications with relatively under-applied surrogate physics models and proposes a novel training framework that is structured in two phases for improved predictive performance.\n- The methods introduced in this work are justified through experiments over multiple PDE-governed systems, indicating the method's effectiveness in various contexts.\n- The authors have documented their training routine thoroughly, enhancing the reproducibility, and made the source code available, adding to the academic transparency.\n- The creativity in employing coarse-grained data alongside physics to achieve super-resolution, making the study relevant in fields where high-resolution data might not be readily available.\n\n**Weaknesses**\n- The paper suffers from organizational and clarity issues, making it difficult to understand the proposed methodology, particularly the definitions, the role and implementation of the transition module, and the down-sampling operator. Additionally, the paper omits explanations for choices like the use of U-Net architecture and lacks clear formulae for loss terms and metrics.\n- It seems that the relevance of predicting coarse-grained observations lacks justification since simulations in practical scenarios often involve high-resolution data.\n- Comparisons with other state-of-the-art methods are not sufficiently broad, focusing primarily on FNO-based methods without considering other contemporary neural operator methods. Also, performance in zero-shot super-resolution cases is unaddressed.\n- The results presented show inconsistencies, for instance, where baselines like PINO* achieve lower reconstruction errors, questioning the superiority of the proposed method. Practical usability and the accuracy level necessary for scientific applications also remain unexplored.\n\n**Questions**\n- Could the authors clarify what specific problems the proposed method aims to address, particularly regarding the practical necessity for coarse-grained prediction models?\n- What is the rationale behind employing the U-Net architecture for the encoder, given the availability of more recent and potentially more effective architectures like UNet++ or Transformer?\n- How does the \"hard encoding\" of \\( \\tilde{o} \\) into \\( \\hat{u}_t \\) function precisely? If it involves dense coupling between high-res and low-res solutions, how does this design decision impact the efficacy of improving high-resolution predictions from low-resolution observations?\n- Could the authors delve deeper into the impact of each term in their proposed loss function and elucidate how changes in the output resolution of \\( f_{\\theta} \\) influence computational costs and prediction accuracy in comparison to baseline methods?\n- There is a reliance on physics loss defined by a fourth-order central difference scheme and Runge-Kutta time discretization, but the paper does not discuss the range of problems where this approach is applicable. Could the authors provide insights on this aspect?\n- The function of \\( f_{\\theta} \\) and its specific role in employing higher-order finite difference techniques require further elucidation. Is there a finite difference operator embedded, or is there a special transformation applied that imitates such an operator?",
        "inference_review": "**Summary**\nThe paper introduces the Physics-Informed Coarse-grained data Learning (PICL) framework, designed to address the challenges of modeling physical systems with coarse-grained data. PICL integrates physics information through a learnable fine-grained state representation and employs a two-stage fine-tuning period to enhance model performance. The framework comprises an encoding module for generating the fine-grained state and a transition module for predicting subsequent states. The proposed method is evaluated across several PDE-governed physical systems, demonstrating improvements in predictive accuracy. However, the paper faces criticism for its lack of clarity in methodological descriptions, insufficient experimental details, and limited novelty in comparison to existing approaches.\n\n**Strengths**\n- The paper is clearly written, with well-defined problems and goals, making it easy to understand and follow.\n- The use of physics-informed learning is innovative and effectively utilizes physics loss to enhance the reconstruction ability of the encoding module and the generalization ability of the transition module.\n- The framework is well-structured, with a clear description of the physics-informed loss function, which is beneficial for understanding and replicating the methodology.\n- The authors have provided a thorough evaluation of the framework using various datasets, demonstrating its effectiveness in predicting future coarse-grained observations.\n- The approach is supported by well-conducted experiments, showing superior performance compared to other baseline models.\n\n**Weaknesses**\n- The paper lacks a detailed description of the methodology, particularly the encoding module and the transition module, which are crucial for understanding the framework's operation.\n- The experimental setup and results presentation are unclear and inadequately detailed, making it difficult for readers to assess the validity and significance of the results.\n- There is insufficient comparison with state-of-the-art methods, and the related work section is not comprehensive, lacking important references and discussions.\n- The novelty of the approach is limited as the proposed framework closely resembles existing methods, such as PINNs, and lacks sufficient differentiation or justification for its unique contributions.\n- The paper contains typographical errors and unclear notation, which can hinder comprehension and detract from the overall quality of the manuscript.\n- The computational cost associated with the proposed method is not discussed, which is an essential consideration for practical applications.\n\n**Questions**\n- Could you elaborate on how the encoding module is specifically designed to handle coarse-grained data and generate a fine-grained state representation?\n- What are the specific advantages of using physics-informed loss in the encoding module, and how does it contribute to the overall performance of the framework?\n- How does the proposed framework compare to other physics-informed learning methods in terms of performance and computational efficiency?\n- Can you provide more details about the experimental setup, including the datasets used, the evaluation metrics, and the specific comparisons made with other methods?\n- How do the authors justify the use of a physics-informed loss function in the transition module, and what are the theoretical or empirical underpinnings of this approach?\n- Could the authors discuss the computational cost associated with the proposed method and compare it to other methods to provide a clearer picture of its practical applicability?"
    },
    "f7PmO5boQ9": {
        "gold_review": "**Summary**\nThis paper introduces DynaEval, a dynamic interaction-based evaluation framework tailored for large language models (LLMs) within game-theoretical contexts. Inspired by extensive games with perfect information (EGPI), DynaEval incorporates an interaction process structured through selection, interaction, recording, and circulation. The framework is characterized by introducing fairness through anonymity and synchronous communication, and stability via independent multiple interactions. Central to its implementation are a referee and a message pool ensuring fair and stable assessments. The authors also make use of four specific game scenarios to test and compare various LLMs. While the application of game theory to LLM evaluation poses an intriguing approach, concerns are raised about the novelty and clarity of the proposed conditions and their practical contribution to the field.\n\n**Strengths**\n- The paper addresses the significant and less-explored problem of evaluating LLMs with fairness and stability guarantees, making it highly relevant to the ICLR conference.\n- The paper is well-written and easy to read, providing clear and theoretically grounded approaches.\n- Novelty is introduced by linking the interaction process of LLMs to extensive games with perfect information (EGPI), and attempting to move beyond static evaluation frameworks by emphasizing dynamic interaction scenarios.\n- The authors provide straightforward, well-executed experiments that demonstrate a gap between static and dynamic uses of LLMs, highlighting practical implications for real-world applications.\n\n**Weaknesses**\n- The technical contribution appears limited as the methods for ensuring fairness and stability are perceived as standard, with no substantial novel insights or practical implementation specifics tailored to dynamic interactions.\n- There is a lack of clarity and sufficient details on key concepts such as the referee, message pool, and task rules, which play critical roles in the evaluation framework.\n- The connection made between DynaEval and EGPI is underdeveloped and not convincingly justified. It\u2019s unclear how this theoretical framework concretely benefits the proposed evaluation methodology.\n- The paper seems to lack a strong comparative discussion of the proposed methods against existing evaluation techniques, particularly in demonstrating the superiority of dynamic over static evaluations.\n- Statistical significance issues arise, with the results presented (e.g., overlapping distributions, negligible performance differences) not convincingly supporting the claims made.\n- Elements of the paper, including crucial definitions and equations, are not explained well enough, potentially confusing readers about their purpose or relevance.\n\n**Questions**\n- How does DynaEval specifically evaluate the 'ability of interaction' beyond the interaction between LLMs, especially in terms of engaging with human users?\n- Can you provide more details or a clearer explanation of the task rules, and how they influence the fairness and stability of LLM evaluations?\n- In what ways does DynaEval manage to address the dynamic nature of LLM interactions better than static evaluation methods?\n- Could you clarify the role and operational framework of the referee in ensuring unbiased performance evaluation?\n- In the context of IDIOMS SOLITAIRE, which specific abilities are being tested? Is the capability related truly to interaction, or merely to the breadth of data exposure?\n- The source code link provided does not work. Could this be updated to allow for replication and further study of your findings?\n- Is the stability condition introduced appropriate and reliable for evaluating convergence among differing LLMs?",
        "inference_review": "**Summary**\nThe paper introduces DynaEval, a novel dynamic interaction-based LLM evaluation framework, which utilizes a message pool and an LLM-based referee to ensure fairness and stability in evaluating LLMs' performance across various tasks like Code Generation and Review, Machine Translation, and Idiom Solitaire. The framework operates by breaking down interactions into rounds, allowing for a structured evaluation process that maintains fairness and stability. Despite its innovative approach, the paper has been criticized for its lack of clarity, specifically in the definitions and methodologies used. The experimental results, while indicating the potential of DynaEval, are limited in scope and depth, lacking a comprehensive comparison with existing methods. The paper also does not sufficiently address the potential biases in the evaluation process and does not provide clear guidelines for task designers or users of the framework.\n\n**Strengths**\n- The paper introduces a novel dynamic interaction-based LLM evaluation framework, which provides a new perspective on LLM evaluation and offers an innovative approach to assess the capabilities of LLMs in dynamic real-world scenarios.\n- The framework's design is intuitive and effectively integrates the message pool and the LLM-based referee, ensuring fairness and stability in the evaluation process.\n- The experiments conducted demonstrate the potential of DynaEval in effectively evaluating the abilities of LLMs in dynamic interaction-based evaluation tasks.\n- The paper is well-written, making it accessible and easy to follow, which facilitates understanding of the complex concepts involved.\n\n**Weaknesses**\n- The paper lacks clarity in several sections, particularly in the definitions and methodologies used. For instance, the definition of the interaction process in Section 3.1 is unclear and needs further explanation.\n- The experimental results are limited in scope and depth, and the paper fails to provide a comprehensive comparison with existing methods, which undermines the robustness of the findings.\n- The paper does not adequately address potential biases in the evaluation process, which is crucial for ensuring the reliability and validity of the results.\n- There is a lack of clear guidelines for task designers or users of the framework, which could lead to confusion or misuse of the framework.\n- The paper's theoretical contributions, while innovative, are not sufficiently justified or explained, making it difficult to fully grasp the significance and implications of the research.\n\n**Questions**\n- Can you provide more detailed explanations for the definitions and methodologies used in the paper, particularly in Section 3.1?\n- How do you address potential biases in the evaluation process, and what measures are in place to ensure the reliability and validity of the results?\n- Could you provide a more comprehensive comparison with existing methods to better establish the effectiveness and novelty of DynaEval?\n- What are the specific guidelines for task designers or users of the framework, and how can they ensure proper implementation and utilization of the framework?\n- In terms of theoretical contributions, could you clarify the significance and implications of these contributions in the context of LLM evaluation?"
    },
    "GAXedKmbFZ": {
        "gold_review": "**Summary**\nThe paper introduces Disco-Bench, a new benchmark dataset focused on discourse phenomena, accommodating nine tasks. These tasks span language understanding, translation, and generation, with an offering of multiple datasets, including a diagnostic set and a large unlabeled dataset for language model pretraining. Primarily featuring Chinese (both modern and classical) and English data, the benchmark evaluates several existing models like BERT, RoBERTa, GPT-3.5, and GPT-4, showing specifics of their performance across different tasks. Although the benchmark\u2019s design and intended contributions are noteworthy, the paper faces criticism regarding the vague presentation of data, unclear copyright and ethical considerations, and insufficient methodological details which raises concerns on the experimental approaches and claims.\n\n**Strengths**\n- The paper highlights an underexplored area by focusing on benchmark datasets that cover multi-sentence and document-level phenomena, alongside traditional single sentences or pairs.\n- It introduces a large, diverse benchmark comprising various discourse-related tasks and presents results showing the limitations of both large and smaller pre-trained models.\n- The creation of a large corpus of Chinese+English text in the literary domain and the demonstration that continued pre-training on this corpus can mitigate some limitations is noteworthy.\n- It is commendable that the paper does not only integrate existing datasets but provides new datasets, specifically focusing on the literary domain, and also introduces a diagnostic test suite for assessing model performance on discourse phenomena.\n\n**Weaknesses**\n- The paper suffers from vague descriptions and lacks clarity in multiple sections including the annotation and alignment processes, how datasets were constructed, and the treatment of copyright and ethical concerns.\n- There is no clear rationale provided for the methodological choices, such as why certain datasets were chosen or created, and how they compare with existing datasets.\n- Quality assurance steps are mentioned, but the specifics such as the double annotation confirmation and the profiles of annotators are unclear.\n- The paper fails to provide a qualitative analysis to support its conclusions, particularly the effects observed in Table 5 where specific pretraining seems to impact model performance on certain tasks.\n- Some existing benchmarks like Super GLUE or LOT already cover similar tasks, and the paper does not sufficiently differentiate its benchmarks from these in terms of novelty or utility.\n\n**Questions**\n- Could the authors clarify whether smaller models encounter issues due to text length and if strategies like truncation or other mechanisms for handling long inputs were employed?\n- Why were the specific six cohesion properties chosen for the diagnostic test suite, and why are these properties important?\n- In the discussion of inter-annotator agreement scores and model performance differences, is there an explanation for the dramatic differences in performance on similar tasks noted by other studies, such as those referenced by Song et al. (2020)?\n- How was the manual alignment of chapters in the Novel Translation task performed, and does \"manually aligned\" imply that millions of alignment annotations were actually completed by the authors?\n- What portion of the performance difference noted in Table 5 between vanilla models and Disco-Bench pretrained models is attributable solely to domain or language mismatches?",
        "inference_review": "**Summary**\nThe paper introduces Disco-Bench, a benchmark designed to assess the contextual modeling abilities of language models, focusing on discourse phenomena such as cohesion and coherence. The benchmark comprises nine document-level datasets in Chinese and English, supplemented by a diagnostic test suite to gauge the extent of discourse information internalized by models. The benchmark covers a range of tasks including understanding, translation, and generation, with the datasets being constructed from literature domains. The paper further explores the impact of fine-grained pretraining on these models, indicating improvements in discourse modeling. However, concerns are raised about the novelty of the benchmark, the diversity of the datasets, and the clarity of its evaluation metrics.\n\n**Strengths**\n- The paper is well-written, making it easy to follow and understand.\n- The proposed benchmark covers a variety of tasks, including understanding, translation, and generation, which helps to evaluate models' contextual understanding.\n- The benchmark is designed to assess intra-sentence contextual properties, which is a crucial aspect in natural language processing (NLP).\n- The paper provides a comprehensive analysis of different models, including standard Transformer, pretrained models, and large language models (LLMs), which gives a good overview of model performance across various tasks.\n- The inclusion of a diagnostic test suite allows for a deeper understanding of the models' ability to internalize discourse information.\n\n**Weaknesses**\n- The novelty of the benchmark is questioned as it appears to be a collection of existing datasets with some modifications.\n- The diversity of the datasets is limited, primarily focusing on Chinese and English, which may not adequately represent the linguistic diversity of other languages.\n- The evaluation metrics used in the benchmark may not be adequate or robust enough to accurately measure the models' performance, particularly in tasks involving generation and translation.\n- There is a lack of detailed analysis on the construction of the datasets, particularly the criteria for selecting and processing the data.\n- The paper does not provide a comprehensive discussion on the limitations and potential biases of the benchmark.\n- The evaluation results are not thoroughly explained, making it difficult to interpret the significance of the findings.\n\n**Questions**\n- How was the benchmark dataset constructed, and what specific criteria were used for selecting and processing the data?\n- Can the authors provide more details on the evaluation metrics used in the benchmark and explain why these metrics were chosen?\n- What are the specific limitations and potential biases of the benchmark, and how do these affect the validity of the results?\n- Can the authors clarify the relationship between the benchmark and the Disco-Bench training dataset, and explain how the benchmark is designed to be challenging for models?\n- What are the reasons for the use of different metrics for evaluating the models, and can the authors provide a more detailed comparison of the metrics used?\n- How does the benchmark account for the diversity of linguistic structures and phenomena across different languages?"
    },
    "Gq1Zjhovjr": {
        "gold_review": "**Summary**\nThis paper introduces a novel consistency regularization method called Logit Attribution Matching (LAM) aimed at improving domain generalization. The authors reinterpret domain generalization through a causal latent decomposition model, stressing the importance of causal-invariant prediction, where predictions remain consistent despite variations in non-core factors. The paper suggests that consistency regularization may be an optimal solution for domain generalization under certain conditions, with traditional methods like probability matching, logit matching, and feature matching being special cases of this broader framework. Extensive experiments demonstrate the effectiveness of LAM, comparing its performance against existing domain generalization and data augmentation strategies. Despite these contributions, concerns were raised about the theoretical underpinnings not being sufficiently connected to the proposed method, and the novelty and practical value of the solutions were questioned by some reviewers.\n\n**Strengths**\n- The paper presents a clear writing style and the idea flow is easy to follow, making the concept of domain generalization from a causal latent decomposition perspective both interesting and novel.\n- Utilizing the Optimal DG theorem enhances understanding by summarizing existing consistency regularization methods into a general framework.\n- A thorough set of experiments conducted over multiple image datasets demonstrates the superiority of the proposed methods, especially the label-aware matching (LAM) approach, in outperforming both domain generalization and consistency regularization methods in out-of-distribution settings.\n- The theoretical backing, although in question regarding its application, highlights the significance of the causal invariant property for domain generalization.\n- A simple yet effective additional weight term over each feature unit and class label introduced shows significant improvements in handling out-of-distribution (OOD) scenarios.\n\n**Weaknesses**\n- There appears to be a lack of novel contributions, as the paper builds on extensively studied areas like consistency regularization and targeted augmentation, and fails to sufficiently differentiate or extend these concepts in a significant new direction.\n- The link between the theoretical foundations such as the Optimal DG theorem and the applied techniques like LAM is weak and not well-motivated, which could confuse the contribution significance.\n- Several assumptions, for example, those used in Theorem 1, are overly strong and not likely to hold in practical scenarios, limiting the applicability and robustness of the proposed methods.\n- The dependence on targeted augmentation (TA) is criticized for lack of algorithmic novelty and general applicability, as it might not be effective or feasible across various datasets and new domains.\n- The paper suffers from certain clarity issues due to extensive use of abbreviations and a sporadic connection of contributions in the introductory section, making it difficult to grasp the integration of ideas at first.\n\n**Questions**\n- Can the authors clarify how the Optimal DG theorem directly supports the implementation of LAM? How do these theoretical insights translate into the practical effectiveness of LAM?\n- Why was the feature matching model chosen as the base for logit attribution matching? Could probability matching or logit matching models provide better or worse outcomes?\n- Is it possible to see further clarifications on how label-aware matching (LAM) performs when faced with dataset-agnostic augmentation methods like RandAugment, CutMix, or AugMix?\n- Given the significant reliance on targeted augmentation, how can LAM be effectively applied to new domains where such specific data augmentations may not be viable?\n- How do the weights introduced in LAM (e.g., \\(w_{uy_k}\\)) determine or influence model performance and what guides their configuration during training or setup?",
        "inference_review": "**Summary**\nThe paper explores the synergy between data augmentation (DA) and consistency regularization (CR) in domain generalization, proposing a novel method called Logit Attribution Matching (LAM). This method leverages class labels to enhance the performance of DA by matching logit vectors, particularly in a causal framework where domain shifts are addressed through DA. The experiments conducted across various datasets, including ImageNet, iWildCam, and Camelyon, demonstrate the effectiveness of LAM in improving out-of-distribution (OOD) performance. The paper also includes a theoretical analysis to justify the CR-based approach to domain generalization, although some reviewers noted that the theoretical contributions could be better explained and integrated with the empirical findings.\n\n**Strengths**\n- The paper provides a thorough analysis of the combination of data augmentation and consistency regularization in the context of domain generalization, showing how these elements can improve out-of-distribution (OOD) performance.\n- It offers a novel method, Logit Attribution Matching (LAM), which is designed to leverage class labels to enhance data augmentation by matching logit vectors, showing significant improvements over baseline methods.\n- The paper is well-written and organized, making it easy to follow, and includes a detailed explanation of the methods used and the experimental setup.\n- It provides a clear and structured presentation of the problem, along with theoretical and empirical justifications for the proposed approach.\n\n**Weaknesses**\n- The paper lacks a comprehensive comparison with existing methods, particularly those that have demonstrated superior performance in previous works. This omission raises concerns about the novelty and effectiveness of the proposed method.\n- There is a noticeable lack of clarity in the presentation of theoretical contributions, particularly the causal framework and its application to the domain generalization problem. This section is also criticized for being overly technical and not well integrated with the empirical results.\n- The paper's theoretical discussion does not sufficiently address the assumptions and limitations of the causal framework, which may not be realistic or applicable in practical scenarios.\n- The experiments are limited in scope, focusing primarily on a few datasets, and do not explore a broader range of domain generalization tasks, which might have strengthened the validity of the findings.\n- There is a lack of detailed discussion on the choice of data augmentation techniques and the potential impact of different augmentation strategies on the results.\n\n**Questions**\n- Could the authors elaborate on the specific choice of data augmentation techniques used and their rationale, as well as the impact of different augmentation strategies on the results?\n- How does the proposed method compare with existing methods, especially those that have shown superior performance in previous works? What are the advantages of the proposed method over these existing methods?\n- Can the authors clarify the role and justification of the causal framework in the context of domain generalization, particularly its assumptions and limitations?\n- Why were certain datasets selected for the experiments, and how do these choices affect the generalizability of the findings?\n- Could the authors discuss the potential scalability of the proposed method to more complex and diverse domain generalization tasks, such as those involving multiple sources of domain shifts?"
    },
    "i7oU4nfKEA": {
        "gold_review": "**Summary**\nThis paper investigates the effects of multilingual pretraining on language model performance across a huge dataset covering 250 languages. The authors conducted controlled experiments using GPT2-style models, training over 10,000 models in varying settings, where they adjusted factors such as monolingual and multilingual data sizes, linguistical similarities, and model sizes. Key findings suggest that while low-resource languages benefit from the addition of multilingual data, this often negatively affects high-resource language modeling. The extent of these effects is influenced by the syntactic and, to a lesser extent, lexical similarities of the languages used. Results suggest that for certain languages and configurations, targeted monolingual models may be more effective than massively multilingual approaches. The impact of multilingual pretraining varies with model size, and the small sizes of models used (up to 45M parameters) bring into question the scalability and applicability of the findings to larger, state-of-the-art language models.\n\n**Strengths**\n- The paper provides an in-depth study of the effects of multilingual pretraining for small-ish language models, assessing a variety of factors including resource levels, syntactic/lexical/geographic similarities, and model size. This holistic approach enhances understanding of how cross-lingual transfer can benefit language models.\n- Researchers conducted extensive and controlled experiments, pre-training a massive number (over 10000) of monolingual and multilingual language models across more than 250 languages. This effort substantiates the paper\u2019s claims with concrete experimental evidence.\n- The methodology adopted, particularly the choice of tokenization approach and the metric for evaluating model performance, enables an intuitive comparison between monolingual and multilingual models. The paper clearly outlines these methods, contributing positively to its reproducibility and clarity.\n\n**Weaknesses**\n- All models studied are relatively small, capped at up to 45M parameters. This limitation is notable as larger models (in the scale of billions of parameters) are common in current research and applications, and results from small models may not generalize well to larger scales.\n- There is a contradiction or lack of support regarding the claim that \u201cmultilingual pre-training may not be beneficial to any languages involved.\u201d This is particularly perplexing given the evidence suggesting clear benefits for low-resource languages.\n- The paper's evaluation heavily relies on pretraining loss metrics, whereas inclusion of downstream task performance could provide a fuller picture of the practical effectiveness of the multilingual models.\n- Repetitiveness and possible inconsistencies in the manuscript, such as different numbers cited for the total models trained and formatting issues, suggest the need for better proofreading and editing for clarity and accuracy.\n\n**Questions**\n- Do the authors expect these results to translate to related larger-scale tasks such as machine translation, speech recognition, etc.? How might the findings align with or diverge from the current state-of-the-art models for these tasks?\n- Why was there relatively minor impact observed when selecting the most vs. the least related languages for inclusion in the multilingual training sets?\n- Could the authors clarify the apparent contradiction regarding the benefits of multilingual pre-training, especially given the positive results shown for low-resource languages?\n- There is mention of both the syntactic similarity of added languages driving results and the surprising finding that adding \"similar\" languages sometimes resulted in larger performance degradation. Could the authors discuss potential reasons for these findings and the implications for multilingual model training strategies?\n- Regarding multilingual tokenizers, is there a limitation with using a uniform vocabulary size (e.g., 32K tokens) for scenarios involving many languages with varying scripts? How might this affect model performance and fairness across languages?",
        "inference_review": "**Summary**\nThe paper examines the impact of multilingual pretraining on language models' performance across 252 languages. It introduces a novel approach by pretraining models from scratch, varying factors such as monolingual and multilingual dataset sizes, model size, and linguistic similarity of the pre-training languages. The study reveals that adding multilingual data generally benefits low-resource languages and harms high-resource ones. This effect is attributed to the limited model capacity, suggesting that multilingual data can act as a regularization mechanism for low-resource languages. The paper also discusses how linguistic similarity affects performance improvements, showing that syntactic similarity is a more significant factor than lexical similarity.\n\n**Strengths**\n- The paper is well-written, easy to follow, and effectively presents the research question and the proposed methodology.\n- The research is highly relevant to the field of multilingual language modeling, providing valuable insights into the impact of multilingual pretraining on model performance across different language resources.\n- The paper is thorough and well-documented, providing a comprehensive overview of related work and a clear description of the experimental setup, data collection, and results.\n- The findings are significant, highlighting how multilingual data can affect the performance of language models in different resource scenarios and how linguistic similarity influences these effects.\n- The paper successfully addresses the question of how different multilingual pre-training language distributions affect multilingual language model performance.\n\n**Weaknesses**\n- The paper's experimental setup is not thoroughly justified, particularly the selection of languages and the choice of dataset sizes, which could limit the generalizability of the findings.\n- There is a lack of exploration into the potential benefits of adding multilingual data to high-resource languages, despite the observation that it generally harms their performance.\n- The paper lacks a discussion on the implications of its findings for practical applications, such as text generation or translation tasks, and does not adequately explore the limitations of the study.\n- The novelty of the work is limited, as it primarily builds on existing research and does not introduce new methodologies or significantly extend the state-of-the-art.\n- The paper does not discuss the potential risks associated with the proposed approach, such as the impact on model performance in high-resource languages or the long-term effects of multilingual pretraining on model capabilities.\n\n**Questions**\n- How were the 252 languages chosen for the study, and what are the criteria for selecting languages?\n- Why were the dataset sizes selected as 1M, 10M, 100M, and 1B tokens, and how do these choices impact the results?\n- Can the authors elaborate on the benefits of adding multilingual data to high-resource languages, as suggested by the paper's findings?\n- What are the limitations of the study, and how do they affect the generalizability of the results?\n- How do the authors plan to address the potential risks associated with the proposed approach, such as the impact on model performance in high-resource languages?\n- Could the authors provide more details on the potential applications and implications of the findings for practical scenarios, such as text generation or translation tasks?"
    },
    "iGHPVbttMs": {
        "gold_review": "**Summary**\nThe paper explores the relationship between cyclical behavior in game-theoretic learning algorithms and the support of mixed-strategy Nash equilibria (MSNE). It introduces a novel graph search learning method called GraphNES aimed at identifying Nash equilibria through self-play in non-cooperative games. This method either concludes at a pure Nash equilibrium or identifies cycles indicative of the support of a MSNE. The paper's empirical studies in games like Connect4 and Naruto Mobile demonstrate that GraphNES can outperform conventional methods requiring larger strategic datasets. However, reviewers have critiqued the clarity and accessibility of the paper, indicating that its theoretical contributions and the novelty of the results might be overshadowed by presentation issues and lack of a thorough literature review.\n\n**Strengths**\n- The paper provides valuable insights into the behavior of empirical game theoretic algorithms and uses these insights to advance the state of the art.\n- The authors present a historical context to strategically analyze phenomena observed in game theory, successfully tying earlier observations of cyclic patterns to formal predictions like the Poincar\u00e9 recurrence theorem.\n- The detection of cycling within Path-Response Strategy Oscillations (PRSO) dynamics is presented as a significant method for uncovering the support strategies of a Mixed Nash Equilibrium (MSNE), suggesting its utility not just as a diagnostic tool but also for understanding foundational game structures.\n- The manuscript addresses an important problem with self-play in gaming frameworks that are not strictly transitive, offering solutions to reduce the number of necessary strategies in training through minimized opponent population, as observed in the GraphNES which outperforms traditional methods like NeuPL.\n- The paper contains rigorous results and interesting experiments that showcase its practical applications in specific games, enhancing understanding of their theoretical implications.\n- Some sections of the paper, such as the introduction, are clearly written, providing a solid grasp of the context and the contributions claimed.\n\n**Weaknesses**\n- The paper is generally difficult to read due to either formatting issues or poor clarity in the writing; specific examples include multiple proofs under a single theorem without clear delineation and frequent typographical errors.\n- The novelty of the research findings is questionable as similar themes have been extensively discussed in prior works, necessitating a more thorough investigation and citation of related literature to solidify the paper's contribution.\n- Computational complexity concerns raised by the claims of feasible cycle detection within PRSO dynamics are not sufficiently addressed, leaving questions about alignment with conventional complexity issues surrounding Nash Equilibria.\n- The scope of the experiments and environmental choices for testing the algorithms are limited or inappropriately selected, which could affect the generalizability and applicability of the results.\n- Visual aids such as algorithmic flowcharts are missing, which could help clarify complex processes discussed in the text.\n- Some sections lack rigorous definitions and thorough explanations (e.g., cyclical strategies, the class of games applicable to the main theorem), which are critical for the understanding and validation of the claimed results.\n\n**Questions**\n- Can the authors clarify the intended purpose of the experiments and the concrete takeaways, especially in relation to the practical applications of the findings?\n- What specific definitions and formal parameters can be provided for key concepts such as cyclical strategies, complete cyclical strategies, and the class of games the main theorem applies to?\n- How does the paper align its claims of computational feasibility with the known PPAD-hardness of finding Nash Equilibria through conventional methods?\n- In light of the criticisms regarding the novelty of the results, can the authors clarify the distinctions and contributions of their findings compared to existing literature, particularly through an expanded related work section?\n- Could the authors provide additional visual representations of the algorithms to aid in understanding, as well as a discussion on the rationale behind the selection of specific environments for the experimental validations?",
        "inference_review": "**Summary**\nThe paper explores the notion of cyclical strategies in non-cooperative games and their equivalence to the support set of a mixed-strategy Nash Equilibrium (MSNE). It introduces a novel approach utilizing a directed graph search to identify these cyclical strategies, which are seen as integral to finding MSNE. The method is supported by a theoretical analysis that links cyclical strategies to MSNE, although empirical validations are limited to simple games like Connect4 and Naruto Mobile. The study suggests that this graph-based search could potentially be more efficient than traditional methods like Policy Space Response Oracles (PSRO) in finding MSNE, but the experimental results are not convincing, and the paper lacks a broader evaluation across diverse games.\n\n**Strengths**\n- The paper introduces a novel perspective on finding Nash Equilibria by considering cyclical strategies as orderly sequences rather than chaotic anomalies.\n- It establishes a theoretical equivalency between a complete set of cyclical strategies and the support set of a Mixed Strategy Nash Equilibrium (MSNE).\n- The paper presents a new graph-based learning representation for self-play, which is theoretically grounded and could potentially be more efficient than existing methods like Policy Space Response Oracles (PSRO).\n- The study demonstrates improved self-play efficiency in discovering both Pure Strategy Nash Equilibrium (PSNE) and MSNE in noncooperative games such as Connect4 and Naruto Mobile.\n\n**Weaknesses**\n- The empirical validation of the proposed method is limited to very simple games, which does not convincingly demonstrate the method's effectiveness across more complex or realistic game scenarios.\n- The paper lacks a comprehensive comparative analysis with other existing methods, particularly PSRO, to adequately demonstrate the superiority or effectiveness of the new method.\n- The theoretical claims made about the equivalency of cyclical strategies and the support set of MSNE are not universally convincing, especially in the context of games with multiple Nash Equilibria.\n- There is a significant lack of detailed experimental results and a thorough evaluation of the proposed method, including a lack of discussion on the computational efficiency and practical implementation aspects.\n- The paper does not address potential issues like the computational cost associated with maintaining and querying the vector database of all strategies, which could be a significant limitation in practical applications.\n\n**Questions**\n- Could you elaborate on how the proposed method compares in terms of computational efficiency to existing methods like PSRO, particularly in more complex games?\n- How does the proposed method handle games with multiple Nash Equilibria, and what are the implications for the theoretical claims made in the paper?\n- In practical terms, how does the vector database of all strategies impact the computational resources and query efficiency of the proposed method?\n- Given the limited empirical validation, how do you plan to expand the experimental scope to include more complex or realistic game scenarios?\n- Could you provide more details on the implementation of the proposed method, including the computational cost and scalability issues associated with the vector database storage and query?"
    },
    "ipWSxcmgsx": {
        "gold_review": "**Summary**\nThe paper introduces NormIntSleep, a two-stage framework for interpretable sleep-stage classification using deep neural networks (DNNs) and linear models. The first stage involves training a DNN to classify sleep stages, followed by a linear model mapping the DNN's latent representations to a clinically interpretable feature space. These features are then input into a glass-box model for final sleep stage prediction. The proposed framework not only matches the performance of non-interpretable models but is also grounded in clinically established knowledge, making it attractive for medical applications. The paper also introduces a new metric, AlignmentDT, to measure the consistency of the glass-box model's decisions with domain knowledge. However, the paper faces criticism regarding the clarity of model comparisons, experiment descriptions, and the generalizability of its methods to other domains.\n\n**Strengths**\n- The paper addresses a critical area in machine learning for healthcare, focusing on interpretability in sleep staging algorithms, which is essential for clinical applications and healthcare.\n- It is well-written and structured for ease of understanding, highlighting significant efforts in explaining the implementation and motivation behind the study.\n- Extensive experiments were conducted on two different datasets, showcasing a variety of baselines which enriches the empirical evaluation and supports robust comparative analysis.\n- The introduction of the Interpretable Decision Tree and decision-making process explained through practical examples (e.g., Figure 2 in section 5.1) effectively bridge the gap between methodological advances and practical, clinical needs.\n- The relevance and potential impact of the work are clear, given the emphasis on explainability and the healthcare context, which could aid in broader acceptance and trust of machine learning models in medical settings.\n\n**Weaknesses**\n- The paper struggles with clarity in several sections; the explanations of methods and results are sometimes confusing, and important details are either missing or not sufficiently explained (e.g., lack of detail on hypermetric tuning, definitions of key terms and metrics).\n- Concerns about the interpretability of the proposed models, particularly when projections diverge from actual features, which could mislead the interpretability of the model\u2019s output.\n- The reproducibility of results is questionable as the code for the experiments is not provided, and there seems to be a lack of standard error reporting in the results, which diminishes the scientific rigor.\n- The paper's technical contributions appear limited, with some methodologies and metrics poorly generalized beyond specific setups (e.g., alignment metrics tailored only for decision trees).\n- The generalizability of the approach to other domains is questionable, and comparisons to other state-of-the-art methods in interpretability are insufficiently explored or justified.\n\n**Questions**\n- Can you clarify the process and criteria used for the optimization of model hyperparameters? Were techniques like cross-validation employed?\n- For the alignment metric, please provide a detailed explanation of its calculation. Was there any manual verification by clinicians, and was there a consensus among multiple clinicians?\n- Could you discuss how the cross-entropy loss for the DNN is combined with the regression loss during the pre-training stage? Is it a simple average, or is there another method used?\n- In regards to the experiments and interpretations from NormIntSleep, can you provide further justification or evidence that supports the meaningfulness of the interpretations generated?\n- Given the concerns about model interpretability when projections diverge from actual features, can you provide further clarifications or modifications to the methodology that might address these concerns?\n- Please consider adding more details about the hypnogram used in the study and discuss the utility limitations of the proposed metrics which seem tailored mainly for decision trees.",
        "inference_review": "**Summary**\nThe paper presents a novel approach called NormIntSleep that integrates interpretable features with neural network embeddings for sleep stage classification, aiming to enhance the interpretability of deep learning models in clinical applications. It introduces a new metric, \\(Alignment_{DT}\\), to evaluate the alignment between the decision tree and clinical domain knowledge. The proposed method combines features like kurtosis, skewness, variance, and mean with deep neural network embeddings, demonstrating a performance comparable to state-of-the-art methods while offering more interpretable results. The approach is validated using two public datasets, and the paper includes ablation studies and a detailed explanation of the methodological choices.\n\n**Strengths**\n- The paper introduces a novel approach that integrates interpretable features with neural network embeddings to enhance the interpretability of deep learning models in clinical applications, specifically in sleep stage classification.\n- The proposed method demonstrates performance comparable to state-of-the-art methods, highlighting its effectiveness.\n- The use of a new metric, \\(Alignment_{DT}\\), for quantifying the alignment between the decision tree and clinical domain knowledge is a significant contribution to the field.\n- The paper includes ablation studies and detailed explanations of methodological choices, which aids in understanding the rationale and impact of different design decisions.\n- The authors provide a comprehensive evaluation of the proposed method using two public sleep classification datasets, benchmarking against state-of-the-art interpretable and deep learning methods.\n- The manuscript is well-structured, making it easy to follow, and the code is available, allowing for reproducibility and further research by the community.\n\n**Weaknesses**\n- The paper does not adequately discuss how the proposed method can be generalized beyond the specific task of sleep stage classification, which limits its applicability to other domains.\n- There is a lack of clear and detailed explanation of the feature engineering process, including the rationale behind the selection and combination of features.\n- The paper does not provide sufficient evidence to support the claim that the proposed method is more interpretable than existing approaches, as the interpretability evaluation is not robustly justified.\n- The decision to use a linear projection layer as the core of the method is not convincingly motivated, and the paper lacks a comparative analysis of different projection layers (e.g., linear vs. non-linear).\n- The paper has several typographical errors and inconsistencies in notation, which can confuse readers and detract from the overall quality of the presentation.\n\n**Questions**\n- Can the authors provide more details on how the proposed method can be generalized to other domains beyond sleep stage classification?\n- How was the feature engineering process determined, and what were the specific considerations for selecting and combining features?\n- What is the rationale behind the use of a linear projection layer as the core of the method, and how does this choice impact the interpretability and performance of the proposed method?\n- Could the authors elaborate on the interpretability evaluation and provide more robust justification for the claim that the proposed method is more interpretable than existing approaches?\n- What are the specific steps involved in using the proposed method for clinical decision support systems, and how does the method ensure compliance with clinical guidelines and domain expertise?\n- How do the authors address the potential biases and errors introduced by the use of decision trees in the proposed method, particularly in the context of clinical applications where precision is critical?"
    },
    "kxebDHZ7b7": {
        "gold_review": "**Summary**\nThe paper introduces a novel optimization algorithm named Trust Region Aware Minimization (TRAM), which aims to integrate the benefits of Sharpness-Aware Minimization (SAM) with Trust Region methods. TRAM is designed to optimize for flat minima while enforcing constraints in the representation space to maintain smoothness and prevent significant deviations from pre-trained models. This could potentially enhance the transferability and generalization of models in fine-tuning scenarios. The proposed approach is evaluated through experiments on language and vision tasks, showcasing improvements over existing methods like SAM and its variants.\n\n**Strengths**\n- The paper effectively summarizes existing approaches and illustrates how the proposed method builds upon them.\n- The combination of SAM and Trust Region methods is well-motivated, interesting, and intuitive.\n- Detailed and comprehensive experimental settings are provided, with extensive experiments conducted on multiple NLP tasks demonstrating the effectiveness of the proposed method.\n- The paper is clearly written, making it easy to follow, and contributes interesting perspectives on fine-tuning techniques in NLP, which is a critical area in model training.\n- Integrates the proposed method with Fisher-SAM to reduce the count of forward-propagation when implemented to the same count as in vanilla SAM.\n- Empirical validations reflect the method's transfer capability in foundational models and large-scale NLP datasets.\n\n**Weaknesses**\n- The paper lacks theoretical motivation for unifying SAM and Trust Region methods and fails to provide a clear distinction between these methods' applications in the proposed approach.\n- Some results show high variance across runs, suggesting the need for additional runs to better characterize performance.\n- The core idea of adaptively changing the neighborhood radius based on certain distance measures does not align well with the established ideas of Trust Region Regularization, leading to unclear methodology and impact.\n- It's unclear why using such a distance measure for neighborhood radius could instill 'trust', and there are missing clarifications on what 'trust' indicates in the proposed method.\n- Equations and some methodological concepts (like in Figures and Tables) are not clearly defined or explained, undermining the comprehension and robustness of the findings.\n- No computational/memory complexity analysis is provided, which is crucial for understanding the practical applicability of the method.\n- Generalization to modalities other than text, such as images, is not demonstrated, raising questions about the method's versatility.\n\n**Questions**\n- Given the paper\u2019s reliance on SAM-like updates, can you provide experiments or evidence that benchmark the new method against the original SAM on tasks where SAM was previously successful, to verify the comparative effectiveness?\n- Is ASAM-type of updates really necessary, or would a SAM version of the proposed method (TRAM) perform similarly?\n- How crucial is having a pre-trained model for TRAM to function effectively, especially considering different stages of model training (beginning vs. end)?\n- Could you clarify the interpretation of the slopes in Figure 1 and the methodological significance of the statistical absence for other TRAM variants in Table 5?\n- How well does TRAM transfer to other modalities like images, and what guidelines can be provided for selecting hyper-parameters for out-of-distribution generalization?\n- Could you discuss why forward KL divergence was chosen for your analysis over other forms like reverse KL or Renyi divergence, and the role of the noise variable in your equations?\n- Why was only accuracy considered in Table 4, and how does this reflect on the dataset's balance?",
        "inference_review": "**Summary**\nThe paper introduces Trust Region Aware Minimization (TRAM), a novel fine-tuning algorithm designed to optimize for both flat minima and smooth, informative representations without forgetting pre-trained structures. TRAM integrates sharpness-aware minimization and trust region optimization, which aims to address the challenge of forgetting task-agnostic representations during fine-tuning. The authors evaluate TRAM on cross-domain language modeling and cross-lingual transfer tasks, demonstrating its effectiveness in improving generalization to out-of-domain data. Despite the reported improvements, concerns were raised about the novelty of combining trust region methods with SAM, as well as the choice of baselines and metrics, and the clarity of the experimental setup and results presentation.\n\n**Strengths**\n- The paper is well-organized, clearly written, and easy to follow, making it accessible to a broad audience.\n- The authors provide a clear explanation of the motivation behind the work, which enhances the paper's readability and comprehension.\n- The experimental design is robust, with a comprehensive set of experiments that cover multiple domains and tasks, and the results are well-presented, showing consistent improvements over baselines.\n- The paper introduces a novel method by combining sharpness-aware minimization and trust region optimization, which could be beneficial for future research in this area.\n\n**Weaknesses**\n- The novelty of combining trust region methods with sharpness-aware minimization (SAM) is questionable, as similar approaches have been explored in prior works, and the paper does not sufficiently distinguish its contributions from these existing methods.\n- The choice of baselines and metrics for evaluation is limited, which could affect the robustness and reliability of the experimental results.\n- The experimental setup is not fully transparent, particularly regarding the details of the tasks used, the models employed, and the hyperparameters tuned, which could impact the reproducibility and credibility of the findings.\n- The paper could benefit from additional analysis, such as a deeper exploration of the trade-off between in-domain performance and out-of-domain performance, to better understand the implications of the proposed method.\n- Some of the figures and tables in the paper are difficult to read or interpret, which could hinder the comprehension of the results.\n\n**Questions**\n- Can the authors provide more detailed explanations and justifications for their methodological choices, particularly regarding the selection of baselines and evaluation metrics?\n- How do the authors ensure the reproducibility of their results, and what steps are taken to verify the reliability of their findings?\n- What is the rationale behind using specific metrics for evaluation, and how do these metrics align with the objectives of the proposed method?\n- Could the authors elaborate on the potential limitations of their method, particularly in scenarios where there might be conflicting objectives between in-domain performance and out-of-domain performance?\n- Is there a possibility of extending the experiments to include additional tasks or models to further validate the effectiveness and generalizability of the proposed method?"
    },
    "LixtB4TYY2": {
        "gold_review": "**Summary**\nThe paper presents an evaluation of vision-language instruction-tuning datasets using a novel \"tune-cross-evaluation\" paradigm, where models are tuned on one dataset and evaluated on others. The evaluation introduces the \"Meta Quality\" (MQ), \"Dataset Quality\" (DQ), and \"Sample Quality\" (SQ) metrics, which assess various aspects of dataset and sample efficacy. The findings, derived from these metrics, informed the construction of a superior dataset from high-quality samples across the existing sets. This work is poised to impact the field by providing methods to assess and enhance the utility of datasets in the generative multimodal modeling sphere.\n\n**Strengths**\n- The paper successfully constructs several concurrent vision-language instruction tuning (VLIT) datasets, allowing for an in-depth comparative evaluation.\n- Introduces an innovative evaluation metric that demonstrates potential as an efficient data selection strategy by proving training models with half of the selected data can still achieve comparative results to using complete datasets.\n- The proposed method's motivation is highly relevant and intriguing, promising enhancements in current vision language model (VLM) research by considering both sample-wise and dataset-level aspects.\n- The entire methodology is presented in a clear and straightforward manner.\n- The idea of formulating a novel evaluation strategy specifically designed for VLIT datasets is well-motivated and can significantly aid in assessing the quality of emerging VLIT datasets.\n\n**Weaknesses**\n- The evaluation of whether the proposed metric itself is effective remains indirect and somewhat nebulous, making it difficult to quantify precisely how well the metrics work.\n- The 'Meta Quality' score still relies on traditional and potentially outdated statistical metrics like BLEU and METEOR, raising concerns about their relevance and effectiveness in the new LLM/LVLM era.\n- The empirical evidence and experiments provided are somewhat lacking in demonstrating that selected data subsets indeed improve overall performance.\n- It is unclear whether the methodology and the selected dataset using QFormer metric can be generalized across different frameworks, such as LLaVA.\n- Relying on VLIT datasets where most ground-truth responses are generated by models like ChatGPT/GPT4 without manual verification, poses a challenge due to potential inaccuracies and biases in these datasets.\n- The experimental design might neglect aspects of model capability when it excludes specific tuning datasets from the evaluation.\n- Equation modifications and settings in the evaluation method may dismiss challenging yet important samples while also including some biased or unchallenged results.\n\n**Questions**\n- Could you elaborate on how direct evaluations of your proposed evaluation metrics could be performed to establish clearer validation?\n- Given your reliance on BLEU and METEOR, how do you justify their continued use in the context of modern LLMs and what modifications (if any) might better adapt them to your needs?\n- Can you provide a comparison of performance improvements when utilizing the entire dataset versus selective high-quality subsets identified by your metric?\n- How generalizable is your proposed metric across various models and frameworks beyond QFormer and LLaVA?\n- In consideration of the quality reliability of existing VLIT datasets, how can you ensure they are suitable for use as high-quality evaluation datasets?\n- Could you offer empirical comparisons between the traditional ChatGPT-based evaluation metrics and your newly proposed methods, especially addressing aspects of accuracy and human subjectivity reduction?",
        "inference_review": "**Summary**\nThe paper introduces a novel approach to evaluating Vision-Language Instruction-Tuning (VLIT) datasets by proposing a tune-cross-evaluation paradigm. This paradigm involves training models on one dataset and evaluating them on others, allowing for a comprehensive analysis of the dataset's capabilities and quality. The paper further defines metrics such as Meta Quality (MQ), Dataset Quality (DQ), and Sample Quality (SQ) to quantify these aspects. A new dataset, REVO-LION, is constructed using the proposed evaluation paradigm and is claimed to enhance model performance compared to simply merging existing datasets. Despite its innovative approach, the paper faces criticism for its limited novelty, unclear explanations, and lack of thorough empirical validation.\n\n**Strengths**\n- The paper introduces an innovative evaluation paradigm for Vision-Language Instruction-Tuning (VLIT) datasets, employing a tune-cross-evaluation methodology that trains on one dataset and evaluates on others to assess the datasets' capabilities comprehensively.\n- The paper defines new metrics such as Meta Quality (MQ), Dataset Quality (DQ), and Sample Quality (SQ) to quantify the comprehensiveness of each dataset and sample, which are considered original contributions to the field.\n- It includes a thorough review of related work and conducts extensive experiments to validate the effectiveness of the proposed evaluation paradigm.\n- The authors have released a new dataset, REVO-LION, which is designed to enhance model performance, and includes an evaluation set that can serve as a benchmark for future research in the field.\n- The paper is well-organized, easy to follow, and provides a clear motivation for the research, contributing to a better understanding of VLIT datasets and their evaluation.\n\n**Weaknesses**\n- The paper's novelty is somewhat limited as the evaluation paradigm and metrics seem to be derived from existing methods, with the primary contribution being the application of these to the field of VLIT.\n- The paper lacks a detailed explanation of the proposed evaluation paradigm and the rationale behind the choices made in the experiments, such as the selection of specific datasets and the justification for using BLEU as a metric.\n- The evaluation section is unclear and lacks empirical evidence to support the claims made about the effectiveness of the proposed evaluation paradigm.\n- The paper does not sufficiently address the limitations of the proposed approach and does not provide a comprehensive discussion of the implications of using the new dataset and evaluation paradigm.\n- The organization and structure of the paper could be improved for better clarity and flow, particularly in the presentation of related work and experimental results.\n- There is a lack of diversity in the datasets used for evaluation, which may not adequately represent the complexity and variability of real-world applications.\n\n**Questions**\n- How does the proposed evaluation paradigm differ from existing approaches, and what specific advantages does it offer in terms of comprehensiveness and accuracy?\n- Could the authors provide more details on the selection of datasets for evaluation and the specific reasons behind choosing BLEU as a metric?\n- How do the authors address the limitations of the proposed approach, and what implications does the use of the new dataset and evaluation paradigm have for the broader field of VLIT?\n- Could the authors clarify the motivation behind using the proposed evaluation paradigm and provide empirical evidence to support its effectiveness?\n- In light of the criticism regarding the novelty of the approach, can the authors provide a more detailed explanation of how their work contributes uniquely to the field of VLIT?\n- Could the authors discuss the potential issues or limitations of the proposed evaluation paradigm and provide suggestions for future work to address these challenges?"
    },
    "MCNqgUFTHI": {
        "gold_review": "**Summary**\nThe paper introduces the Plug-and-Play Dialogue Policy Planner (PPDPP), designed for enhancing proactive dialogues within large language models (LLMs). PPDPP integrates both supervised fine-tuning and reinforcement learning to adapt LLMs to varied dialogue scenarios effectively. The proposed system utilizes a plug-in mechanism that allows easy adaptability and showcases its superiority over existing models in multiple proactive dialogue domains like negotiation, emotional support, and tutoring. Evaluation through empirical experiments on three datasets demonstrates promising results in automatic and human evaluations, highlighting the system's efficient transferability. The approach notably helps LLMs transition from passive instruction-following to actively steering conversations in goal-oriented dialogues.\n\n**Strengths**\n- The paper introduces an innovative plug-and-play dialogue policy planner using Large Language Models (LLMs) for proactive learning, which showcases flexible adaptability across different dialogue domains.\n- Empirical results across three datasets demonstrate commendable outcomes in both automatic and human evaluations, indicating good transfer capabilities.\n- The integration of the LLM as a reward function for reinforcement learning (RL)-based dialogue planning provides a novel approach to dynamic prompt selection and adaptability.\n- The study combines supervised fine-tuning with online RL for training the dialogue policy ranker, optimizing the dialogue action prediction and enhancing overall system performance.\n\n**Weaknesses**\n- The dialogue LLM operates within a restricted action/prompt space, potentially limiting its adaptability and application across varying dialogue domains.\n- The distinctiveness of the approach from other Reinforcement Learning from AI Feedback (RLAIF) methodologies appears minimal, primarily centering around mapping the LLM\u2019s text output to scalar rewards, raising concerns about the uniqueness and revolutionary nature of the proposed system.\n- The need for individual training of dialog policies for each domain restricts the system's generality and scalability.\n- The proposed system appears somewhat improvised as the policy planner (PPDPP) is segregated from the dialogue LLM and relies heavily on pre-defined prompts rather than generating new, context-specific prompts dynamically.\n\n**Questions**\n- Could you explain the negative relative success rate noted in Figure 2 of the study?\n- How is the reward LLM utilized during the real-time inference within each dialogue turn, particularly relating to the decision-making process?\n- Can you detail the process and rationale behind the conversion of reward LLM\u2019s textual output into scalar reward values and how these integrate into the dialogue policy planning during individual dialogue interactions?\n- The supervised fine-tuning applied to the PPDPP: could you elaborate more on this process, its aims, and benefits?\n- In Equation 6, you mention sampling goal-oriented AI feedback multiple times; does this method observe a significant variance in the rewards provided by the LLM, and if so, what strategies are employed to mitigate this variance?",
        "inference_review": "**Summary**\nThe paper introduces a Plug-and-Play Dialogue Policy Planner (PPDPP) aimed at enhancing proactive dialogue systems using Large Language Models (LLMs). PPDPP leverages a novel training framework that combines supervised fine-tuning and reinforcement learning from goal-oriented AI feedback to optimize dialogue policy planning. This approach is evaluated across three different proactive dialogue applications, demonstrating superior performance over existing methods. The framework includes the use of LLMs as user simulators and reward models, offering a novel interactive evaluation protocol for assessing the effectiveness of dialogue systems. Despite its promising results, the paper faces criticism for unclear presentation, insufficient technical contributions, and the limited scope of experimental evaluations.\n\n**Strengths**\n- The proposed Plug-and-Play Dialogue Policy Planner (PPDPP) is a novel and innovative approach that integrates supervised fine-tuning and reinforcement learning to optimize dialogue policy planning, showing significant improvements over existing methods.\n- The paper is well-structured and easy to follow, making it accessible to readers.\n- PPDPP introduces a new training framework that allows for the tuning of a language model plug-in, enhancing the adaptability of the system to different dialogue applications.\n- The use of LLMs as user simulators and reward models is highlighted as a significant technical contribution, offering a novel interactive evaluation protocol that assesses the effectiveness of dialogue systems.\n\n**Weaknesses**\n- The paper suffers from clarity issues, particularly in the introduction, which lacks a clear explanation of the problem and the proposed solution, making it difficult for readers to understand the context and significance of the research.\n- The technical contributions of the paper are perceived as incremental, mainly involving the application of existing methods to dialogue systems without substantial innovation.\n- The experimental evaluation is limited in scope and does not adequately cover a broad range of dialogue applications, raising concerns about the generalizability of the results.\n- There is a lack of ablation studies and discussion on the impact of different components of the proposed framework, such as the role of LLMs as user simulators and reward models.\n- The paper does not sufficiently discuss the ethical implications of using LLMs in dialogue systems, particularly in scenarios involving sensitive or critical decisions.\n\n**Questions**\n- Can you provide a clearer explanation of the problem addressed by PPDPP and how the proposed solution aims to address it?\n- How do the technical contributions of this paper differentiate from existing methods, and what innovative aspects do they bring to the field of dialogue systems?\n- What are the specific dialogue applications used in the experimental evaluation, and can you explain the rationale behind selecting these particular applications?\n- Could you elaborate on the design choices made in the PPDPP framework, particularly the roles of LLMs as user simulators and reward models, and their impact on the system's performance?\n- In light of the ethical concerns raised by the use of LLMs in dialogue systems, what measures do you propose to ensure the responsible deployment of these systems in real-world scenarios?"
    },
    "OJoMzslBIa": {
        "gold_review": "**Summary**\nThe paper under review proposes a novel reweighting scheme in the context of Out-of-Distribution (OOD) detection, inspired by supervised contrastive learning to better manage the inter-class distance and intra-class variance. Named ReweightOOD, this method dynamically adjusts weights for hard positives and negatives based on similarity scores to enhance OOD detection efficacy. The methodology leverages contrastive optimization to create an OOD-friendly embedding space, with experiments conducted on benchmark datasets such as CIFAR100 and ImageNet100 showing performance gains. While the approach counters the common issue of class overlap in traditional distance-based OOD detections by enforcing minimum enclosing spheres and higher inter-class separations, there are concerns about its novelty, experimental comprehensiveness, and results presentation clarity.\n\n**Strengths**\n- The motivation behind the study is clear, and the presentation throughout the paper is coherent and easy to follow.\n- The proposed method, which includes dynamic adjustment of weights for positives and negatives based on the similarity score, is novel and straightforward.\n- Empirical evidence is provided to demonstrate the effectiveness of the method, highlighted by performance gains on CIFAR10/100 and ImageNet100 as well as improved metrics like MES and inter-class dispersion.\n- The paper addresses a crucial issue, enhancing the safety and reliability of Out-of-Distribution (OOD) detection in neural networks.\n- The method's simplicity contributes to its practicality and ease in implementation, particularly in integrating reweighting with contrastive optimization.\n\n**Weaknesses**\n- The novelty of the proposed method is somewhat limited, as the concept of hard sample mining and weighting has been extensively explored in fields like deep metric learning.\n- The method's performance comparison is restricted primarily to CIFAR100 and ImageNet100, lacking broader validation on more diverse datasets such as ImageNet-1K.\n- Despite impressive claims, the actual improvement over state-of-the-art methods is not significant, particularly when compared to recent OOD detection baselines like ReAct and ASH.\n- Detailed comparisons and additional baseline evaluations (e.g., CIDER, ASH, GradNorm) are missing, which could provide a clearer perspective on the method's relative performance.\n- Some figures and tables (like Figure 5 and Table 2) are criticized for their design and content, which could be improved for clarity and effectiveness.\n- The paper is missing comprehensive ablation studies on effects of parameters changes, additional backbones or datasets variations, and experiments demonstrating scalability concerning category numbers.\n\n**Questions**\n- Can the authors clarify the differences between their work and prior studies such as CurricularFace and AdaFace in terms of hard samples re-weighting?\n- Why is there only one cluster depicted in Figure 5(b), and can the authors provide feature visualizations for comparative models like SupCon or CIDER?\n- Are results from other methods on ImageNet100 besides SupCon available for comparison? If not, why were these not included in the study?\n- What is the rationale behind the specific settings of the hyperparameters in the linear transformation layers, particularly for different datasets or neural network architectures?\n- Could the article benefit from exploring learnable temperatures or other methods to enhance inter-class separation, and how might these compare to the current instance weighting approach?\n- How does the proposed method perform when adapted to different numbers of classes or when applied to transformer-based architectures?",
        "inference_review": "**Summary**\nThe paper introduces a novel method called ReweightOOD, which aims to improve out-of-distribution (OOD) detection in neural networks by optimizing the contrastive loss function through a reweighting mechanism. This method focuses on enhancing the separation between in-distribution (ID) and OOD samples in the embedding space by maximizing inter-class dispersion and minimizing the Minimum Enclosing Sphere (MES) for each class. The paper presents experiments conducted on various datasets, comparing ReweightOOD with existing methods and demonstrating its effectiveness. The approach leverages the concept of similarity optimization, prioritizing the optimization of less-optimized contrasting pairs and assigning lower importance to already well-optimized contrasting pairs. This innovative reweighting scheme is evaluated through empirical experiments, showing significant improvements in OOD detection.\n\n**Strengths**\n- The paper is clearly written, easy to follow, and well-organized, which facilitates comprehension and engagement with the content.\n- The methodological approach is sound, well-motivated, and grounded in a reasonable theoretical foundation, providing a solid basis for the proposed techniques.\n- The paper addresses a significant and challenging problem in the field of OOD detection, which is crucial for improving the reliability and trustworthiness of machine learning models.\n- The experimental setup is robust, including extensive ablation studies and thorough evaluations using various datasets and metrics, which helps to validate the effectiveness and generalizability of the proposed method.\n- The paper provides a comprehensive review of related works and effectively situates the proposed method within the existing literature, demonstrating a good understanding of the current state-of-the-art.\n\n**Weaknesses**\n- The novelty of the proposed method is somewhat limited, as the approach primarily involves reweighting the loss function, which has been explored in prior works. The specific application to OOD detection, while relevant, may not constitute a groundbreaking innovation.\n- The paper could benefit from a more detailed explanation of the chosen similarity metric, particularly how it relates to the cosine similarity used in standard contrastive learning frameworks. This would help in understanding the rationale behind the chosen metric and its implications for the method's performance.\n- The experimental setup lacks a clear comparison with recent and relevant works, particularly those that also address OOD detection using contrastive learning. This omission weakens the paper's ability to demonstrate its superiority over existing methods.\n- The paper does not provide sufficient details on the implementation of the proposed method, such as the specific hyperparameters used or how the method is integrated into existing contrastive learning frameworks. This lack of clarity could hinder reproducibility and practical application of the proposed method.\n- There are concerns about the generalization capabilities of the proposed method across different datasets and network architectures, as the experiments primarily focus on a specific scenario with a ResNet-18 architecture and CIFAR-100 dataset.\n\n**Questions**\n- Can the authors clarify the choice of the similarity metric used in the proposed method and explain how it aligns with the cosine similarity commonly used in contrastive learning?\n- How does the proposed method compare with other recent works that also employ contrastive learning for OOD detection? Could the authors provide a more detailed comparative analysis to establish the relative strengths and weaknesses of their approach?\n- What specific hyperparameters were used in the experiments, and how were they determined? Additionally, can the authors provide more details on the implementation of the proposed method within existing contrastive learning frameworks?\n- Could the authors address the concerns regarding the generalization capabilities of the proposed method across different datasets and network architectures? Are there plans to conduct experiments on a broader range of datasets and architectures to better establish the method's robustness and applicability?\n- Given the focus on OOD detection using contrastive learning, how does the proposed method compare with other methods in terms of computational efficiency and scalability, particularly in large-scale datasets and complex network architectures?"
    },
    "oTRekADULK": {
        "gold_review": "**Summary**\nThe paper introduces SparseDiff, a novel approach to enhance the scalability of graph diffusion models by combining sub-graph sampling and sparse message-passing neural networks. SparseDiff extends existing models like DiGress by employing a noise model that preserves sparsity during diffusion, using a sparse transformer for denoising, and computing loss on a subset of all node pairs. Despite these innovations, the contributions are viewed as incremental, mainly extending prior works such as DiGress and EDGE. The method suffers from presentation issues, including unclear methodology and formatting problems, and lacks comprehensive empirical validation, especially in scaling to very large graphs.\n\n**Strengths**\n- The proposed approach innovatively uses techniques to leverage the sparsity of the graphs during training, addressing scalability issues in diffusion model graph generation, which has been a notable challenge.\n- The development and architectural design of the model are clearly and comprehensively demonstrated, making its operational logic convincing.\n- The paper contributes to a rapidly growing interest in deep models for diffusion-based graph generation, with the core concept of sampling a fraction of node pairs for inclusion in message-passing being a reasonable approach.\n- The paper comprehensively covers related works, providing a good foundation and context for the research.\n\n**Weaknesses**\n- The contributions, while valuable in addressing sparsity, appear largely incremental as many elements are derived or extended from existing models such as DiGress and EDGE.\n- Despite claims of scalability, the method involves quadratic complexity in graph generation (sampling) which remains a performance bottleneck.\n- The paper suffers from numerous presentation issues, including unclear writing in places, grammatical errors, and inconsistent formatting. Specific description problems, such as typos on several pages and unclear notation, impact the readability and professionalism of the manuscript.\n- The experimental section lacks a comprehensive empirical study, particularly missing deeper analysis on very large graphs and the effect of including large graphs in training datasets. There is also a concerning inconsistency in the use of baselines across datasets.\n- Theoretical support for the model's efficacy, such as guarantees on the generative capabilities or thorough time complexity analysis, is missing.\n\n**Questions**\n- 1. Could the authors provide additional clarification on the model architecture and the specific roles of components like PNa and FiLM, given that the absence of an appendix creates confusion?\n- 2. Throughout the different calls to the model during sampling, is the edge list updated each time, and if so, how does this impact performance and complexity?\n- 3. It would be beneficial to understand better why there is significant performance improvement in certain datasets over DiGress if the method is an extension of it. What are the underlying factors leading to these improvements?\n- 4. How can the authors justify the exclusion of GraphARM and SaGess in the large graph experiments, and could inclusion of such models offer a more balanced comparison?\n- 5. For a clearer understanding of the method's approach and scalability, could the training and sampling procedures be outlined more clearly in the text, possibly with algorithms detailed in the main document rather than the appendix?\n- 6. The paper mentions avoiding distribution shifts by exploiting sparsity only during the training phase. Can the authors clarify how the model maintains accuracy without introducing significant shifts in the distribution it learns?",
        "inference_review": "**Summary**\nThe paper introduces SparseDiff, a scalable denoising diffusion model for graph generation that leverages sparsity during training and sampling phases. The model comprises a sparse diffusion process, a noise model that preserves sparsity, and a sparse graph transformer, all designed to handle edge list representations efficiently. Experimental results demonstrate that SparseDiff achieves comparable or better performance to state-of-the-art methods on small and large graphs. Despite these strengths, the paper suffers from several significant weaknesses, including poor clarity, lack of novelty, and insufficient comparison with existing methods. The paper also fails to address scalability issues in the sampling phase and lacks detailed ablation studies.\n\n**Strengths**\n- The paper addresses the scalability issue in graph generation by proposing a novel approach that leverages sparsity, enabling the generation of graphs with a larger number of nodes compared to previous methods.\n- The use of sparse diffusion models allows for efficient training and sampling, which is critical for large-scale graph generation tasks.\n- The methodology is well-motivated and the paper is clearly written, making it easy to follow.\n- The experimental results demonstrate that SparseDiff achieves state-of-the-art performance on both small and large graphs.\n- The proposed method is versatile and can handle different types of graphs, including molecular graphs and protein graphs.\n\n**Weaknesses**\n- The paper lacks a detailed explanation of the methodology, particularly the sparse diffusion process and the sparse graph transformer, which are crucial components of the model.\n- The novelty of the proposed method is questionable as it builds upon existing work without sufficient differentiation or explanation of its unique contributions.\n- The paper does not adequately address scalability issues in the sampling phase, which is a significant concern for large-scale graph generation tasks.\n- The experimental evaluation is limited and lacks a comprehensive comparison with existing methods, particularly those that also exploit sparsity.\n- The paper contains several typos and unclear statements that detract from its readability and professional quality.\n- The ablation studies are insufficient, and the paper does not provide a thorough analysis of the impact of different components of the model.\n\n**Questions**\n- Could the authors clarify the differences between the sparse diffusion process and the sparse graph transformer, and provide more details on how these components interact with each other?\n- How does the proposed method handle scalability issues in the sampling phase, and what strategies are employed to address these challenges?\n- What are the specific advantages of the proposed method over other existing methods that also exploit sparsity, and how do these advantages translate into practical benefits for graph generation tasks?\n- Can the authors provide a more detailed explanation of the motivation behind the use of sparse diffusion models in graph generation, and how this approach is expected to improve scalability and performance?\n- What are the key differences between the proposed method and other state-of-the-art graph generation methods, and how do these differences impact the performance and scalability of the model?"
    },
    "P895PSh41Z": {
        "gold_review": "**Summary**\nThe paper introduces Relaxed State-Adversarial Offline Reinforcement Learning (RAORL), a novel approach in offline RL that creatively integrates adversarial robust reinforcement learning with a model-free framework. RAORL optimizes policy robustness by constructing an uncertainty set of plausible dynamics, leveraging adversarial perturbations to ensure risk-aware policy performance. The method is validated on the D4RL benchmark, demonstrating its effectiveness and potential for risk-sensitive applications. Despite its theoretical contributions and empirical achievements, reviewers noted concerns, including its similarities to existing methods, unclear presentation, and inadequate state-of-the-art comparisons.\n\n**Strengths**\n- The paper introduces an innovative concept by adapting an existing online robust RL algorithm (RAPPO) to the offline setting, integrating adversarial robust reinforcement learning with offline model-free reinforcement learning within a state-adversarial optimization framework.\n- It presents robust theoretical foundations and provides theoretical guarantees for an idealized version of the algorithm.\n- The performance of RAORL on D4RL is impressive and shows strong results, especially evident in the AntMaze tasks, demonstrating the algorithm\u2019s efficacy compared to previous methods.\n- It offers a lower bound guarantee which distinguishes and potentially significantly contributes to the field of reinforcement learning.\n\n**Weaknesses**\n- The paper's structure and organization could be improved to clearly convey its primary contributions, as the narrative is somewhat difficult to follow due to convoluted writing.\n- The distinctions between RAORL and RAPPO are not substantially articulated, specifically regarding offline application, solver differences, and hyperparameter tuning.\n- There is a lack of comparison with state-of-the-art algorithms like SAC-N, EDAC, and LB-SAC, reducing the persuasiveness of the experimental results.\n- The content occasionally engages in excessive self-promotion which might detract from its academic tone.\n- Some theoretical results appear very similar to existing works (e.g., MoREL paper), and these similarities or differences are not adequately discussed.\n- The experimental setup does not include stochastic tasks, despite the claims of addressing environments where model-based algorithms struggle.\n- The paper does not incorporate or thoroughly compare with related robust RL approaches, such as RORL and S4RL, which are critical for establishing novelty and significance.\n\n**Questions**\n- Could you clarify whether the expectation over s, a in Definition 1 covers all transitions in the offline dataset?\n- In Definition 3, do the transition probabilities require re-normalization if the argmin defining Z\u03c3\u03c0 contains more than one state?\n- How were the perturbations selected in section 5.3?\n- How effectively does RAORL bridge the performance gap in real-world applications as claimed?\n- What is the primary advantage of RAORL, and can you provide more evidence or explanation to support its claimed advantages over other offline model-free algorithms?\n- Can you detail the learning objectives for both value functions and policy, and provide more implementation details in the Appendix to facilitate reproduction of the results?\n- Could a comparison with the prior state adversarial baseline RORL be included in the state perturbation experiments?\n- How was the attack budget (\u03b5) determined in RAORL, and what impacts do the hyperparameters \u03b5 and \u03b1 have on performance?",
        "inference_review": "**Summary**\nThe paper introduces a novel approach called Relaxed State-Adversarial Offline Reinforcement Learning (RAORL), which integrates a model-free offline RL method with a state-adversarial perturbation to enhance policy robustness and adaptability to varying transition dynamics. RAORL employs a conservative value function to address model uncertainty in offline settings, which is supported by both theoretical analysis and empirical evidence. The method has been evaluated against state-of-the-art methods on established offline RL benchmarks, showing competitive performance. The core idea revolves around the application of the relaxed state-adversarial approach to offline RL, which allows the policy to perform well in a variety of environments.\n\n**Strengths**\n- The paper is well-written, clear, and easy to follow, making it accessible to a broad audience.\n- The proposed method combines robust RL principles with model-free offline RL, which is a novel and promising approach that shows potential for handling offline RL challenges.\n- Theoretical analysis and empirical results support the efficacy of the proposed method, demonstrating its effectiveness in improving offline RL performance.\n- The method's ability to improve upon existing offline RL methods like TD3+BC and ReBrac by reducing the performance gap and enhancing the robustness of the learned policy is noteworthy.\n- The paper is well-organized, making it easy to understand and follow, and the authors provide a good comparison with other related methods in the literature.\n\n**Weaknesses**\n- The paper does not sufficiently differentiate its contributions from existing works, particularly those that address robustness in offline RL settings.\n- The experimental evaluation is limited in scope and does not include a diverse set of benchmarks, which could potentially limit the generalizability of the results.\n- The theoretical analysis, while comprehensive, may not fully account for all possible scenarios, such as non-linear dynamics or high-dimensional state spaces, which could impact the practical applicability of the proposed method.\n- The method's reliance on assumptions such as the Lipschitz continuity of the value function may limit its applicability in certain real-world scenarios.\n- The paper does not provide sufficient details on the experimental setup, including the choice of hyperparameters and the specifics of the offline datasets used.\n\n**Questions**\n- Can the authors clarify the specific contributions of this work in the context of existing literature on robust offline RL?\n- Why is the performance of RAORL on the door-cloned dataset not comparable to other methods? Is there a specific reason for this, and could it be related to the nature of the dataset or the method used?\n- How do the authors address the potential limitations of their theoretical analysis, particularly regarding non-linear dynamics and high-dimensional state spaces?\n- Could the authors provide more details on the experimental setup, including the choice of hyperparameters and the specifics of the offline datasets used?\n- In terms of reproducibility, can the authors provide the source code for the experiments and the exact details of the datasets used?\n- Could the authors discuss the implications of the assumptions used in their theoretical analysis and how they might affect the practical applicability of the proposed method?"
    },
    "qi88abxiE4": {
        "gold_review": "**Summary**\nThe paper proposes a new methodology for scaling spectral graph neural networks through the sparsification of Laplacian polynomials, aiming to retain essential spectral properties and enable both fast and end-to-end training across various datasets, including a very large-scale graph dataset. The proposed framework leverages prior work on random-walk-based spectral sparsification to make spectral GNNs more scalable by approximating the propagation matrix of Laplacian filters, which could potentially enhance the effectiveness of these neural networks on node classification tasks. Additionally, the paper attempts to bridge theoretical and experimental gaps by providing mathematical proofs to support its methodologies, although the paper has been critiqued for its practicality given the multitude of hyperparameters and potentially restrictive assumptions regarding the spectral GNNs addressed.\n\n**Strengths**\n- The paper addresses the critical issue of scalability in spectral graph neural networks and provides a clear motivation for this study. The relevance of scalability in large-scale applications is well established.\n- Empirical results demonstrated on Ogbn-papers100M emphasize the method's scalability. Additionally, the paper covers experiments with datasets of different sizes, showcasing the method's applicability to very large datasets.\n- There is a rigorous mathematical foundation provided, demonstrating through proofs the efficacy of spectral sparsification aimed at improving scalability in the training phase of GNNs.\n- The methodological explanation is clear, and the paper presents a theoretically analyzed approach. The experimental data often indicates improvement over the typical out-of-box GNN methods when using the sparsification strategy.\n\n**Weaknesses**\n- The paper's scope appears limited as it mainly applies to APPNP and GPR GNNs and does not provide results for other types of spectral GNNs, such as JacobiConv.\n- It is unclear whether the proposed methods would apply to non-linear models of spectral GNNs, particularly when they involve stacking layers of polynomial spectral filters interleaved with nonlinear activation functions like ReLU.\n- Although the study emphasizes scalability, there is insufficient comparison concerning computational efficiency (memory usage and wall-clock time) across various methods and datasets, missing a direct linkage to the scalability claims.\n- The theoretical underpinnings, while rigorous, are mostly derivative of prior works, with little novelty or critical insights into unique challenges posed by spectral sparsification.\n- Several methodological assertions and the experimental setup lack depth in explanation and comparative analysis, notably how spectral GNNs with sparsification fare against established benchmarks or similar recent approaches.\n- The writing needs improvement for clarity and coherence, with several sections requiring better structuring and reduction of redundant elements. Attention to details like proper and consistent notation, references, and proof environments in appendices is also necessary.\n\n**Questions**\n- 1. Is the proposed spectral GNN design applicable to models involving multiple layers with interleaved non-linearities such as ReLU? How would this affect the theoretical analysis?\n- 2. Could you provide specifics on the efficiency improvements (memory and computation time) realized by the node-wise sampling method described in Section 3.3, possibly including these details in an appendix?\n- 3. At what stage is the sampling (sparsification) procedure applied\u2014every forward pass or just at the initiation of training?\n- 4. How do you address the inconsistency between the sparsification approach benefiting only a few heterophilous datasets, with some datasets even showing degraded performance? What is the percentage of edges retained after sparsification, and how does this correlate with training efficiency and final model performance?\n- 5. To advance the understanding of scalability, could you discuss the thresholds or criteria used to determine the degree of sparsification or spectral similarity in practical scenarios? How do these choices affect GNN accuracy and overall performance metrics?\n- 6. Are comparison metrics against established or concurrent spectral GNN methodologies available, particularly those that also address scalability or utilize different forms of sparsification or polynomial approximations?",
        "inference_review": "**Summary**\nThe paper introduces a novel method for graph sparsification using Laplacian sparsification techniques, aiming to enhance the scalability of spectral Graph Neural Networks (GNNs) by precomputing graph propagation matrices. The proposed method, which includes static and learnable variants, utilizes multi-hop neighbor interactions to reduce computational complexity while maintaining spectral properties of the graph. The authors provide theoretical proofs and empirical evidence demonstrating the effectiveness of their method across various graph datasets. However, the paper has been critiqued for its limited novelty, unclear presentation, and insufficient comparative analysis with other existing methods.\n\n**Strengths**\n- The paper introduces a novel approach to graph sparsification by employing Laplacian sparsification techniques, which enhances the scalability of spectral GNNs.\n- Theoretical proofs are provided, which support the correctness of the proposed methods and demonstrate that they generate Laplacian sparsifiers for the random-walk matrix polynomial.\n- Empirical results presented in the paper demonstrate the effectiveness of the proposed methods, showing stable improvements over the corresponding baselines across different real-world datasets.\n- The paper is well-written and easy to follow, with clear presentation of the methods and results, making it accessible to readers.\n- The proposed method can be applied to a wide range of GNNs, including spectral GNNs with learnable polynomial filters, which is a significant advantage.\n\n**Weaknesses**\n- The novelty of the paper is limited as it builds upon existing methods and techniques such as SGC, GLSGC, and APPNP-LS, with a lack of significant new theoretical contributions.\n- The paper does not adequately discuss the impact of the pre-computation on the performance of the GNNs, which is critical for understanding the effectiveness of the proposed method.\n- There is a lack of comparative analysis with other existing methods, which could provide a more comprehensive understanding of the proposed method's advantages and limitations.\n- The paper does not provide sufficient details about the training time, complexity, and scalability of the proposed methods, which are essential for evaluating the practical applicability of the method.\n- The experimental setup and results lack clarity, making it difficult for readers to understand the significance and impact of the proposed methods.\n\n**Questions**\n- Can the authors provide more detailed results on the training time and complexity of the proposed methods, especially in comparison with other methods?\n- How does the pre-computation of graph propagation matrices affect the performance of the GNNs, and what are the implications of this for the scalability and effectiveness of the proposed method?\n- Could the authors provide a more detailed comparative analysis with other existing methods to better highlight the advantages and limitations of the proposed method?\n- How does the proposed method perform on graphs with high-dimensional input features, and what are the implications for the scalability and effectiveness of the method in such scenarios?\n- Can the authors provide more information on the experimental setup and results, particularly the details of the datasets used and the hyperparameter settings, to aid in understanding the significance and impact of the proposed methods?"
    },
    "qIn2IgMWYg": {
        "gold_review": "**Summary**\nThe paper introduces a method known as Iterative Search Attribution (ISA) that combines gradient descent and ascent to assess the relevance of input features in neural network predictions, enhancing model interpretability. It claims improvements over existing methods by offering more accurate and interpretable attribution, using a scale parameter in the iterative process that prioritizes significant parameters over others in subsequent iterations. Its effectiveness is demonstrated via experiments on datasets like ImageNet, and it reportedly outperforms state-of-the-art methods in insertion score evaluations. The authors provide a description of an innovative approach to constructing gradients integration paths and the method's efficacy is validated via comparative analysis with baseline methods.\n\n**Strengths**\n- The paper introduces an innovative approach by combining gradient descent (GD) and gradient ascent (GA) to construct integration paths in gradient-based attribution methods, potentially improving the interpretability and accuracy of saliency maps.\n- Promising qualitative results are shown in Figure 2, illustrating the effectiveness of the proposed method.\n- The paper is well-organized and clearly articulates key contributions, aiding in reader comprehension and highlighting the main innovations.\n- The corresponding code has been released, enhancing the paper's utility and facilitating reproducibility.\n- State-of-the-art experimental results are achieved, and detailed ablation studies validate the proposed methodology.\n\n**Weaknesses**\n- The paper's discussion on the distinction between local and global attribution methods is unclear, specifically regarding how these properties relate to input space.\n- It lacks a thorough theoretical analysis, particularly in justifying the chosen constraints in Section 4.3 and the effectiveness of the insertion and deletion metrics.\n- Some sections of the paper, including the algorithm description and Figure 1, contain typos and confusing statements that reduce readability and clarity.\n- There is a need for more rigorous justification for various ad-hoc design choices and hyper-parameters; the impacts of these elements on the attribution results are not well-explained.\n- The comparison with other methods is not extensive enough, with a limited range of models and newer methods could have been included to benchmark the proposed method's efficacy.\n- The efficiency of the methodology has not shown significant improvement due to its iterative nature, which could limit its practical applicability in some scenarios.\n\n**Questions**\n- Could you provide clearer definitions and comparisons regarding local versus global attribution methods?\n- Can you clarify the connections and the rationale behind the feature attribution discussed in Section 4.2?\n- Could you provide more in-depth theoretical justification for the constraints mentioned in Section 4.3? What implications arise if the hyper-parameter $S$ is not introduced?\n- Is it possible to include a more detailed quantitative analysis supporting the claim that the insertion score is a more representative indicator of the performance of attribution algorithms?\n- How does the proposed methodology perform in non-CNN models, given the assertion of poor performance of methods like Grad-CAM and Score-CAM in such models?\n- Could you discuss the sensitivity of the step size, learning rate, and scale parameters observed in Figure 3? What are the implications of this sensitivity on the method's robustness and reliability?",
        "inference_review": "**Summary**\nThe paper introduces the Iterative Search Attribution (ISA) method for improving the interpretability of deep neural networks. ISA combines gradient ascent and gradient descent to iteratively identify and refine the importance of features in model inputs, aiming to enhance attribution results. The approach involves clipping relatively unimportant features and introducing a scale parameter to ensure the significance of the next iteration's parameters over the current. This method is compared to existing state-of-the-art attribution methods, demonstrating its effectiveness through experiments on the ImageNet dataset. However, the paper is criticized for its lack of clarity in writing and presentation, as well as insufficient ablation studies to substantiate the claims. Furthermore, it does not address the potential issues with the scale parameter's influence on attribution results and lacks a thorough comparison with other methods, such as SHAP and LIME, which are critical for establishing the robustness of the ISA method.\n\n**Strengths**\n- The paper is well-written, making it accessible and easy to follow, with clear explanations and effective use of visual aids like figures and tables to enhance comprehension.\n- The proposed method introduces a novel approach to feature importance estimation by combining gradient ascent and gradient descent, which is a logical and innovative concept in the field of explainable artificial intelligence (XAI).\n- The experimental results show that the proposed ISA method outperforms existing state-of-the-art attribution methods in image recognition interpretability tasks, highlighting the potential of this new approach.\n- The authors have performed comprehensive experiments to demonstrate the effectiveness of the proposed method, which include ablation studies to evaluate the influence of different parameters and various comparisons with existing methods.\n\n**Weaknesses**\n- The paper lacks a clear and detailed explanation of the motivations behind the proposed method, specifically why combining gradient ascent and gradient descent is necessary and how it addresses the limitations of existing methods.\n- The novelty of the approach is not convincingly demonstrated, with the paper heavily relying on existing literature and not providing sufficient evidence or justification for the superiority of the proposed method over others like SHAP and LIME.\n- The experimental design and analysis are not robust enough to fully support the claims made about the effectiveness of the ISA method. Notably, the paper does not address potential issues such as the influence of the scale parameter on the accuracy of feature importance estimation.\n- There are several inconsistencies and ambiguities in the presentation of the paper, including the use of similar terms like \"features\" and \"parameters\" which could lead to confusion.\n- The related work section is insufficiently detailed, lacking a comprehensive review of existing literature, which is necessary for contextualizing the contribution of the paper.\n\n**Questions**\n- 1. Could the authors provide more details on the motivations and rationale behind combining gradient ascent and gradient descent in the proposed method?\n- 2. What are the specific advantages of the proposed ISA method over existing methods like SHAP and LIME, and can the authors provide a more detailed comparison of these methods?\n- 3. How does the scale parameter in the ISA method affect the accuracy of feature importance estimation, and can the authors provide empirical evidence or theoretical analysis to address this concern?\n- 4. Could the authors clarify the apparent contradictions and inconsistencies in the presentation of the paper, particularly in the use of terminology and the explanation of methodologies?\n- 5. Can the authors discuss the potential limitations of the ISA method and how it could be improved or extended to address these limitations?"
    },
    "qKKwQvepx0": {
        "gold_review": "**Summary**\nThe paper introduces a framework named Natural Language Constraints and Parameters (NLCP) aimed at enhancing the explainability and steerability of machine learning models using natural language. The proposed method represents statistical model parameters as natural language predicates, such as \"has a casual style,\" which can be steered and explained through optimization algorithms that handle both the continuous and discrete aspects of these predicates. The framework is evaluated across four statistical models (Clustering, Contrastive Learning, Regression, and Topic Modeling) using three different datasets. Evaluations leverage denotation and surface similarity scores judged using GPT-4. The authors demonstrate the practical application of NLCP in generating understandable image clusters and detecting variations in major topics, thereby hoping to provide an innovative approach to control and explain model behavior effectively.\n\n**Strengths**\n- The paper proposes an innovative idea of using natural language explanations based on different criteria, allowing explanations of cluster nodes for image clustering based on the style of images or type of objects.\n- The use of natural language sentences as binary feature extractors is considered novel.\n- The paper is well-written, easy to follow, and introduces a new framework leveraging the denotational semantics of natural language.\n- Demonstrations of proof-of-concept applications are provided, showing controllably generating explainable image clusters and describing major topic variations.\n- The idea of using a large language model (LLM) to generate natural language predicates to explain and guide model predictions is intriguing.\n\n**Weaknesses**\n- Some figures (e.g., Figure 1) and visualizations are unclear, particularly where learned parameter explanations are involved, and certain visualizations appear identical.\n- The contributions of the paper are not distinctly outlined in the introductory section which could be improved for clarity.\n- Mathematical notation used in the paper is confusing (e.g., [[c]] (\u03c6) and [[\u03c6]] (x)), making it difficult to distinguish and follow the roles of variables early in the document.\n- Theoretical justification for methods like OptimizeWandPhi and Discrete is weak and needs strengthening.\n- The experimental section seems limited and somewhat superficial (\"toyish\"), raising concerns about the practical applicability of the method in the current state of machine learning.\n- Extensive reliance on large language models for various steps throughout the approach raises issues about computational feasibility and potentially undermines the paper's contribution as appearing ad hoc.\n- Insufficient variety and volume in datasets used for experiments make it difficult to evaluate the effectiveness of the method fairly.\n- The method's overall structure and accommodations for different parameters are not well illustrated or explained.\n\n**Questions**\n- How can the evaluation of the method be ensured to be reliable and representative, particularly when relying on algorithms like GPT-4 for similarity ratings?\n- How are constraints like \"I want to cluster based on style\" determined and ensured to be representative?\n- Would it be possible and advantageous to assign natural language predicates to clusters in a post-hoc fashion?\n- Regarding equation (5), does it assign a zero probability to all sentences that don't match a certain topic? How computationally intensive is the process to verify each sentence against each predicate \u03c6i?\n- Could you expand on the subsection \"Modeling Uninformative Nuisances with a Base Distribution\"? How is the base distribution typically defined?\n- How exactly is the continuous unit vector \u03c6~k obtained, and why is there no need for a gradient estimator for back-propagation through non-differentiable discretization in your model?\n- Have more challenging tasks beyond the three datasets been explored to test the applicability of the proposed method?\n- Could you clarify if the primary goal of the paper is to use an LLM to generate explainable predicates, or if there are other optimization methods considered for generating these predicates?\n- How can this approach be integrated in an iterative human-in-the-loop setting, and does it allow re-utilizing previous predicates when incorporating new constraints?",
        "inference_review": "**Summary**\nThe paper introduces a novel framework called NLCP (Natural Language Parameters with Constraints) aimed at improving the explainability and steerability of statistical models in text. NLCP employs a two-step optimization process, initially using gradient descent to optimize a continuous relaxation of natural language parameters, followed by a refinement step that converts these into discrete parameters. This approach is demonstrated across various statistical models such as clustering, topic modeling, and regression, utilizing datasets like the New York Times and AG News. The paper claims that this framework enhances the model's ability to learn from constraints and interpret its parameters in natural language, making the models more understandable and controllable.\n\n**Strengths**\n- The paper is well-written and provides a clear, intuitive explanation of the approach, making it easy to follow.\n- The proposed approach is novel and addresses the significant challenge of integrating natural language into statistical modeling, enhancing explainability and steerability.\n- The methodology is described as sound and the results are promising, with good performance reported on the datasets used.\n- The paper provides a comprehensive review of related work, which helps contextualize the research within the existing literature.\n- The inclusion of multiple baselines and various statistical models in the experiments adds depth to the evaluation.\n\n**Weaknesses**\n- The paper's focus on text modeling could benefit from including visualizations, such as word clouds or topic distributions, to better illustrate the results.\n- The use of a large language model (LLM) for feature extraction is not sufficiently justified, especially considering the potential for biased or irrelevant features.\n- The paper lacks detailed experimental results for certain models and datasets, which could be addressed by including additional tables or figures.\n- The paper could benefit from a more thorough discussion on the practical applications and limitations of the proposed method.\n- The comparison of the proposed method with other methods is not entirely fair, as some baselines use different datasets, which could skew the evaluation results.\n- The optimization of natural language parameters and the use of LLMs for feature extraction are not sufficiently explained, which could affect the reproducibility of the results.\n\n**Questions**\n- How does the paper ensure the robustness of the results, particularly concerning the use of LLMs for feature extraction?\n- Could the authors provide more details on the experimental results for all models and datasets, and explain the rationale behind the choice of baselines and datasets?\n- How does the proposed method handle the scalability of the model, especially in terms of computational efficiency?\n- What are the practical applications of the proposed method, and what are its limitations?\n- In the context of using natural language parameters, how does the paper ensure that these parameters are accurately and reliably extracted from the LLMs?\n- Could the authors elaborate on how the proposed method compares with other existing methods, and what advantages or disadvantages it offers over these methods?"
    },
    "RXU6qde675": {
        "gold_review": "**Summary**\nThis paper introduces the Adversarial Enhanced Representation (AER), a novel graph embedding framework designed for link prediction in multi-layer networks. AER incorporates a representation generator, a layer discriminator, and a link predictor to manage both intra-layer and inter-layer representations through adversarial training. The representation generator leverages these learned representations to further enrich the intra-layer embeddings. Real-world datasets were employed to demonstrate the performance of AER, with some showing notable improvements over established baselines. Despite these strengths, there are concerns regarding the novelty of the approach, sufficiency in experimental comparisons, and overall coherence in methodological presentation.\n\n**Strengths**\n- The paper is well-organized and clear, making it easy for readers to understand the model and its intended applications in multi-layer network settings.\n- Extensive experiments demonstrate the effectiveness and efficiency of the proposed method in capturing relevant information across different layers of multi-layer networks.\n- The paper identifies an interesting and relevant problem in the domain of multi-layer networks, proposing a novel layer discriminator that appears promising in this context.\n- The experimental results show some improvement over existing baselines, and ablation studies underscore the necessity of the layer discriminator.\n- The paper considers an intriguing adversarial setting to learn edge representations that are \"layer-invariant\" and yet effective for intra-layer link prediction.\n\n**Weaknesses**\n- The novelty of the proposed approach is limited, as it heavily relies on well-known models and operators such as GCN and CNN without adequately motivating the reason for their combination.\n- The proposed approach and certain component choices (e.g., layer discriminator and link predictor) lack clear motivation and sufficient differentiation from existing methods.\n- The manuscript suffers from issues in writing clarity and organization, with some sections containing redundant information and lacking necessary citations.\n- The selection of baselines for experimental comparison is incomplete, missing both traditional link prediction models and relevant state-of-the-art (SOTA) multi-layer GNN models mentioned in existing literature.\n- The datasets used for evaluating the model are relatively small, which raises concerns about the scalability and applicability of the proposed methods to real-world, large-scale networks.\n- There are minor issues with readability and notational clarity which could hinder the comprehension of the methodological details and experimental setups.\n- Some methodological choices in the proposed models are not well-justified, and the paper lacks comprehensive ablation studies to validate these choices.\n- The reproducibility of the results is questionable as the paper does not provide sufficient details for replication, and no auxiliary material is utilized to bridge this gap.\n\n**Questions**\n- Could you provide a more specific description of the multi-layer networks discussed in the introduction and clarify how they differ from typical graph-level datasets used in GNN research?\n- Why are CNNs applied after GCNs for both intra- and inter-layer node embeddings, and what distinct advantages do they offer in this setting?\n- Can you explain the differences between the layer discriminator and the link predictor, particularly in terms of their roles and functionalities within the model?\n- What is the rationale behind the combination of an adversarial loss with a binary classification loss in the model, and how do you ensure a balanced optimization of these loss components?\n- Given the small size of the datasets used, how can you ensure that the proposed methods can scale effectively to larger, more complex networks?\n- Why were certain relevant works on link prediction in heterogeneous graphs and embeddings for knowledge graphs not discussed or compared in the study?\n- What steps have been taken to ensure fair comparisons with baselines, particularly in terms of model complexity and computational requirements?\n- The paper mentions several losses and model parameters\u2014can you provide details on how model convergence was assessed, including typical values and behaviors of these parameters during training?",
        "inference_review": "**Summary**\nThe paper presents a novel graph embedding method called Adversarial Enhanced Representation (AER) aimed at link prediction in multi-layer networks. AER employs a three-module framework comprising a representation generator, a layer discriminator, and a link predictor. These modules work together through adversarial training to learn and fuse inter-layer and intra-layer representations effectively. The representation generator aims to deceive the layer discriminator by generating transferable representations, while the discriminator attempts to accurately identify layer sources. The adaptive fusion between these representations enables the link predictor to make informed decisions about missing links. The method is evaluated on real-world datasets, demonstrating its efficacy compared to several baseline methods.\n\n**Strengths**\n- The paper is well-written, easy to follow, and provides a clear motivation for the proposed method.\n- The proposed method, AER, is innovative and demonstrates a novel approach to link prediction in multi-layer networks, employing an adversarial training mechanism which is well-described.\n- The experimental results are thorough and show that the proposed method outperforms several baseline methods, indicating the effectiveness of the approach.\n- The use of a layer discriminator in the AER framework is a unique contribution, helping to identify layer sources of learned representations, which is a novel aspect in multi-layer network research.\n\n**Weaknesses**\n- The paper lacks a detailed explanation of the dataset, particularly the types of datasets used, which could be beneficial for readers to understand the applicability and context of the research.\n- The paper does not include a comprehensive literature review on multi-layer networks, which could have provided a richer background for the study.\n- There are unclear elements in the paper, such as the definition of \"multi-layer networks\" and the role of the \"link predictor\" in the proposed framework, which could be better defined and explained.\n- The paper's description of the AER framework is insufficiently detailed, especially regarding the training process and the specific roles and interactions between the different components like the representation generator and the layer discriminator.\n- The paper does not sufficiently discuss the limitations of the study and does not compare the results with other recent state-of-the-art methods, which could help in evaluating the robustness and positioning of the proposed method.\n\n**Questions**\n- Can you provide a detailed explanation of the datasets used in your study, including their types and characteristics?\n- How does the proposed method handle datasets with varying numbers of layers? Is there a specific strategy for handling datasets with different numbers of layers?\n- Could you clarify the definition of \"multi-layer networks\" used in your study? This would help in understanding the scope and application of the proposed method.\n- What is the role of the \"link predictor\" in the AER framework, and how does it interact with other components of the framework?\n- Could you elaborate on the training process of the AER framework, specifically how the representation generator and the layer discriminator interact and influence each other?\n- In the ablation study, why is there a significant performance drop for AER- compared to AER? What are the implications of this finding for the proposed method?\n- How does the proposed method compare with other recent state-of-the-art methods in terms of performance and efficiency?\n- What are the specific limitations of the proposed method, and how do these impact the applicability and effectiveness of the method in real-world scenarios?"
    },
    "uvFhCUPjtI": {
        "gold_review": "**Summary**\nThe paper introduces an Evolving Fourier Transform (EFT) suited for temporal graphs by addressing the complexities associated with evolving graph structures. This transform is an alternative spectral method, optimizing over the graph's Laplacian dynamics and effectively decomposing the spatial and temporal domains to reduce computational demands. Theoretical guarantees validate EFT's approximation to a true variational solution. Additionally, empirical results showcase EFT's ability to filter noise and enhance signal interpretation, even within large-scale dynamic settings. Challenges remain concerning the theoretical underpinnings of learning within this framework and the approach's generalizability to dynamic graphs undergoing node changes.\n\n**Strengths**\n- The concept of Evolving Graph Fourier Transform (EFT) for analyzing spatio-temporal graphs is novel and theoretically grounded, providing an innovative approach to handling time-evolving graph data.\n- The theoretical properties of EFT are elaborately established with proofs and approximations which afford provable guarantees, enhancing the method's credibility.\n- EFT's practical effectiveness is demonstrated through benchmarks and simulations, where it shows promise in applications like filtering noise, amplifying useful signals, and integrating into transformer models for sequential link prediction.\n- The method is computationally efficient with a complexity noted as \\(O(T + T\\log(T))\\), and it separates the vertex and time domain analysis which may simplify the computational demands in practice.\n\n**Weaknesses**\n- The presentation of the paper can be improved. It suffers from being dense, with crucial points such as the coupling of filtering in vertex and time domains relegated to appendices instead of being highlighted in the main text. Font sizes in tables and clarity of equations need attention to enhance readability.\n- The paper lacks extensive empirical evaluation against other established methods and does not discuss limitations related to dynamic graphs that experience node additions or drops.\n- While theoretical underpinnings are strong, practical uncertainties about EFT's performance in real-world scenarios lacking comparison to baselines are unaddressed.\n- EFT's assumptions and generalizability are concerns not sufficiently addressed in the main text. Necessary conditions for its application, such as the bounded rate of graph changes and unique eigenvalues, are significant and should be better highlighted.\n- The novel decoupling approach in spatio-temporal data analysis is not new to the broader community, suggesting a need for a clearer articulation of EFT's unique contributions over prior models.\n\n**Questions**\n- Can the efficiency of EFT's computation be empirically verified, especially against conventional baselines? How does this performance translate in large-scale scenarios?\n- What are the implications of EFT in scenarios beyond link prediction, such as predicting node features or embedding timespan of edges? How flexible is EFT in adapting to such extended applications?\n- Could the authors provide more intuitive examples or small case studies to illustrate the working and benefits of EFT? What would the harmonics look like for specific graph structures, such as a ring of ring graphs?\n- In what ways does EFT potentially outperform or fall short when compared against methods like spectral clustering for dynamic networks?\n- What does conducting the EFT \"dimension-wise\" imply, and how does this approach affect its application across different data scales and structures?",
        "inference_review": "**Summary**\nThe paper introduces an Evolving Graph Fourier Transform (EFT), a novel approach to handling temporal graphs by decomposing them into vertex and time domains and applying a spectral transformation. The EFT aims to filter out noise from signals on these graphs by focusing on low-frequency components. The authors provide both theoretical underpinnings and empirical evidence to support the efficacy of this method, showing it to be computationally efficient and capable of outperforming existing methods in tasks such as denoising and link prediction. However, concerns were raised regarding the clarity of the writing, the theoretical foundation, and the empirical evaluations, particularly the selection of datasets and baseline comparisons.\n\n**Strengths**\n- The paper is well-written and easy to follow, making it accessible to readers familiar with spectral graph theory.\n- The authors provide both theoretical analysis and empirical evaluations, which are crucial for understanding the performance and limitations of the proposed method.\n- The proposed method is novel and appears to be well-motivated, with a clear focus on denoising temporal graph signals.\n- The computational efficiency of the proposed method is highlighted, which is a significant advantage given the complexity of the problem addressed.\n- The authors provide a clear explanation of the method, with detailed derivations and a comprehensive experimental setup, including both synthetic and real-world datasets.\n\n**Weaknesses**\n- The paper suffers from significant clarity issues, particularly in the motivation and theoretical underpinnings. Key concepts such as the Laplacian matrix and the pseudospectrum are not clearly defined, and the paper lacks a thorough comparison with existing methods.\n- The experimental setup is not robust, with too few datasets and baseline comparisons, which makes it difficult to assess the method's effectiveness and scalability.\n- The paper claims to handle dynamic graphs but focuses only on static graphs, which may mislead readers regarding the scope of the research.\n- The novelty of the method is questionable, as similar approaches have been previously proposed in other contexts, such as the Joint Fourier Transform (JFT) and the Joint Fractional Fourier Transform (JFFT).\n- The paper's claims about computational efficiency are not substantiated with adequate experimental evidence, making it difficult to verify the actual benefits of the proposed method.\n- There are concerns about the practicality of the proposed method, particularly in real-world applications, given the assumptions of the Laplacian matrix and the pseudospectrum.\n\n**Questions**\n- Can the authors clarify the definition and usage of the Laplacian matrix and the pseudospectrum in the context of this paper?\n- How does the proposed method compare to existing methods in terms of performance and computational efficiency?\n- Why is the proposed method considered novel, and how does it differ significantly from previous approaches like JFT and JFFT?\n- Could the authors provide a more detailed explanation of the experimental setup, particularly the choice of datasets and baseline comparisons?\n- How does the proposed method perform in scenarios with more complex or dynamic graph structures, such as those with multiple edges between nodes or with nodes entering or exiting the graph over time?\n- Are there any plans to include more diverse and challenging datasets in future work to better evaluate the method's effectiveness and scalability?"
    },
    "whFQe4MRIY": {
        "gold_review": "**Summary**\nThis paper delves into the development of a unified NeRF model, MI-NeRF, designed for learning from monocular videos of talking faces across multiple identities. The core innovation is a multiplicative module that effectively distinguishes between identity and expression information, inspired by TensorFaces, and allows for disentangled learning of these features. The method's key strength is its ability to handle multiple identities using a single model, significantly reducing training times and computational resources. It leverages a structure that involves an element-wise product between identity embeddings and expression embeddings for this purpose. Experiments conducted demonstrate superior performance in facial expression transfer and lip synchronization tasks, showing promising results over current state-of-the-art methodologies. However, concerns arise regarding the handling of varying expressions and lighting conditions across different identities, and the model's robustness under real-world scenarios has been questioned.\n\n**Strengths**\n- The proposed method, MI-NeRF, robustly adapts to unseen expressions and identities, requiring minimal retraining, which saves computational time and effort.\n- MI-NeRF effectively separates identity from expression thanks to its multiplicative module, ensuring consistent portrayal even with dynamic expressions, which is a challenge for some other models.\n- The method is simple and effective, built on top of earlier multi-identity NeRF methods, featuring a multiplicative structure between identity embeddings and expression embeddings.\n- Experiments and ablation studies validate the design of the multiplicative structure, showing that it helps improve factor disentanglement and visual quality.\n- The paper presents results that outperform competitors' approaches in visual quality and lip synchronization, and significantly reduces the training time.\n\n**Weaknesses**\n- The paper\u2019s descriptions are unclear regarding how face expressions and different lighting conditions are managed, sparking concerns about real-world application viability.\n- Concerns arise about the handling of time-varying information, as it's not clearly explained how the model ensures these codes don't inadvertently encode identity or expression information.\n- The implementation of the high-degree interaction module is not justified, as there is no visible use or experimental analysis mentioned.\n- Comparisons with similar multi-identity NeRF-based methods, especially in expression transfer experiments, are lacking or incomplete.\n- Ethical considerations concerning data privacy are not addressed adequately, particularly in terms of the usability and public release of the collected video data.\n- While MI-NeRF's uniqueness largely stems from its multiplicative module, the dependence on this single component could limit overall robustness in complex real-world scenarios.\n\n**Questions**\n- Could the authors explain how different expressions for various identities are aligned or handled within the model? Is there a canonical face model being used for this purpose?\n- How does the method handle different lighting conditions during model training and application?\n- Can the authors provide a more detailed comparison between MI-NeRF and other state-of-the-art methods, particularly GAN-based methods in the context of face video synthesis?\n- Is there a comparison or benchmarking for training time with other identities methods, like HeadNeRF?\n- Could the authors clarify the nature of the per-frame latent codes and how they ensure that these codes do not contain identity or expression specifics?\n- What steps are taken to prepare the data before its integration into MI-NeRF to ensure the integrity of the dataset and reproducibility of the results?\n- Can the authors discuss any potential limitations or challenges faced by the multiplicative module in complex real-world scenarios?",
        "inference_review": "**Summary**\nThe paper introduces a novel approach, MI-NeRF, that aims to train a single dynamic neural radiance field (NeRF) model from monocular talking face videos of multiple identities. The model incorporates a multiplicative module to capture non-linear interactions between identity and non-identity specific information, which is trained on multiple videos simultaneously to reduce training time significantly. The method allows for further personalization for a target identity and demonstrates state-of-the-art performance in facial expression transfer and audio-driven talking face video synthesis. However, the paper is criticized for insufficient comparisons with other multi-identity NeRFs, lack of clarity in methodology, and limited novelty in the technical contributions.\n\n**Strengths**\n- The paper addresses an important problem in the NeRF community, specifically the challenge of learning a single dynamic NeRF from multiple identities, which is significant for real-world applications.\n- The proposed method demonstrates a notable reduction in training time and achieves state-of-the-art results in facial expression transfer and audio-driven talking face video synthesis.\n- The paper is well-structured, making it easy to follow and understand the content, which is further enhanced by the inclusion of supplementary videos for better visualization.\n- The method's simplicity and straightforward approach make it accessible and understandable, which is supported by comprehensive experimental results and clear illustrations in the figures.\n\n**Weaknesses**\n- The novelty of the proposed method is questionable as the idea of learning a single NeRF for multiple identities is not entirely new, and the technical contribution appears limited.\n- The paper lacks comparisons with other multi-identity NeRFs, which would have strengthened the claims of the method's effectiveness and efficiency.\n- There is a lack of detailed methodology and mathematical definitions in the paper, particularly in Section 3.1, which could lead to confusion about the exact steps and parameters involved in the experiments.\n- The experimental results, although promising, are not sufficiently comprehensive to fully support the claims made in the paper. Specifically, the paper does not include detailed comparisons with other state-of-the-art methods or provide ablation studies on the number of training identities.\n- The writing and formatting of the paper need improvement for clarity and professional presentation. There are inconsistencies and errors in notation and terminology throughout the document.\n\n**Questions**\n- How does the proposed method compare to other multi-identity NeRFs in terms of performance and efficiency?\n- Can the authors provide more detailed mathematical definitions and explanations, particularly in Section 3.1, to clarify the methodology and parameters used in the experiments?\n- How does the performance of the proposed method change with varying numbers of training identities? What is the optimal number of identities for achieving the best results?\n- In light of the limited novelty and technical contribution, can the authors elaborate on the significance and novelty of their proposed method compared to existing works?\n- What are the main challenges and limitations of the proposed method, and how can they be addressed to further improve the performance and applicability of the method in real-world scenarios?"
    },
    "wOb0xFwdpr": {
        "gold_review": "**Summary**\nThe paper examines the effectiveness of various GPT models from OpenAI, such as GPT-3, InstructGPT, GPT-3.5, and GPT-4, in detecting sarcasm using the SARC 2.0 dataset from Reddit. Intending to establish performance benchmarks, it compared twelve variants of these models in fine-tuned and zero-shot scenarios with and without domain context prompts. The study revealed that while larger models generally performed better, the incorporation of domain context did not significantly enhance model performance. The results also highlighted the variability of performance across different versions and settings of these models, indicating potential areas for future investigation in NLP sarcasm detection.\n\n**Strengths**\n- The study effectively utilizes OpenAI GPT models for sarcasm detection, which signifies an advancement in NLP for detecting figurative language.\n- The research results are promising, with the fine-tuned GPT-3 davinci model outperforming prior sarcasm detection models.\n- The paper is well-written and easy to follow, providing a comprehensive investigation into the utilization of GPT-based LLMs for sarcasm detection.\n- The analysis of the results is detailed and rigorous, and the conclusions drawn have the potential to guide future directions in sarcasm detection methodologies.\n\n**Weaknesses**\n- The study focuses only on one balanced dataset, which does not represent the usual distribution of sarcastic vs. non-sarcastic conversations on social media platforms, reducing the generalizability of the results.\n- The results exclusively utilize GPT models from OpenAI, limiting the representativeness of the findings across the broader spectrum of LLMs.\n- The experimental results are mainly reliant on a single table, lacking in-depth visual representations or further analytic details that could strengthen the conclusions.\n- The use of domain context and prompt design seems underexplored, which could potentially influence the model's performance significantly.\n- Some methodological concerns were raised regarding the statistical significance and the appropriate reporting of quantitative measures.\n- The analysis does not fully explore the effects and mechanisms when using situational context to detect sarcasm, missing an opportunity to delve deeper into this critical aspect.\n\n**Questions**\n- Why were other LLMs beyond OpenAI's GPT models not considered for this study? Could their inclusion potentially affect the study's conclusions?\n- What impact might different prompt designs or additional forms of domain context have on the performance of the models? Could exploring these variations offer more insights?\n- Is it possible to provide a comparative performance analysis against other traditional and modern sarcasm detection models to contextualize the effectiveness of the GPT models employed in this study?\n- Given the significant emphasis on the use of a single dataset, could the inclusion of more diverse datasets provide a more comprehensive understanding of the models' capabilities?\n- Can a deeper examination be provided regarding the claim of domain context reducing the number of missed observations, specifically how these conclusions were drawn from the presented data?",
        "inference_review": "**Summary**\nThe paper examines the effectiveness of various GPT models, including GPT-3, GPT-3.5, and GPT-4, in detecting sarcasm within a dataset known as the Self-Annotated Reddit Corpus (SARC 2.0). It assesses these models through both fine-tuning and zero-shot methods, comparing their accuracy and F1-score against traditional models and other baseline classifiers. The paper highlights the performance variability of GPT models across different releases, noting that while some newer versions like GPT-4 exhibit better performance, others, like GPT-3.5, show a decline. The research also explores the impact of domain context on model performance, albeit with mixed results. However, the paper's approach is critiqued for its limited novelty and narrow focus on sarcasm detection, which may not contribute significantly to the broader field of NLP research.\n\n**Strengths**\n- The paper is well-written and easy to follow, making it accessible to readers.\n- The experiments are clearly defined, well-executed, and the results are easy to interpret.\n- The paper provides a straightforward and concise analysis of the GPT models' performance across different releases.\n- The authors have demonstrated a good understanding of the strengths and limitations of the models tested, providing a nuanced discussion on the implications of their findings.\n\n**Weaknesses**\n- The paper's scope is too narrow, focusing only on sarcasm detection in Reddit comments, which limits its general applicability and contribution to the broader NLP community.\n- The use of GPT models for sarcasm detection is not novel, as this has been a common approach in recent years, and the paper does not significantly advance the state-of-the-art.\n- The paper lacks a thorough discussion on the potential limitations of the GPT models, such as their potential biases or the impact of data distribution on model performance.\n- There is no detailed analysis of the dataset used, which is necessary for a robust evaluation of the models' performance.\n- The paper's methodology and experimental design could benefit from more clarity and detail, particularly regarding the fine-tuning procedures and the handling of domain context in the experiments.\n- The paper does not adequately compare the performance of the GPT models against traditional baseline models or other recent state-of-the-art models, which would provide a more comprehensive understanding of their relative performance.\n\n**Questions**\n- Can you elaborate on the fine-tuning procedures used for the GPT models? Specifically, how were the models fine-tuned, and what were the specific hyperparameters used?\n- How does the paper address the potential biases in the GPT models? For example, how do the models handle different types of sarcasm or sarcasm in diverse contexts?\n- Could you provide more details on the dataset used, including its size and diversity, and discuss how it was used for training and testing the GPT models?\n- How does the paper justify the use of the GPT models for sarcasm detection, and what are the main advantages of using these models compared to traditional or other recent models?\n- In terms of the performance metrics reported, could you clarify the specific metrics used and how they were calculated?\n- How do the results presented in the paper compare to those obtained using other state-of-the-art models, such as the models discussed in the works cited in the reviews?"
    },
    "xJ5N8qrEPl": {
        "gold_review": "**Summary**\nThis research presents a new single-loop Hessian-free algorithm for bi-level optimization (BLO) problems involving lower-level (LL) constraints coupling both upper and lower-level variables. This innovative approach utilizes the Moreau envelope value function, enabling a single-level reformulation with smooth constraints. This results in the proposed Lagrangian Value function-based Hessian-free Bi-level Algorithm (LV-HBA), which relaxes the strongly convex assumption on the lower-level problem to general convexity. The paper provides a detailed non-asymptotic convergence analysis and validates the effectiveness of the algorithm through extensive numerical experiments across various practical applications, highlighting its superior performance and computational efficiency.\n\n**Strengths**\n- The paper is well-written, with clear organization and elucidation of assumptions, which makes it easy to follow and understand both the primary concepts and the technical intricacies of the proposed approach.\n- The paper introduces the first single-loop Hessian-free algorithm for solving the bilevel optimization (BLO) problem, which includes a novel use of the Moreau envelope value function leading to an efficient gradient-based algorithm.\n- A new potential function associated with monotonically decreasing step sizes is presented, and methods to select these step sizes to ensure sufficient descent are demonstrated.\n- The authors include non-asymptotic convergence analysis for the proposed method and relax the lower level problem's requirements from strongly to only convex, increasing the method's applicability.\n- Extensive experimental results on five machine learning tasks validate the performance and demonstrate the efficiency of the proposed methods.\n\n**Weaknesses**\n- The paper includes many hyperparameters, which complicates practical implementation and parameter selection.\n- Some of the assumptions such as Assumption 3.1(i) and 3.3(ii) are considered too strong or unclear, which might limit the applicability of the proposed method in practical scenarios where these conditions are not met.\n- Comparisons with some recent significant works in constrained BLO through the value function approach are missing, which could provide a deeper contextual understanding of the paper's position within current research.\n- It is unclear whether the performance of the algorithm is overly sensitive to the stepsize parameters, and the choice of certain parameters like 'r' for the truncated proximal Lagrangian value function is not discussed.\n- The paper could benefit from more examples of bilevel optimization in machine learning with non-smooth and weakly convex lower level functions to better motivate and illustrate the approach.\n\n**Questions**\n- 1. Can the authors elaborate on why there is no need to assume Lipschitz continuity of the upper-level function F(x,y), which is typically necessary in bilevel optimization?\n- 2. How is the exact form of \u03c1f determined, especially in practical applications where it is potentially smaller than Lf?\n- 3. Can the authors clarify whether the optimal solutions of the reformulated and the original constrained BLO problem are equivalent, as suggested by Theorem A.1?\n- 4. How should the parameter 'r' be chosen in practical applications as mentioned in reformulation (5)?\n- 5. Could the authors provide insights into the central benefit of using the Moreau envelope as opposed to the optimal value function in the technical aspects of this work?\n- 6. How are the hyperparameters, including 'r', chosen in the experimental setups, and what guidance can the authors provide for their selection in practice?",
        "inference_review": "**Summary**\nThe paper introduces a novel method for solving constrained bi-level optimization problems by employing a smooth proximal Lagrangian value function to reformulate the lower-level problem into a single-level optimization problem with smooth constraints. This transformation enables the development of a Hessian-free gradient-based algorithm named LV-HBA, which offers a single-loop solution to constrained BLO problems. The paper also provides non-asymptotic convergence analysis for LV-HBA, eliminating the need for strong convexity assumptions at the lower level. Empirical results validate the algorithm's practical performance across various machine learning applications. The approach combines elements of previous methods and extends the value function reformulation to constrained problems, yet the novelty and depth of technical contributions are questioned, particularly in terms of its originality and the incremental nature of the proposed methods.\n\n**Strengths**\n- The paper introduces a new method for solving constrained bilevel optimization problems (BLOs) using a smooth proximal Lagrangian value function to reformulate the lower-level problem into a single-level optimization problem.\n- It presents a non-asymptotic convergence analysis for the proposed algorithm, which does not require strong convexity at the lower level, addressing a significant technical challenge.\n- The approach combines elements of existing methods and extends the value function reformulation to constrained problems, which could be beneficial for practical applications.\n- Empirical results provided in the paper demonstrate the practical performance of the algorithm in various machine learning applications.\n\n**Weaknesses**\n- The paper lacks a detailed comparison with existing methods and does not clearly articulate the main novelty of the proposed algorithm, making it difficult to understand its advantages over prior works.\n- The technical contributions are described as incremental, with the new method appearing to be a minor extension of previous works.\n- The presentation of the paper could be improved for clarity and readability, as some sections are difficult to follow.\n- The assumptions on the problem structure are restrictive, and it is unclear whether the results can be generalized to more complex scenarios.\n- The convergence analysis provided is limited to specific assumptions and does not consider more general or practical scenarios.\n\n**Questions**\n- Could you clarify what is the main novelty of your method and how it differs from and improves upon previous works?\n- How does the proposed algorithm perform in scenarios where the lower-level problem is non-convex or has more complex constraints?\n- Can you elaborate on the practical applicability of your method, especially in scenarios where the assumptions on problem structure are not met?\n- How does the proposed method handle scenarios where the lower-level problem is not strongly convex, and can you provide more details on the convergence behavior in such cases?\n- Could you provide a more detailed comparison with existing methods, particularly in terms of the computational efficiency and the assumptions required for convergence?\n- In the experimental section, how do the results compare with other methods like those cited in recent studies, such as those by Gao et al. (2023) and Kwon et al. (2023)?"
    },
    "ziDFH8TPPK": {
        "gold_review": "**Summary**\nThe paper introduces the Long-Term Typhoon Trajectory Prediction (LT3P) framework, which innovatively utilizes a data-driven model based on various weather and typhoon reanalysis data for real-time typhoon trajectory prediction. LT3P leverages a cross-attention mechanism between encoded past trajectory points and global meteorological data like geopotential and wind directions, eliminating the dependency on high-quality reanalysis data at runtime. The central coordinates of a typhoon are predicted using a real-time Numerical Weather Prediction (NWP) dataset, distinctly differentiating LT3P from alternative methods. Despite currently being tested solely on typhoons, the methodology shows potential for broader applications. Extensive evaluations and performance testing against state-of-the-art physics-based methods highlight its effectiveness. The model, along with its training and test code, will be open-sourced.\n\n**Strengths**\n- The paper presents a novel data-driven model for real-time typhoon trajectory prediction, differentiating it through the use of a real-time NWP dataset and applying innovative methodologies including cross-attention mechanisms and error correction schemes.\n- Significant empirical gains are reported over conventional physics-based baselines, showcasing the model's state-of-the-art performance.\n- The decision to open-source the data, training, and testing codes along with pre-trained weights will greatly contribute to reproducibility and advancements in the field of climate AI.\n- The method shows promise by initially learning the prediction of physical variables maps using reanalysis data before combining these with trajectory predictions, resulting in effective and accurate predictions.\n\n**Weaknesses**\n- The paper suffers from a lack of clarity and numerous grammatical errors that could significantly hinder comprehension and reproducibility. Detailed explanations on the network architecture, loss functions, and ablation studies are either vague or entirely absent.\n- The application of the model is currently restricted to typhoons and has not been demonstrated on other types of tropical cyclones. Moreover, the study's generality is limited to specific regions, raising questions about its applicability in different geographical conditions.\n- Over-reliance on the availability and accuracy of the real-time NWP dataset might limit the model's performance in less ideal conditions. Additionally, the dependence on updated reanalysis data, which has inherent delays, introduces concerns regarding the lead time in predictions.\n- There are inconsistencies in reported results and trends compared to other models cited in existing literature, with insufficient explanations provided for the observed differences, particularly the substantial improvements claimed.\n- The manuscript includes potential overstatements regarding its novelty and the feasibility of training models from scratch on datasets like ERA5, which have been accomplished in other studies.\n\n**Questions**\n- Given the dependence on real-time NWP data, how does the LT3P model's performance fare in scenarios with sparse or inaccurate data? Specifically, how is data accuracy managed in real-time to ensure reliable predictions?\n- How well does the LT3P model generalize across different regions and varying conditions of typhoon occurrences? Are there specific adaptational challenges when applying the model to other geographical locations?\n- Can you provide detailed clarifications on the methodological implementation aspects, such as the exact implementation of the ensemble methods, ablation study configurations, and the handling of bias correction in practical scenarios?\n- What insights can be drawn from Figures 4 and any other visual comparisons in the paper, particularly regarding the effectiveness of bias correction using ERA5 and UM datasets?\n- Several conceptual and terminological clarities are needed. For instance, the use of different alphabets for varying components in equations, precise definitions of error metrics, and clearer depiction of implementation details like the number of layers and compute times. Could these be addressed comprehensively in the revision?",
        "inference_review": "**Summary**\nThe paper introduces a novel approach for typhoon trajectory prediction using a physics-conditioned encoder and a trajectory predictor. The model leverages Unified Model (UM) data, which is available in real-time, to predict typhoon trajectories up to 72 hours in advance. The authors claim that this method outperforms both state-of-the-art data-driven methods and numerical weather prediction models. The paper also includes a dataset consisting of ERA5 reanalysis data, typhoon best-track data, and UM forecast data, which is released to support further research in this domain. Despite its promising results, the paper has been critiqued for its lack of clarity in methodology, insufficient baseline comparisons, and the need for more detailed experimental evaluations.\n\n**Strengths**\n- The paper introduces an innovative approach to typhoon trajectory prediction, using a physics-conditioned encoder and a trajectory predictor, which is well-documented and easy to understand.\n- The method incorporates real-time Unified Model (UM) data, which is not widely used in the field, and the approach is supported by a comprehensive dataset released to the public.\n- The authors have shown that the proposed method outperforms baseline models, and the manuscript is well-written and clear, making it accessible to a broad audience.\n- The use of the UM dataset and its bias correction is highlighted as a novel approach, which could be of interest to the community.\n\n**Weaknesses**\n- The paper lacks a detailed description of the UM dataset, particularly its quality and potential biases, which could impact the accuracy of the results.\n- There is insufficient comparison with existing methods, particularly those that utilize UM data, which makes it difficult to gauge the novelty and effectiveness of the proposed method.\n- The experimental evaluation is limited, with only a single dataset used for testing, and the results do not include error bars or statistical measures, which could affect the interpretation of the findings.\n- The methodology section could be improved by providing more details on the training process and the architecture of the models used.\n- The paper suffers from a lack of clarity in its presentation, particularly in the description of the method and its components, which could confuse readers or researchers attempting to replicate the study.\n\n**Questions**\n- Can the authors clarify whether the UM dataset used is publicly available and what the data processing steps are for the UM dataset?\n- How does the proposed method compare to existing methods that use UM data? Specifically, could the authors provide more comparative analysis or results from such studies?\n- Is there a possibility to provide more detailed information on the UM dataset's quality and potential biases to better understand the results?\n- Could the authors provide a more detailed description of the experimental evaluation, including error bars or statistical measures, to enhance the credibility and reliability of the findings?\n- Would it be possible to include more baseline comparisons or different experimental settings to better demonstrate the effectiveness and robustness of the proposed method?"
    },
    "nrDRBhNHiB": {
        "gold_review": "**Summary**\nThe paper explores extending regularization paths from linear models to deep neural networks (DNNs) by introducing a multi-objective optimization framework that combines empirical loss with sparsity regularization. The authors propose a novel algorithm composed of a stochastic gradient descent coupled with a proximal mapping and a multi-objective update, aiming to efficiently approximate the Pareto front of solutions. The methodology is validated using experiments conducted on the MNIST dataset. This paper provides a new insight into handling sparsity constraints in DNNs through its predictor-corrector approach to navigate along the regularization path effectively, addressing the issue of model overfitting by incorporating sparsity into the training process.\n\n**Strengths**\n- The paper presents a novel approach using an approximation of the Pareto front to enhance multi-objective optimization for non-linear, high-dimensional deep learning models, potentially avoiding overfitting and achieving low loss with sparsity.\n- The incorporation of a predictor-corrector scheme is innovative, helping to avoid clustering around unregularized and very sparse solutions, a significant improvement over the weighted sum approach.\n- The method is validated with a commonly used dataset, providing some empirical evidence of the technique's effectiveness.\n- Extensive background information and a clearly outlined methodology make the paper accessible and comprehensible.\n- The idea of considering multi-objective optimization to tackle the sparsity constrained problem is novel and effectively challenges the traditional single-objective frameworks in deep learning.\n\n**Weaknesses**\n- The paper does not provide adequate comparisons with existing regularization path generation methods, which is crucial for situating the novel contributions within the broader research landscape.\n- There is a lack of comprehensive experimental validation across more complex datasets and with deep neural networks that include non-linear layers, which undermines the generalizability of the results.\n- Key references are missing, including those related to the extension of regularization paths from linear models to deep neural networks, potentially overlooking valuable prior work and context.\n- The experimental setup and results need to detail computational time metrics to substantiate efficiency claims.\n- The method's applicability seems limited to two-objective problems, questioning its utility for more complex multi-objective settings.\n- The experiments conducted appear insufficient, especially considering the simplicity of the used networks and datasets which might not convincingly demonstrate the method's efficacy in more challenging scenarios.\n\n**Questions**\n- Can the authors explain how they plan to extend their method to handle more complex datasets and deeper neural networks with non-linear layers, as briefly mentioned in their discussion?\n- What strategies are proposed for efficiently determining initial points and handling random multi-starts in complex network structures without causing significant bottlenecks?\n- How does the proposed method compare in computation time and accuracy with traditional approaches to regularization path generation which incrementally increase L1 penalties?\n- Given the method's reliance on stochastic gradients, are there concerns about variability in performance or iteration times due to different initial points?\n- Are there plans to explore the use of non-convex penalties like SCAD/MCP instead of the L1 penalty, which is known to introduce bias in weight estimates?\n- How do the authors justify the absence of multiple loss functions in their experiments considering their claim of addressing multi-objective optimization?\n- Could the proposed methodology be effectively applied to find the Pareto front of a series of Lottery Ticket Subnetworks?",
        "inference_review": "**Summary**\nThe paper discusses a novel continuation algorithm for computing the regularization path in deep neural networks, addressing the trade-off between the empirical loss and the L1-norm of the model parameters. This method extends previous work by Bieker et al. (2022) to handle non-convex objectives, achieving a reduction in computational cost and improving efficiency. The paper presents numerical results on the MNIST dataset, demonstrating the efficacy of the proposed algorithm. However, the paper has received criticism for its lack of rigorous theoretical analysis and experimental validation, particularly in comparing the performance of the proposed method against existing techniques. Furthermore, the paper's claim of efficiency is questioned due to the potentially high computational costs involved in solving optimization problems at each step of the regularization path.\n\n**Strengths**\n- The paper is well-written, clear, and easy to understand, making complex concepts accessible.\n- The authors successfully extend the regularization path methodology to a non-convex setting, addressing a significant issue in the field.\n- The proposed continuation algorithm is described as efficient, with a potential reduction in computational cost compared to previous methods.\n- The numerical results presented are promising, suggesting that the method is effective in finding the regularization path.\n- The paper is well-organized and structured, making it easy to follow.\n\n**Weaknesses**\n- The paper lacks a rigorous theoretical analysis of the proposed method, specifically concerning the convergence properties and the impact of hyperparameters.\n- There is a lack of experimental validation, particularly a comparison with other existing methods that compute regularization paths.\n- The paper does not address the scalability of the proposed method, particularly in terms of its applicability to large-scale datasets.\n- The method's efficiency claims are questioned due to the potential high computational cost associated with solving optimization problems at each step of the regularization path.\n- There is a lack of clarity in the experimental setup and results, specifically concerning the choice of hyperparameters and the performance metrics used.\n- The paper does not discuss the sensitivity of the results to hyperparameters or the impact of the non-convex nature of the objective function on the regularization path.\n- There is a concern regarding the reproducibility of the results, as the code is not provided, and the method's applicability to other datasets is not demonstrated.\n\n**Questions**\n- Could the authors provide a more detailed theoretical analysis of the proposed method, including convergence proofs and sensitivity analysis regarding hyperparameters?\n- Can the authors compare the proposed method with other existing methods that compute regularization paths to validate the claimed efficiency and effectiveness?\n- How does the proposed method scale to larger datasets, and what are the computational costs involved?\n- What are the specific performance metrics used in the experiments, and how do these metrics relate to the objectives of the study?\n- Why were specific hyperparameters chosen for the experiments, and how do these choices affect the results?\n- Could the authors discuss the impact of the non-convex nature of the objective function on the regularization path, and provide insights into how this affects the method's performance?\n- Can the authors provide more details on the experimental setup, including the choice of network architectures and the datasets used?"
    },
    "Ue93J8VV3W": {
        "gold_review": "**Summary**\nThe paper introduces eight graph datasets each containing 7-31 features per node and evaluates various machine learning models against these benchmarks, focusing on heterogeneous node features. Named 'TabGraph', the benchmarks provide a mix of feature types, node numbers, average degrees, and domains. The paper discusses the implementation of models like GNNs, tabular deep learning, and tree models, alongside a hybrid approach. Various recommendations and analyses are given for both tabular and graph machine learning fields. The contribution centers around bridging the gap between traditional tabular data modeling and newer graph-based machine learning techniques. However, the paper lacks in-depth theoretical insights and substantial novelty in methodology, bringing into question its authenticity and potential impact on the field.\n\n**Strengths**\n- The new datasets include useful node-level features, especially enriching existing benchmarks with additional attributes that add realism to the graph datasets.\n- The paper provides several benchmark datasets useful for machine learning models focusing on both tabular and graph-based approaches, along with combinations of the two.\n- There are valuable insights and recommendations for researchers and practitioners working with a mix of tabular and graph data.\n- The introduction of performance comparison across various machine learning models for tabular data and graph-based models highlights the applicability in real-world scenarios.\n- The paper effectively fills the gap between machine learning for tabular data and graph machine learning by comprising datasets of different kinds and attempting a comprehensive evaluation of major models.\n- The structure of the paper is commendable, making it a readable and approachable resource.\n\n**Weaknesses**\n- The paper lacks in-depth discussion on the rationale for dataset construction and does not thoroughly analyze the qualitative properties of newly created datasets.\n- There is a significant need for greater insight into the empirical study, which currently only presents results from base models without further analytical discussion.\n- The document does not effectively differentiate between transductive and inductive settings in its analysis, a distinction crucial for the applicability of graph neural networks and graph-based machine learning.\n- The paper's focus and contribution towards \"research\" are weak, leaning more towards being a dataset paper rather than offering significant advancements in graph learning.\n- There are unaddressed limitations, such as the conversion of relational data into graphs, the computational costs associated, and the non-inclusion of certain data types like strings or texts which are crucial in tabular data.\n- The methodology for dataset selection and preprocessing lacks clarity and comprehensiveness.\n- Insights provided are not entirely convincing due to the dataset being preprocessed by undisclosed rules.\n\n**Questions**\n- What was the specific criteria for the selection of these eight tabular datasets?\n- How does the paper address the difference between transductive and inductive learning methods, particularly in performance comparison?\n- Can the authors provide clarity on the comparative model performances on homogeneous features versus heterogeneous features to demonstrate the efficacy of the proposed datasets?\n- Why were strings or text data types not included in TabGraph, and how does this omission affect the benchmarks provided?\n- Could the authors explain their decision-making process regarding which features to include or exclude during dataset preprocessing, such as the number of votes in GBDT experiments?\n- What is the rationale behind the choice of thresholds for different datasets as mentioned in Section 3.1?\n- Is there a plan for adding at least one dataset from the science domain for node classification and regression tasks?\n- Can the importance of different types of features (number, binary, categorical) be comparatively analyzed in the paper?\n- What are the expected dates for the release of the source code and the datasets?\n- Could the authors elaborate on the resource implications of converting tabular data into graphs, considering computational limits and other constraints?",
        "inference_review": "**Summary**\nThe paper introduces a benchmark named TabGraphs, designed to evaluate machine learning models on tabular data structured as graphs, emphasizing the incorporation of heterogeneous features. This benchmark aims to fill the gap in existing datasets by offering a diverse set of graph datasets with heterogeneous node features, focusing on practical, real-world applications. The authors conducted extensive experiments using a variety of machine learning models, including traditional tabular models, deep learning models, and graph neural networks (GNNs). Their findings highlight the potential of graph models in enhancing predictive performance over traditional tabular models, particularly with the integration of feature embeddings and specific GNN architectures.\n\n**Strengths**\n- The paper addresses an important and timely issue of combining tabular and graph machine learning, which is highly relevant in the current research landscape.\n- The introduction of the TabGraphs benchmark, featuring a diverse set of datasets with heterogeneous features, is a significant contribution to the field, helping to bridge the gap between tabular and graph machine learning.\n- The experimental setup is thorough, providing a comprehensive evaluation of various machine learning models, including traditional tabular models, deep learning models, and graph neural networks.\n- The paper offers a clear and detailed explanation of the datasets and experimental setup, making it accessible and understandable to a broad audience.\n- The results presented in the paper are encouraging, showing that graph models can outperform traditional tabular models in many scenarios.\n\n**Weaknesses**\n- The paper lacks a clear motivation and justification for using tabular data structured as graphs, particularly in the context of the datasets used, which are not inherently graph-structured.\n- The experimental results are presented in a way that does not clearly distinguish between different models' performance, which could lead to confusion about the effectiveness of various approaches.\n- The literature review is insufficiently comprehensive, particularly regarding recent studies on node property prediction and graph learning for tabular data.\n- The paper does not sufficiently discuss the limitations of the proposed benchmark and does not compare the performance of the TabGraphs benchmark against other existing datasets or benchmarks.\n- Some of the terminology and notation used in the paper are unclear or inconsistent, which could hinder understanding and replication of the work.\n- The paper does not provide a clear justification for the choice of specific datasets or the exclusion of other relevant datasets, which could impact the perceived validity and generalizability of the results.\n\n**Questions**\n- Could you provide more details on the motivation behind using tabular data structured as graphs, especially considering the datasets used in your study?\n- How do you justify the choice of specific datasets for your study, and why were other datasets not included?\n- Could you clarify the notation used in the paper, particularly the use of \"R\" in equations and the notation of datasets?\n- Can you explain the decision-making process behind selecting the specific machine learning models for evaluation in your study?\n- Why was the evaluation of the benchmark limited to the models mentioned, and could you consider including a broader range of models in future studies?\n- Could you provide more details on the experimental setup, particularly the choice of metrics and the methodology for comparing the performance of different models?"
    }
}